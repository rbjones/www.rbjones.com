% $Id: pc.tex,v 1.1 2007/01/05 14:40:09 rbj01 Exp $
\chapter{Perfect Cadence}\label{PerfectCadence}

In this chapter I look to the future.

Here I speculate, as best I can, about how things might be if logic were exploited to its limits, and in particular what that might contribute to standards of rationality.

To draw the contrast and place the line, it is also necessary to consider where logic will not help, why not, and perhaps briefly what might.

We consider therefore, what might rationality be like if we were, or were aided by our machines in being perfectly logical, a line having thus been drawn under this stage in the intellectual history of mankind.

It is timely that we should consider this matter now, because, in the century ahead, for the first time in history, it seems possible that the world will become populated with intelligent artifacts, who are rational {\it by design}, not on the part of some God, but by mere mortals.
In the future some of us may be practically involved not merely in influencing but in determining what passes for rationality in millions of intelligent beings.

The design of such artifacts is not only a matter of practical concern, it is a test-bed for epistemological theories.

I have no inclination to claim that philosophy should be concerned exclusively with {\it a priori} thought, and hence should be dominated by logical methods.
However, there seem to be strong reasons for claiming that, insofar as philosophers support their views by arguments which purport to be deductive, then the validity of these arguments, and the meaning of their conclusions can both be greatly clarified by the use of formal techniques, and can by these means be taken beyond reasonable dispute.

Even if the effect of these methods were {\it only} to remove from the concern of philosophers problems which need not concern them, this would be a material benefit.

\section{Technological Hypotheses}

My speculation about the future of philosophy begins with a counterfactual hypothesis which I will call {\it the FAn oracle hypothesis}.
This is about the kind of software available for support of knowledge workers using formal languages.

The hypothesis is simply that a well-engineered FAn oracle is available for use by such people, together with formal knowledge bases formalising all the knowledge on which their work is to build.

The hypothesis is strictly counterfactual in the sense that we know now as a result of Godel's incompleteness results that there will never be a FAn oracle.
However, we do in fact know formal systems which are for practical purposes very close to complete.
Formal incompleteness is not the real difficulty, the real difficulty is computational intractability.
The hypothesis is worth considering because in the long term problems of computational intractability are likely to be gradually solved in much the same way as they are partially solved by human intelligence.
We learn the shortcuts which get us to a solution in reasonable time over a decent space of problems, the machines can be taught too.

The hypothesis puts us in an idealised world, but one which we can expect to approach close enough in practice that the thought experiment is worth doing.

Now our concern here is with the impact that such developments might have on philosophy.
But I believe that the first impact will not be on philosophy, but on engineering and science.
The initial impact on philosophy will be simply in the need to understand the effects of this technology on science and engineering.

So I plan first of all to talk my way through the likely impact of the FAn oracle on Mathematics, Science and Engineering before considering what might happen to philosophy.

\section{Formalised Science and Engineering}
\subsection{Language and Logic}

The premise is that we have a well supported {\it logical foundation system} which provides us with the {\it Logic + Ontology} needed to permit all other analytic truths to be expressed using only conservative extensions.
Notational flexibility is supported both in the piecemeal way that mathematicians extend their notation and by semantic embedding for completely new notations whenever these may be desirable for some special application domain.
The underlying ontology is to a large extent arbitrary, providing only the witnesses necessary to establish the consistency of our linguistic extensions, which are then interpreted abstractly.

This core therefore provides an objective are reliable test of the truth of analytic conjectures, in a linguiwtic framework which allows language to be developed and extended with the necessary precision for analyticity to be well defined.

\subsection{Mathematics}

With our mathematical foundation in place mathematics can now be formalised.

Once known mathematics has been assimilated by the system it will provide an ideal research environment for mathematicians.
Though a FAn oracle would not take over the most creative aspects of a mathematicians work, notably the conceptual innovations on which new branches of mathematics are based, or even the formulation of important hypotheses, it could take over the burden of checking the truth of the hypotheses.
Mathematicians would be able to concentrate on understanding their problem domain with all the detailed drudgery of proof lifted from their shoulders.

The automation of proof of hard new mathematical results is the least plausible feature of the FAn oracle hypothesis.
However, an approximation to a FAn oracle would not need to be superhuman in intelligence to provide an environment for cooperative mathematical research which was more congenial and productive than a mathematician has at present.

The support of research in mathematics is however of marginal importance.
Support for the application of mathematics in science and engineering is likely to be less taxing on the intelligence of our oracle and more substantial in its impact on society.

\subsection{Metaphysics}

We now consider how our purely logical oracle serves the purposes of empirical science.

The basic premise is that science is engaged in producing mathematical (or perhaps more generally, {\it logical} models of aspects of the real world, which are then applied by engineers to real world problems.
For tidyness I assume that scientists create and engineers apply; the oversimplification is of no consequence for our present purposes.

Building mathematical models is a purely mathematical activity.
The fact that these models are intended as models of the real world has no impact on the model itself.
The evaluation of such a model against the real world is done by first translating the real world situation into the mathematical terms of the model, then mathematically deducing the behaviour of the model, and then translating the mathematical results back into a real world interpretation.
The translation is informal, but natural.
The mathematics is abstract and therefore intended for multiple interpretation.
The interpretation used by the FAn oracle to ensure that the model is consistent may be exclusively in terms of pure sets.
But many other interpretations will also be valid, and the real world interpretation intended by the scientist is one such interpretation (if the scientist is on the right track).

Ontologically therefore, the transition from pure mathematics to applied science requires no supplements to the purely logical ontology on which our foundation is based.
If you are acquainted with the intuitions behind the foundation system (which a user might not need to be) we are heading for a pythagorean ontology, in which the world is made entirely of abstract objects.
In the case of Pythagoras it was numbers, in our case it could also be numbers, but is more likely to be sets.
The difference is mere pragmatics.

This does not mean that there are not real ontological problems for metaphysics to grapple with.
The first stage in the formalisation of a scientific theory is to determine what the theory is about.
In the case of fundamental physical theories such as those of Newton and Einstein the theory is about the universe and a decision must be made on how the universe is to be modelled.
For preference abstract models would be used (in which the specific objects involved are not known, but the key features of their inter-relationships are known), but sometimes ``concrete models'' (in which specific sets are know to represent the various kinds of objects) may be easier to understand.
Such a concrete model for a Newtonian universe of point masses would be a set of tuples of numbers, each number represeting one of the quantities necessary to uniquely identify a particle and its properties, e.g. its coordinates in space, its mass, the components of its velocity.
The state of the Universe at some moment in time may thus be represented as a set of tuples, and the behaviour of the Universe over time as a function from numbers representing moments in time to these temporal states.
Let us call such a Universe a ``Euclidean Particulate Universe'', the metaphysical activity consisting in formally defining this concept.

In chosing such a model we have elected for a Euclidian space time and a material ontology consisting exclusively of points of mass.
From a physical point of view, the only things that exist are these particles.
from a logical point of view our ontology is unchanged, in Russell's terminology these particles are {\it logical constructions}, in this case from sets.

Thus far metaphysics, which in our scheme of things is defining the kind of things a scientific theory is {\it about}.
The formulation of scientific laws is then the formulation of properties of such systems, which we will discuss further shortly.

Another important point about the relationship between our logical and physical viewpoint must now be made.
Our logical foundation system is unchanged as we transit into metaphysics and science.
Only conservative extensions over the foundation system are permitted, with the effect that all the results provable within the system are analytic, logical truths.
This protects the consistency of the logical system, which might be compromised by extensions which are not conservative, and since we start with a strong logical system this constraint is not a material impediment.

When a mathematical model is developed in the system, this is just another conservative extension.
The development of the model is simply the construction of an elaborate definition.
A this point we simply have a model defined, for consideration, not a model affirmed as true.

There are good reasons why, from a formal standpoint, we should go no further.
A benefit of holding this metaphysics as hypothetical is a necessary pluralism.
Science and Engineering work with a variety of different underlying metaphysics, to affirm any one would be to exclude the others.
Metaphysics provides a library as basic building blocks for science and engineering, but affirms none and thus remains an {\it a priori} science.

\subsection{Empirical Hard Science}

The term ``hard'' is used here to distinguish those sciences which benefit from mathematical (or more generally perhaps, logical) models.
In fact we are particularly interested in those sciences which provide the basis for aspects of engineering design, because of their potential to economically catalyse the development of epistemological support technology.

The formulation of a scientific model is a further act of definition.
We define a ``Newtonian Particulate Universe'' as a Euclidean particulate universe which satisfies Newtons laws of motion.

Formally the kind of activity involved here is just the same as in metaphysics, it is another conservative extension to our language in which meaning is attached to another concept.
What distinguishes the formulation of a scientific model from that of a metaphysic is applicability, and hence testability or falsifiability.

The metaphysical model is a stage in the formulation of a scientific model, and one which we would expect to be common to many scientific models, but one whose utility consists only in providing concepts which are useful in the subsequent scientific modelling.

From our formal standpoint the truth of scientific theories is not an important consideration.
In practice scientific theories are approximate models (some of them very precise indeed).
If we take the collection of useful scientific models then we will find that they do not agree.
In practice, though relativistic mechanics may provide more precise models, newtonian mechanics provides more useful models (in the sense that they are the models of choice in most situations).
However, these models are incompatible.
It the use of a model involved the assertion that it was a true model of the world, then the use of both of these models would render our logical system incoherent (and could not be done by conservative extension).

So far as the formal treatment of science is concerned, it is for these reasons unhelful to consider scientific models as objectively true or false.
They are applicable or inapplicable, and the assessment of the applicability of models is more important than the assignment of a truth value to them.

\subsection{Engineering Design}

We now come to the formalisation of the process of design, which is selected as illustrative of the material benefits of formality.

The idea is here that some artefact is to be constructed, possible at very great expense, with some particular purpose in mind.
Because of the expense involved it is important that the construction should be carefully planned and a {\it design} plays a crucial role in this, being the description of what parts are required for the construction and how they are to be fitted together to form the desired artefact.

Since we have some particular purpose in mind for this artefact there is a correctness consideration for the design.
If the design is correct then an artefact constructed according to the design will fullfil the purpose for which it was intended, otherwise the design is defective.
The design problem then consists in coming up with a design which is in this sense {\it correct}.

In order to judge whether a design is correct without going to the expense of building the object it prescribed (which we will prefer to do only {\it after} establishing the correctness of the design) we need to be able to model the kinds of system concerned.

Let us suppose then that science (and perhaps some other aspects of engineering activity) has furnished us with suitable mathematical models of the kinds of components which are available for building our artefact.
With the benefit of these models, the question of correctness of some putative design with respect to the requirements is an analytic question answerable by a FAn oracle.
Furthermore, a correct design, if one exists, is in principle discoverable by a FAn oracle.
In practice there are likely to be constraints on the requirements not formally modelled, and the {\it discovery} processes are likely to involve human intelligence for ``the forseeable future''.
However, the possibility of even modest increases in productivity of engineering design processes, particularly from machine support for the verification of such designs, is of substantial economic importance.
If it were accepted that proof technology (in the form of any kind of approximation to a FAn oracle) would deliver such benefits then this would generate the funding for developing the technology.

It is in fact already accepted that in some engineering domains, in particular in the design of complex digital electronic hardware, the use of formal techniques is beneficial, though the kind of approach suggested here has not been attempted.

\section{Epistemology}

The twentieth century has been both the age of analysis, and the century in which philosophers have shown unprecedented preoccupation with language.
Since my earliest acquaintance with philosophy I have regarded language as a tool not as a subject matter, let alone a source of philosophical wisdom.
This personal predeliction against the flow is reflected here in the central place of epistemology, and the marginal placing of philosophy of language, in an essay which could be said to be essentially about the potential impact of logic, an aspect of language.

I'm going to use the term epistemology here in an unusual sense, for though I consider it the most central concern of analytic philosophy, when I read what seems to be a good account of modern epistemology (e.g. \cite{dancy}) I find it to be almost wholly preoccupied with problems which don't deserve serious attention, or in approaching problems by quite inappropriate methods, and neglectful of many other problems which seem to me more worthwhile.

On scepticism ``modern epistemology'' seems preoccupied with disputing sceptical arguments which are beyond dispute, engaged in an wholly academic debate divorced from any practical relevance.
The role of more subtle and useful kinds of scepticism is neglected.
The study of what it means to know, which must either be a question about how this term is in fact used in language, or perhaps a study of how it might be used, attempts the former by methods appropriate at best for the latter.
The study of various kinds of knowledge seems concerned to provide a philosophical account, most prominently of perception, which is radically different from and seemingly ignorant of the scientific one.

Epistemology is {\it about knowledge}, how should it be differentiated from other kinds of study of knowledge, such as the sociology of knowledge?
Well, as philosophy it is not primarily concerned with how things {\it are}, it is more broadly concerned with how they {\it might be} and with the merits of these possibilities.
Furthermore, it is concerned particularly with criteria or justification.
A psychologist or a sociologist might be interested in a dispassionate way in how we arrive at judgements and how these judgements may come to be accepted in some community as truthful.
A philosopher may take a particular interest in what ways are arriving at or justifying beliefs are {\it rational}.

Philosophical epistemology, to a greater extent than scientific studies in the same area, may be seen as contributing to choices about how things might or should be rather than simply analysis about how they are.
Rather than engaging in field studies or focussing on problems which may be thought not to require them, it should draw on relevant studies in empirical or social sciences, though no uncritically.
What it can do more wholeheartedly is to engage in the kind of analysis and speculation which contribute to change.

Problems of method in all branches of learning should be included, and especially those of scientific method.
Beyond this, problems in non-academic areas where {\it establishing the truth} should also be taken into accoutn, and may contain important philosophical value.
Jurisprudence is an obvious example, but there are many less obvious ones.
One area of special interest is computer security, where the use of formal methods is recognised in the criteria for certification of secure sysems.
Even where formal methods are involved, all certification procedures may be interpreted as attempts to secure consistent high standards of justification of certain key types of proposition (e.g. that a system is secure or that it is safe), and may be of philosophical interest.


\section{Return to Leibniz}

\index{Leibniz}

Let us now recapitulate my reasons for believing that the search to automate knowledge via universal formal notations is worthwhile and may ultimately be fruitful.

{\onecolumn
\begin{centering}
\begin{table}[h]
\begin{tabular}{p{2in} p{3in}}
deductive incompleteness & not a practical problem \\
\\
linguistic relativism & semantic embedding \\
\\
logical pluralism & semantic embedding \\
\\
semantic incompleteness & not a practical problem \\
\\
computational intractability & a real problem, but not a stopper\\
\\
synthetic propositions & by definition of models
\end{tabular}
\caption{Defending Leibniz's Dream}
\end{table}
\end{centering}
}%\onecolumn
