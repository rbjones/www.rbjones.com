% $Id: p050.tex $
% bibref{rbjp050} pdfname{p050}
\documentclass[10pt,titlepage]{article}
\usepackage{makeidx}
\usepackage{turnstile,amssymb}
\newcommand{\ignore}[1]{}
\usepackage{graphicx}
\usepackage[unicode]{hyperref}
\pagestyle{plain}
\usepackage[paperwidth=5.25in,paperheight=8in,hmargin={0.75in,0.5in},vmargin={0.5in,0.5in},includehead,includefoot]{geometry}
\hypersetup{pdfauthor={Roger Bishop Jones}}
\hypersetup{pdftitle={Logical Truth and Proof}}
\hypersetup{colorlinks=true, urlcolor=red, citecolor=blue, filecolor=blue, linkcolor=blue}
%\usepackage{html}
\usepackage{paralist}
\usepackage{relsize}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{longtable}
\usepackage{url}
\newcommand{\hreg}[2]{\href{#1}{#2}\footnote{\url{#1}}}
\makeindex

\title{\LARGE\bf Logical Truth and Proof}
\author{Roger~Bishop~Jones}
\date{\small 2022/11/19}

\begin{document}

%\begin{abstract}
% An attempt to define logical truth and how to demonstrate such truths.
%\end{abstract}
                               
\begin{titlepage}
\maketitle

%\vfill

%\begin{centering}

%{\footnotesize
%copyright\ Roger~Bishop~Jones;
%}%footnotesize

%\end{centering}

\end{titlepage}

\ \

\ignore{
\begin{centering}
{}
\end{centering}
}%ignore

\setcounter{tocdepth}{2}
{\parskip-0pt\tableofcontents}

%\listoffigures

\pagebreak

\section*{Preface}
\addcontentsline{toc}{section}{Preface}

This is a place to work out some ideas intended to form a part of a larger structure, a book perhaps.

\footnote{There may be ``hyperlinks'' in the PDF version of this document which either link to another point in the document  (if coloured blue) or to an internet resource  (if coloured red) giving direct access to the materials referred to (e.g. a Youtube video) if the document is read using some internet connected device.
Important links also appear explicitly in the bibiography.}

\section{Introduction}

This is intended to be a part of a description of a cognitive architecture suitable for a very large scale distributed cognitive system of the kind which might arise if self-replicating intelligent systems were to proliferate across the Milky Way galaxy or beyond.

The idea is that the whole structure of data across the known universe should be interpretable as a single coherent information and knowledge structure, with multiple layers of interpretation, multiple loci of evolution, and an integrity which survives the impossibility of synchronisation.

This will first be discussed as an abstract view of a distributed information structure, then as a distributed catalogue of languages local to particular parts of the structure (contexts) and of logical truths which are demonstrated in the various contexts.

A cognitive system will naturally be expected to contain empirical as well as logical truths, and also some crucial knowledge of important purposes and values.
The later sections will give some information about how this logical system can represent these non logical truths.

There will likely ever be controversy over logical foundations, into which this document is not intended to engage.
It is offered as one alternative among many, with the merit of universality.
The contention is that all logical truths can be represented conveniently in this system and that in turn all other kinds of propositional knowledge can be hosted in a logical system such as that described.

It works by adopting a single abstract syntax for the representation of logical truths, and allowing that other languages can be accomodated by mapping both the abstract syntax and the semantics of the language onto the foundational system described here.

\paragraph{quotes and apostrophes}

I use double quotes only when I am reporting verbatim the words written or spoken elsewhere, in which case it would be normal to have an attribution, though sometimes when referring to my own usage.
I use single quotes if I am mentioning rather than using a word, or when I am distancing myself from (despite adopting) a usage which is doubtful or controversial in some way.
There may be other cases, but the main
I use italics for emphasis or when I am introducing some new terminology to highlight the new term.

Apostrophes are something else, in which I hope my usage is not eccentric.

\section{Analyticity}

In the aftermath of the debate on the concept of analyticity which took place between Rudolf Carnap and W.V. Quine \cite{carnap90}, the attempt in this essay to make as solid and precise as possible a conception of analyticity and the means for establishing the analyticity of particular propositions may be thought to be responding to a presumed weakness in the concept of analyticity which renders it rather more in need of attention than other philosophical terminology.

The purpose of this section is to give my reasons for considering that there should never have been credible doubt about the status of the word analyticity, even in the days between the publication of Carnap's `The Logical Syntax of Language' (which was Quine's introduction to Carnap's work) and Quine's supposed demolition of the concept of analyticity in his `Two Dogmas of Empiricism'.
Which is not to say that there was not and is not grounds for further refinement of the concept and elaboration on its ramifications, to which this essay is intended to contribute.

I know of no other philosophical concept which is as precisely definable as the concept of analyticity, matching the level of precision found in the concepts of mathematics.
Any such definition depends for its precision on an exact delimitation of the domain in which it is applicable, for otherwise the terms used in the definition themselves be meaningless.

What is required for the concept of analyticity (as it is used here%
\footnote{The concept has a long history and its meaning has evolved over millenia.}) to be applicable to the sentences of some language, is that the language has definite `truth conditions'\index{truth conditions}.
For a language to have definite truth conditions, it must have a definite delimitation of its scope of applicability, which, if the subject matter of the language is 'the world', would be the range of possible worlds.
If the language is not intended to refer to `the world' then we may in general consider the subject matter of the language to be constituted by a collection of intended interpretations, and I will use that terminology for the general case, including as possible worlds as `interpretations' of a language.

The truth conditions of sentences in a language then consist in:

\begin{enumerate}
\item A set of intended interpretations (the possibiities)
  \item An assignment to each sentence of the language of a subset of the intended interpretations (the cases in which that sentence is true).
\end{enumerate}

The set of interpretations thus assigned to each sentence should be understood as the set of interpretations under which the sentence in question is `true'.
A sentence in such a language is then considered `analytic' if (and only if) the set of sentences in which that sentence is true is the full set of intended interpretations, i.e. if it is \emph{always} true under every possible cirumstance.
\footnote{
Though this concept has been at the centre of controversy in philosophy it is less controversial among mathematical logicians, who are more accustomed to precise definition of the syntax and semantics of their notations and languages.
The property of `completeness' of a deductive system consists in the derivability in that system of every analytic formula, but is generally expressed in other terms.
Some important milestones in the development of modern logic have been proofs of that kind, notably, the completeness of the sentential calculus, proven in the doctoral dissertation of Emil Post \cite{post21}(in which the term `positive' is used for the formulae here called analytic), and the completeness of the first-order predicate calculus, proven in the doctoral dissertation of Kurt G\"{o}del \cite{godel30} (by which time the term `valid' was usual).
}

Methods for the formal description of the semantics of formal languages were later greatly elaborated by computer scientists and engineers, who also engaged 


The usage of the term `interpretation' here is generic, supports the present narrative and may not exactly correspond to the accepted usage in accounts of particular logical systems.
It encompasses all that must fixed before the truth value of a sentence is determined, which would not normally include values for free variables, since `sentences' may be required to be closed (i.e. to contain no free variables).

In an early treatment of simple formal languages which indicates how comfortable mathematicians are with describing the meanings of their notations well enough for 

\cite{heijenoort67,post21,godel30a,tarski31,tarski56,carnap47}

\section{Natural and Formal Languages}

Deductive reason, which begins in the natural languages which homo sapiens has spoken since the origins of our species, has been shown to be highly reliable and to delineate the particular class of truths here spoken of as ``logical truths''.
Nevertheless, attempts to reason soundly in natural languages have not always been successful.

Both extremes are documented in the works of the philosophers of ancient Greece in the period between 600 and 300 years before Christ.
During that period a body of mathematical theory was established under the heading ``Equlidean geometry'' (and beyond) which survived more than 2000 years before any flaws could be found in it, but when reasoning was applied to understanding the cosmos the conclusions reached were almost immediately disputed, and it was to be readily demonstrated that contradictions and absurdities could ostensibly be demonstrated.

It is reasonable to attribute these disparities to two principle factors, not unrelated.
The first is subject matter.
In mathematics, the subject matter is abstract and has quite simple characteristics which are readily captured precisely by quite simple language.
When we come to talk about the material world, and when we concern ourselves with the nature of that world at very small or very large scale, the language we use is much less clear, and our knowledge of the key principles in those domains is tentative or speculative.

Considering the question of precision of language it may be noted also, that a weakness of clarity translates into a risk of equivocation.
Equivocation is the logical fallacy of using the same term with different meanings in the same argument, which is lethal to sound reasoning and gives ruse to contradictions and the demonstration of falsehoods.

Reliably extending the reach of deductive reason beyond Euclidean geometry was not impossible in mathematics, since in that domain the subject matter not only permitted but made essential notational innovation ensuring that the language of mathematics remained a precise and unambiguous tool for expressing and demonstrating results.
Greek philosopher did seek to capture that same realiability in other domains.
Aristotle, the first philosopher knowm to have studied and written about logic and demonstration, devoted consiferable energy to articulating a conception of demonstrative science to that end, taking important steps toward `formal' treatment of the topic in his syllogistic.
Logic was also a strength of the Stoic tradition in Greek philosophy.

For the study and enunciation of logical principles, further demands are placed upon language, not dissimilar to those familiar in mathematics.
For example, in order to talk about a variety of linguistic structures which have a common logical structure, it is helpful in the study of logic, as it is in mathematics, to make use of `variables', names which have no definite designation but are to be construed as referring to any one of a number of gramatically similar entities.

We will find that for logic to reach its full potential, and for a good account of the conception of logical truth. resort to formal notations, similar in character to the mathematical notations, will be necessary.
In what follows the discussion of the various aspects of logic will at first begin with the way in which these appear in natural languages, but will then progress to speaking of them in formal notations which minimise the great risk in natural languages of reading those concepts in ways not intended, and hence possibly not consistent with the story.

\section{Propositional Logic}

\subsection{Propositions in Natural Languages}

That which is expressed by a sentence in a natural language, which from its form and meaning we would expect to be either true or false, I call a {\it proposition}\index{proposition}.
The word `proposition' is not always used in this way.
Sometimes it is used to refer to sentences themselves, rather than what is expressed by them.
Sometimes `proposition' is a verb.

In speaking of that which is expressed, I speak of the \emph{meaning}, either of a sentence or of some other expression in a language. such as a word or phrase.
What kind of thing a meaning is will remain rather vague, but there are certain aspects of meaning of which I will speak in more precise terms in due course, notably, ``truth conditions'', which tell us under what circumstances a sentence will be true or false.

By `natural language' I mean the kind of language which people normally use when conversing with each other, and which typically has very ancient origins of which we are largely ignorant.
The meanings associated with sentences or expressions in natural languages are to be discovered by studying the way in which those sentences and expressions are used in typical discourse.
Insofar as that usage is imprecise or inconsistent, so will be our understanding of the meaning of the language.
We know the meaning of 'meaning' in a similar way, and this adds confusion to an enquiry into the meaning of natural languages, which is best remedied for our present purposes by adopting and defining technical terms to describe the aspects of language which are of interest.
Because people will learn and make use of languages before they have very broad acquaintance with the usage of any but a few others speakers of the language, the meanings of expressions in these languages is often uncertain, to the extent that not only may each of us not know what they are, but that there may be no definite objective meaning.

This is in contrast with what I will call ``formal language'', which is a language which has been devised and defined for some particular range of usage, often with the desire for a language which is more precise and better defined than natural languages.

\subsection{Sentential Connectives}

The study of propositional logic begins with the connectives in natural languages which become the prototype for operators in a formal language.
For a more extended treatment see \cite{sep-connectives-logic}.

Given one or more sentences we may construct more complex sentences from them using sentential connectives \index{sentemtial connective}.
Our interest here is in those sentential connectives which are \emph{truth functional}\index{truth functional}, which means that the truth of a comppound sentence formed using the connective depends only upon the truth of the sentences from which the compound was formed.

Two simple connectives illustrate this phenomenon.
The connective `and' combine two sentences into a larger compound which is true if and only if both of the two constituent sentences are true, and false otherwise.
Semantically this connective operates upon the propositions expressed by the sentences, and is may therefore also be called a propositional connective or operator, and plays an important role in propositional logic.

We can describe the meaning of truth functional operators using \emph{truth tables}\index{truth table}.
A truth table shows for each combination of truth values for the constituent propositions the truth value of the resulting proposition.

Because the word `and' is not only used in natural English purely as a truth functional connective, we abstract its truth functional role into a formal language where that is its sole purpose, and its semantics is therefore simplified and made more definite.
In that context, instead of `and' it is common to use the symbol '\land'.
The following table gives the truth function which this symbol denotes.

\begin{center}
  \begin{tabular}{c|c|c}
 A & B & A \land{} B\\
 \hline
 F & F & F\\
 F & T & F\\
 T & F & F\\
 T & T & T\\
 \end{tabular}
\end{center}

An even simpler connective, which doesn't really connect because it has onlt one operand, but is nevertheless a truth functional operator of great significance, is expressed in English as `not' and in its use as a truth functional operator inverts the truth value of the sentence it is applied to as is seen in its truth table:


\begin{center}
  \begin{tabular}{c|c}
 A &\lnot{} A\\
 \hline
 F & T\\
 T & F\\
 \end{tabular}
\end{center}


In the language of propositional logic, complex expressions are built from propositional variables, by repeated application of a variety of propositional operators.
The meaning of such expressions is then the truth function which maps the values of the variables which occur in the expression to the resulting value of the expression as a whole.

Just as in the case of single truth funcitonal operators corresponding to sentential connectives, the truth function can be shown using a truth table.
It is then considered to be a logical truth or a tautology, if the resulting value is always true, whatever the truth values of the propositional variab;es which occur in it.

Inspecting the tables above, we can see that neither $A \land B$ nor $\lnot A$ are tautologous, since for some values assigned to A and B they yield the value false.

Taking these two connectives as given, we can define other connectives.
One important connective is `or' rendered symbolically as `\lor{}', which can be defined in terms of \land{} and \lor thus:

\[  A \lor{} B = \lnot{} ((\lnot{} A) \land{} (\lnot{} B)) \]

which says that A or B is true when it is not the case that both A and B are false, with the truth table:

\begin{center}
  \begin{tabular}{c|c|c}
 A & B & A \lor{} B\\
 \hline
 F & F & F\\
 F & T & T\\
 T & F & T\\
 T & T & T\\
 \end{tabular}
\end{center}

We are now in a position to exhibit some elementary logical truths.

\begin{center}
  \begin{tabular}{c|c|c|c|c}
 A & \lnot{} A & A \land{} (\lnot{} A) & A \lor{} (\lnot{} A) & \lnot(A \land{} (\lnot{} A))\\
 \hline
 F & T & F & T & T\\
 T & F & F & T & T\\
 \end{tabular}
\end{center}

In this table the second and third columns both show T on every row, indicating that the formulae at the head of these columns are both logical truths in the propositional calculus, or tautologies.

We do not yet have a `logic', for we lack formal rules which enable us to prove the logical truths which can be expressed in this language.

To introduce the notion of proof we must instroduce one more sentential connective with corresponds to the expession (A therefore B) or (if A then B).
For this we use the technical term `material implication' because of its similarity with the concept of implication, and because there are non truth functional uses of the term `implication' which make the truth functional commective a controversial formalisation of implication.

The symbol we will use here for material implication is `\Rightarrow{}', which can be defined as:


\[ A \Rightarrow{} B = B \lor{} (\lnot{} A)\]

Which allows us to state as a theorem the rule of Modus Ponens, which is important in establishing a formal deductive system for propositional logic.


\[ (A \Rightarrow{} B \land{} A)  \Rightarrow{} B\]

To describe the structure of formal proofs we need some more notation.
The symbol $\vDash{}$ will be used to signify that the following formula of the propositional calculus is a tautology and hence a logical truth.
The symbol  $\vdash{}$ will be used to signify that the following formula is a theorem of propositional logic.

What we seek in an inference system is that it proves only truths:

\begin{center}
  $\vdash{}$A only if $\vDash{}A$
  \end{center}

which is the property of being \emph{sound}\index{sound}.

Ideally it will also be \emph{complete}\index{complete}:

\begin{center}
  if $\vDash{}$A then $\vdash{}$A
\end{center}

The inference system for propositional logic consists of a single rule of inference and a small number of \emph{axioms}\index{asiom}.
It is sound and complete.


\section{The Distribued Information Structure}

The whole could be thought of as simple a natural number, for however much information is stored across the Galaxy, the aggregation of that information will at the end be simply a number.

This is not a particularly helpful way of thinking of it, but it is a starting point.
In order for this to have any value we must be able to refer to particular parts of the information. which would be facilitated by thinking of the number as a sequence of bninary digits.
We may then address particular parts of the information by its location in the binary sequence.
Though that may help, its clearly not much help.
It would be better if we cou;d use some kind of name to refer to particular parts of the structure, and if that location and length of the sections referred to by a name to be flexible, so that changes to one part of the structure which effectively move parts if the structure do not disturb the naming of other structures to which the change would otherwise be irrelevant.

The information structure then becomes a name-space, or a mapping of names to strings of bits (or more elaborate structures represented ultimately by such strings).
Naturally we would want these names to form a structured heirarchy, along the lines of a directory structure, extended as it has been to provide a unique global nameing system as Universal Resource Identifiers, extended yet again to provide a unique naming system for a pan galactic information system.
As information systems expand across the galaxy they will in all likelyhood encounter previously unknown systems and would want to create an integrated distributed system which embraced both systems.
This could be done by adding one of the new systems as a top-level ``domain name'' in the other system, or by creating a new higher level to the heirarchy and allocating distinct names at that level to each of the participants.
This requires a naming scheme which is always relative to a place in the naming structurem. and the number of layers above is not fixed.

For this distributed system to function coherently over the very large distances which would be involved, hundreds of thousands of light years in this galaxy alone, it must be a write-once structure in which any node has only a partial representation of the structure, but it is guaranteed that no two distinct versions of any part of the structure exist.
That means that any changes to the structure create a new version of the structure leaving the older version intact.
This can be thought of as the process of updating a large information structure in a purely functional language, which works from a list of versions of the structure and computes a new list whose tail is the original structure and whose head is an amendment to the head of the old list.
There is nothing to say that an implementation of such a system or of a fragment of the system could not be accomplished by some completely different mechanism, such as a database which keeps a log of transactions (including the original values), or by the methods use in source code control systems to preserve all previous versions of the software.

That this information structure is ``write once'' is essential to the coherence of deductive closure.
If amendments were permitted to data which is referred to in some proposition without that proposition having to be reproven, then contradictions would result and the deductive system would no longer be sound.
So, when the value associated with a name is modified, any theorems which directly or indirectly mention that value would continue to refer to the old value, and only a revised demonstration would be able to refer to the updated value.

\section{Languages}

We have so far only addressed an information store.

Before we are able talk about logical truth and proof we must talk about language.

The conception of logical truth we are addressing is that known as \emph{analyticity}, as that notion was defined by Rudolf Carnap \cite{carnap47,schilpp63} and refuted by Quine \cite{quine51b,quine61a}.
Passing over that refutation, the implication of Carnap's conception of logical truth  is that logical truth is not something which belongs only to sentences in those very special languages which may be called ``logics'', but rather something which may be found in the sentences of any language which is well-defined (in its syntax and in certain details of semantics).

There is no general consensus about what a ``language'' is, between philosophers, logicians, computer scientists, cognitive scientists and linguists.
For some purposes, for example in the logician's notion of ``a first order language'', a language has a fixed vocabulary.
If new terms (known as constants) are introduced to an existing first order language, the result is a new first order language.
On the other hand, when we talk about \emph{programming languages} we speak of fortran, cobol, C, java, python... each as \emph{a} language, of which we expect normal use to consist in elaborating new algorthms, giving them names, and then using them in defining yet more named  algorithms and data structures, until in the fullness of time the functional behaviour required of the program is properly defined.
Introducing new vocabulary is the normal manner of use of these languages, but does not create new languages.

The augmentation of language in the normal course of its use usually goes beyond the mere aggregation of vocabulary, allowing flexibility in the concrete ways in which the use of the vocabulary is presented.
Thus new names for mathematical functions may syntactically appear as prefix, infix, or postfix, appearing before, between or after the values to which the function is to be applied, and may be given priorities which influence the order in which the operations are to be undertaken during the evaluation of expressions.
The need for such flexibility in concrete syntax is felt more strongly in languages which are intended for the formal derivation of logical theories, since their use may aspire to match the flexibility with which mathematical notations have been devised during the historical development of mathematics.
This may be crucial to the adoption of more formal notations by human mathematicians.
In the distant future, when theoretical mathematics is undertaken by synthetic rather than natural intelligence, the historical and continuing need to communicate with humans will make similar demands.
These are not the only issues which complicate the support for languages in our distributed information and knowledge system.

\section{Logical Foundation Systems}

At the birth of modern logic, arguably with the publication by Gottlob Frege of his \emph{Begriffsschrift} \cite{frege1879}, Frege perceived that his new logical notation and its deductive system would suffice for the formal development of arithmentic (and was more generally applicable).

At that point he offered the formula:

\begin{quote}
  mathematics = logic + definitions
\end{quote}

The approach to deductive reason proposed here is rooted in that insight.
The idea was not universally accepted because the conception of ``logic'' which it required was broader than many thought logical necessity should embrace, mainly because it involved the establishment of an abstract ontology in terms of which the mathematical definitions could be understood, which was somewhat arbitrary.

An alternative rendition which proved more acceptable (and has often been offered as a correction to Frege's maxim) was:

\begin{quote}
  mathematics = set-theory + definitions
\end{quote}

In which context the entities of mathematics, such as numbers, were to be construed as sets.

Set theory is not the only basis on which mathematics can be built in a similar manner.

Though there is discretion about abstract ontology, it may still be thought purely a matter of logic, in which there is choice of abstract ontology on which to base mathematics (and all abstract models), but the entire proceeding precede any input from the concrete world.
The philosophical position which I here adopt can reasonably be described as \emph{ontological conventionalism} and its central tenet is that abstract ontology is, like language, a choice which we are free to make, and that logical truths ensue by reasoning in the context of such a choice.
The freedom to make that choice, and the manner of making it, are not entirely without consequence.
The choice of ontology for a foundation system may be made in two different ways which must then be closely connected.
There may be a \emph{semantic} choice in which an informal description of the domain of abstract entities is described in terms not necessarily capable of rendition in an already defined formal notation, and there may be a more formal rendition as axioms in the logical language of the foundation system which admits the formal derivation of truths about the system, but may not be complete in proving all the sentences which are true in the intended and informally described domain.
It is very likely that no single domain is intended, but that several alternative interpretation of the axioms exist and that no single interpretation is given a special status.

A logical founation system is a logic together with a copious abstract ontology in which the main body of mathematics can be derived given suitable definitions of the concepts involved.
We do not expect any such system to be universal, but there are systems which admit of augmentation by the addition of further ontological premises, such that it is plausible that any coherent logical theory could be accomodated gived an appropriate extension, and in which sufficiently strong ontological principles are readilty identified so that practical applications are unlikely to require firther augmentataion of the ontolgical premises (even though some questions about the ontology may never be conclusively settled).



\phantomsection
\addcontentsline{toc}{section}{Bibliography}
\bibliographystyle{rbjfmu}
\bibliography{rbj2}

\addcontentsline{toc}{section}{Index}\label{index}
{\twocolumn[]
  {\small\printindex}}

%\vfill

\tiny{
Started 2022/11/19

\href{http://www.rbjones.com/rbjpub/www/papers/p049.pdf}{http://www.rbjones.com/rbjpub/www/papers/p050.pdf}

}%tiny

\end{document}

% LocalWords:
