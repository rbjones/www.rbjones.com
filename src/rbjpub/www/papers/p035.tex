% $Id: p035.tex $ﬁ
% bibref{rbjp035} pdfname{p035}
\documentclass[10pt,titlepage]{article}
\usepackage{makeidx}
\usepackage{turnstile,amssymb}
\newcommand{\ignore}[1]{}
\usepackage{graphicx}
\usepackage[unicode]{hyperref}
\pagestyle{plain}
\usepackage[paperwidth=5.25in,paperheight=8in,hmargin={0.75in,0.5in},vmargin={0.5in,0.5in},includehead,includefoot]{geometry}
\hypersetup{pdfauthor={Roger Bishop Jones}}
\hypersetup{pdftitle={Oracular AI}}
\hypersetup{colorlinks=true, urlcolor=red, citecolor=blue, filecolor=blue, linkcolor=blue}
%\usepackage{html}
\usepackage{paralist}
\usepackage{relsize}
\usepackage{verbatim}
\usepackage{enumerate}
\usepackage{longtable}
\usepackage{url}
\newcommand{\hreg}[2]{\href{#1}{#2}\footnote{\url{#1}}}
\makeindex

\title{Oracular AI}
\author{Roger~Bishop~Jones}
\date{\small 2023-08-08}


\begin{document}
%\frontmatter

%\begin{abstract}
% In the context of LLM popularity despite their inability to distinguish truth from fantasy, here is a fantasy of my own about how they can be made very highly reliable within the domain of analytic truths.
%
%\end{abstract}
                               
\begin{titlepage}
\maketitle

%\vfill

%\begin{centering}

%{\footnotesize
%copyright\ Roger~Bishop~Jones;
%}%footnotesize

%\end{centering}

\end{titlepage}

\ \

\ignore{
\begin{centering}
{}
\end{centering}
}%ignore

\setcounter{tocdepth}{2}
{\parskip-0pt\tableofcontents}

%\listoffigures

%\mainmatter

\section*{Preface}

\section{Introduction}

Alongside the enthusiasm for the largest of the Large Language Models initiated by the release of \emph{chatGPT}, the ways in which these models fall short of the ideals of General Artificial Intelligence have come into focus, and the discussion of the associated risks has been more intense, if not more informative.

LLMs were not intended to solve the problem of AGI, the are ``generative AI'', not designed as accurate or reliable stores of knowledge, or to have competence in reasoning or mathematics.
The following discussion is about what might be achieved if the capabilities of LLM's adapted to address some of desiderata around reliable retention of knowledge and reasoning about that knowledge.

The term ``Oracular'' AI is intended to suggest a kind of AI which can be completely relied upon to speak the truth, and which has a completely reliable deductive capability which exhibits that same kind of scale relative to the ability of homo sapiens as a supercomputers ability to do arithmetic calculations exceeds that of humans.

\subsection{Contextual Speculation}

The following speculations are not the point of this essay, but may help to make intelligible the ideas which follow.

Public speculation about how LLM technology might progress has include the following two very general approaches:

\begin{itemize}
\item Giving Large Language Models (LLMs) direct access to tools.
\item Integrating LLMs with other approaches to the development of AGI
\end{itemize}

Most of the intelligent beings which now exist are slow and unreliable by comparison with algorithms running on digital computers in very many kinds of problem.
There is no reason to expect that Artificial Intelligence will change that situation.
Sometimes there is an efficient algorithm and that is the best way to solve the problem.
Once an ``AI'' has access to such tools, then it will use them in preference to its own machinations.

Most of the great accomplishment, perhaps all, of the greatest intellects in history are but one stage in the development of knowledge and skills by an entire culture over long periods of time.
Large engineering enterprises involve very many intelligent designers collaborating to create and refine clear statements of requirements, design, coding and details of the physical and logical structures necessary to meet the requirement.
Most of these contributors will have specialised in some aspect of this process and could not effectively contribute in areas which are too far removed from their speciality.

Nevertheless, AI marches forward toward a goal of complete generality.
That generality might be thought of as being capable of specialising to any area given appropriate training, but even that would exceed the kinds of intelligence which homo sapiens exhibits, for our gene pool is diverse and different individuals have the aptitude to perform well in distinct domains.

The direction of movement which we perceive in some of the most complex feats of engineering design is toward better support for collaboration between even larger distributed teams.
The most prominent manufacture of digital hardware intended to support AI, Nvidia, provides an environment called ``the Omniverse'' in which a complete factory can be designed and simulated, making the most of AI, and through which a widely distributed development team can work together to advance the design.
In such an environment the behaviour of each part of the manufacturing system can be simulated, and the simulated environment can be used to train the software for robots intended to participate in the running of the factory.

As AI becomes capable of contributing to such projects it may at first be directly used by human designers to help them accomplish their part of the work, but later we may expect AI agent to act on a par with human beings, seeking help as necessary, subject to review by the normal processes.

Alongside the Omniverse, Nvidia promotes the idea of ``digital twins'', which are abstract computational models of physical systems.
These models may serve various roles throughout the life cycle of the systems, appearing at first before the construction of the physical counterpart, enabling comprehensive testing verification and mutli-faceted evaluation prior to manufacture, and subsequently tracking the state of their physical instances to facilitate control and maintenance.

\subsection{A Safe Zone}

One aspect of making AI safe is simply making it more reliable in distinguishing truth from falsity.
This does nothing to prevent malfeasance, but a large proportion of pre-AI safety concern addressed the prevention of accidental rather than deliberate harms.
A safe car is not one which will refuse to mow down pedestrians, it is one that will not do so unless its driver intends it, or is incompetent or culpably negligent.

Even this kind of safety is hard to guarantee, and potentially becomes harder as AI permeates the workings of the world.

It may therefore be comforting to know of important domains in which conclusively establishing the truth is feasible (and customary) and in which even greater assurance of truth can be realised with the help of computers and in the context of artificial intelligence.

This is the domain of deductive inference, and logical truth.
It is the purpose of this essay to mention some of the well known ways in which these truths can conclusively be established and to add some ideas which may be less widely appreciated.

If deductive inference were to be automated so well that very lengthy deductions could be reliably conducted and subsequently depended upon, then the context in which those deductions are undertaken is important.
First it is necessary for the meanings of the language (or languages) involved must be clearly and precisely understood, for reasoning and comprehension is otherwise compromised.
Second, it is necessary that the context in which deduction is undertaken is coherent, for otherwise a contradiction may be proven and from that contradiction any conjecture, true or false, will be derivable and proof will confer no confidence.

The verification of engineering design is an important potential application for AI powered deductive inference.
But the reasoning involved must make use of a large body of mathematical and scientific knowledge, it must take place in the context of 
mathematical models of the designed artefact and the context in which it is required to operate.


\subsection{Some Observations on Intelligence}

We know well enough how intelligent beings go about extending our knowledge of the world and applying that knowledge to various practical ends.

Two pervasive features are:
\begin{itemize}
\item The gathering of knowledge is cumulative and cooperative.
\item The knowledge is a shared resource mostly held in media external to the intelligent agents involved.
\end{itemize}

I suggest that this is unlikely to change with the advent of AGI.
So it it likely that the AGIs will be cooperating with other intelligent agents in the continued accumulation of knowledge stored in shared distributed media a large part of which is freely accessible to all.

These are some features of intelligence which I expect to persist as AGI progresses.

Nevertheless there will be important and substantial changes.
In the past, it has been fairly rare for a new area to be automated by computer without significant changes in how it is done.
A simple example of this is the very different expectations we have of the reliability and scale with which arithmetic computation can be performed one digital computers were available.
In many more cases, it is not just the greater reliability and speed which matters, something which was hitherto infeasible may be rendered commonplace.

Another area in which computational machinery has outstripped prior capabilities is in memory.
Very large quantities of information can now be reliably stored, perfectly retrieved, swiftly searched and processed in some way.

In these terms, the current crop of LLM's are a regression.
They were not intended to perform well in any of those ways, they were intended to process languages, and having exhibitied surprising ``emergent capabilities'' are now sometimes judged as if they were intended as AGI.

Much of the effort invested in AI research aims to replicate the kinds of intellgence exhibited by humans, rather than aiming at superior performance in areas of practical importance.
Though early in the history of AI research the automation of formal logical theorem proving was not only an important domain of AI research, but was considered by some to be the route to a general intelligence, it later was outflanked by simulating the brain as neural nets and common sense reasoning became the aspiration.

In the following speculations I am concerned with how to enable GAI which is as reliable as possible in all domains, approaching this by focussing on the kind of reasoning which we can reasonably expect to be made wholly reliable.
This includes reasoning in mathematics, science and engineering.

In these domains, deductive reasoning has a very important role.
It may be said to be almost the whole of pure mathematics.
We may also speak of the nomologico-deductive model of science, in which the evauation of scientific hyotheses or the application of accepted theories is undertaken by deduction from those theories and the particulars of the case in hand.
Engineering is then merely a collection of application of science in which the process of verification of a design against some statement of desiderata is one of logical deduction.


My aim here is to sketch a tool for use by LLMs and other AI as a way of guaranteeing that the kinds of deductive reasoning which they might effectively deploy can be guaranteed sound.
The importance of this cannot be underestimated, due to the difficulty in containing infidelity.
Once a falsehood has been proven a contradiction is not far away, and armed with a contradiction all proofs whether of truths or of falsehoods become very short and completely worthless.

My description of the proposed logical tool will come in several stages, growing more complex as additional desiderata are introduced and address.

In the first instance the tool could simply be the logical kernel of en existing Interactive Theorem Prover, which for reasons which I hope to make clear should I suggest support formal deduction in the variant of the HOL logic devised at the University of Cambridge, originally for reasoning about digital hardware.


\subsection{Alternate Paradigms for System Development}

The approach to systems development exemplified by digital twinning and the Omniverse centres around computational simulation, accelerated and enhanced by AI.

This is an effective approach which we may expect to be progressed and advanced.
It retains the limitation which has always attended verification by testing, notwithstanding the scope for testing coverage improvement by AI.

It a very sophisticated for of informed guesswork.

The best way to ensure compliance of a design with a requirement is by logical analysis, which has been a distant ideal for decades.

\subsection{Language, Knowledge and Models}

Mathematics, science and engineering design and implementation involve a large body of knowledge presented in many distinct languages as well as the statements of requirements and descriptions of design and implementations, construction of one or more formal or abstract models of the

\section{What is an Oracle?}

The word has a variety of usage, so best to be clear about what is intended here.
In ancient Greece it was a mouthpiece for deity, and therefore had not only wisdom but any other characteristic one might attribute to someone with a direct line to God.

Skip, doubtless, many intervening subtleties, and arrive in the twentieth century not so long after mathematicians got into logic (a century is nothing in the scale of these things) and we find that the notion of oracle gets a place in recursion theory, i.e. the theory of effective computability.

In that theory, after the concept itself was precisely and convincingly defined, the next step (for which purpose the concept had been introduced) ws the demonstration that not all numerical functions were effectively computable.

This problem was addressed through the idea of a decision procedure for a set of natural numbers, and it was shown that some sets were not effectively decidable, and hence that their decision problem was ``unsolvable''.
It further transpired not all unsolvable sets were equally unsolvable, but that they could be classified according to their degree of unsolvability.
These degrees were defined through the concept of reduction, in which the decision problem for a set A is reducible to that of a set B if, given an oracle for set A the decision problem for B could be soled.
The notion of oracle for a set A is quite simple here, it is simply something which will tell you of any number whether or not it is in the set A.

There are no vague notions of wisdom in play here, calling something an Oracle for B just tells you that it has the answers to a particaular set of questions.
The idea of Oracular AI discussed in this paper is primarily that of an AI, which is, over some well defined class of problems, able to give the correct answer.

I have to make one retrenchment to that, in acknowledgement of the incompleteness result first discovered and proven by Kurt Godel.
There is also a related issue concerning semantics, which I suppose we might think connects back to Tarski, that the set which I will seek to characterise here as the domain in which Oracular AI might be an Oracle cannot be precisely defined.

With those two caveats the aim of this essay is to argue that corresponding to Hume's ``fork'' there is a domain within which we can reasonably expect AI's to be Oracle's.

\pagebreak
\phantomsection
\addcontentsline{toc}{section}{Bibliography}
\bibliographystyle{rbjfmu}
\bibliography{rbj2}

%\addcontentsline{toc}{section}{Index}\label{index}
%{\twocolumn[]
%{\small\printindex}}

%\vfill

\tiny{
Started 2023/07/28


\href{http://www.rbjones.com/rbjpub/www/papers/p034.pdf}{http://www.rbjones.com/rbjpub/www/papers/p035.pdf}

}%tiny

\end{document}

% LocalWords:
