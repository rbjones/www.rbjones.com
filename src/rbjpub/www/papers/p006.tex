% $Id: p006.tex,v 1.1 2005/01/26 20:53:38 rbj Exp $
\documentclass{rbjk}

\begin{document}                                                                                   
\begin{article}
\begin{opening}  
\title{Philosophical Themes}
\runningtitle{Logico-Philosophical Themes}
\author{Roger Bishop \surname{Jones}}
\runningauthor{Roger Bishop Jones}

\begin{abstract}
An exhumation of the ideas which have engaged me throughout my life, so far.
\end{abstract}
\end{opening}

\tableofcontents

\section{Introduction}

THe purpose of this document is to present the themes which I ``worked upon'' over the last 40 years or so, to help me decide what kinds of things I want to work on in the future.

The presentation is historical, the various ideas I have worked on are presented in the order of their occurrence.
The themes which tie these ideas together as separately discussed by reference to the main account.
In the next section the themes will be described partly by reference to the third section in which the individial stages in the development of these themes are described.
A final section will look to the future.

\section{Themes}

The themes are:
\begin{description}
\item[Artificial Intelligence]
\item[Foundations]
\item[Philosophy]
\end{description}

\subsection{Artificial Intelligence}

\subsection{Foundations}

\subsection{Philosophy}

\section{As it Went}

\subsection{God - 1959-1960}

When I started boarding at Skipton Grammer School I had to spend more time listening to sermons on Sunday.
Ever a poor listener I thought about things, and in particular about the nature and existence of God.
This is the first ``philosophical thinking'' that I can recall, and after thinking about what God might be I eventually concluded that God did not exist.
This thought process must have been completed within the first year because when at the beginning of the second year I was asked whether I wanted to start preparation classes for confirmation I declined, and did so not because I had doubts, but because I had no doubts.

My greatest difficuly in coming to my conclusion, was in understanding how it could be if God did not exist, that so many eminent and respected people seemed to think he did.
Much later I was enlightened on this matter by the books of Howard Bloom.

\subsection{A Thought at Cambridge - 1966-67}

I was at Cambridge as an undergraduate reading Mechanical Sciences for just one year.
I didn't much care for the engineering but was taken with the IBM11130 which they had installed in the Engineering Laboratories, partly for teaching undergraduates.

We were taught how to program in Fortran II, and prohibited from using assembly language (this was not a multiprogramming system and there was no limit to the damage a user program might do).
Somehow I figured out how to assemble a program into a fortran array and then contrive (by using negative indexing in the array I think) to overwrite the fortran program so that on exit it jumped into the array.
By this means I was able to try out interesting things whicn couldn't be done in Fortran, like getting red ink on the printer.
This was a paper tape machine and the program and data tapes were punched up using these things called ``flexowriters''.
Sometimes they were in such great demand that the computer itself would be sitting idle but all the flexowriters were in use.
So I wrote a fortran program which turned the computer into a flexowriter.
However, since it was in Fortran when a tape was read, tabs were converted into spaces, but when a tape was punched the reverse effect did not take place.
When the computer was used as a paper tape editor, the paper tape got much larger, because all the tabs were converted into multiple spaces.

This provoked the first thoughts which I can recall about AI.
The editor was introducing redundancy, and I thought about eliminating redundancy.
I decided that if you could write a program which would take a large set of true statements and code the documents up in the least redundant way possible, so that the paper tapes seemed completely random, then by feeding random numbers into the inverse of the compression function, you would get out random true statements.

OK so this is a completely and hopelessly naf idea, I never tried to implement it, and it obviously wouldn't work.
Fortunately, I don't think it is representative of the character of my subsequent thoughts about AI, though thoughts about AI don't usually actually work, some of them are not quite so easily dismissed.

\subsection{Philosophy of Life c1968-1970}

After leaving Cambridge and taking a job in Computing I found myself living in bedsits in strange place with raging hormones wondering why I got depressed and what to do about it.
This provoked a certain about of thought, of the kind which might be called ``philosophy of life'', or, how to be.

I went through a number (can't remember what number) of ``philosophies'' to which I gave names, and tried each for size before deserting it for the next.
The two I remember were the early ``rationalism'' which was an attempt to persuade myself that I should really do whatever it was that I had rationally decided would be best for me, and anarchism which was more of less a capitulation to the fact that I just don't do that.
Of course, anarchism is really the name of a policital philosophy, but I used it (at least in my head) for a personal philosophy for a long time, and felt that there should be some fit between the personal and the political (the way you treat yourself, the way you treat others, and the way you think the state should treat people ought to fit together).

Anyway, this was the period in my life when I worried about this kind of thing, and then settled into and gradually forgot this thing that I thought of as anarchism, and which amounted to self-trust.
Just do what you do.

I did have many subsequent periods of soul searching, even to the point of suicidal depression.
But actually, they were mostly provoked by women, or the lack of them, and they didn't result in this same kind of ``philosophical'' thinking.
There was one more period of crisis which seems to me similar, and which I hope has just now drawn to a close.

\subsection{Russell and Logical Positivism - 1970-71?}

Eventually I went back to University and read joint mathematics and philosophy.
I did do some philosophical reading before that, and must have thought about this, but I have no recollection of these thoughts.
However, many years later I noticed that I had a philosophical position which seemed to be at odds with contemporary philosophers, and eventually concluded that it must have been largely formed by during the philosophical reading which preceded my return to University.
Of these the most significant readings I guess were Bertrand Russell, notably his history of Western Philosophy and his Introduction to Mathematical Philosophy, and Ayer's Language Truth and Logic.

\subsection{Foundations - 1971-2}

I spent five years in the computer industry before returning to University at Keele.
Toward the end of this period, I was retrieving papers by Church and Turing and others from via the company library in company time, and had some story about why this was relevant to my work which I don't think my boss (John Dawes) actually believed, though he didn't seriously object.
I can't remember what the story was, but it must have been pretty tenuous.
I had a think about floating point representation of real numbers, and thought at that time that it was a mistake that the theory of real numbers was not more constructive, blaming that for the use of floating point numbers for reals.
This must have come from Turings stuff about computable reals.

Since than I have always had a leaning toward better computational support for computable reals, but have never actually done anything significant about it.
These days it seems to me essential for the application of proof technology in building correct software for doing mathematical analysis.

\subsection{Foundations - 1972-5}

I arrived at Keele University already knowing something about formal mathematical reasoning, already with some kind of a bee in my bonnet about proof.
I know this because when I started doing mathematics properly (in the second year, since Keele had a foundation year before one could specialise), I did some of my exercises with fairly detailed formalish proofs.
Presumably this didn't last very long since there isn't much university mathematics one can hope to do that way, but my notes are now lost.

The first ideas I can recollect about the foundations of mathematics concerned Principia Mathematica.
I acquired the paperback of the Principia ``to *56'' and devoted some time to it.
It seemed to me a bit unclear and I thought it would be useful to define the logical system formally.
This was my first grapple with a kind of regress problem, and I decided that one should define the logical system using the very simplest language in which it could possibly be done, so that there was no real danger of that language being misunderstood.

That language seemed to me to be the language of post productions, of which I had learned from Marvin Minksy's book ``Finite and Infinite Machines''.
For a while this was to be a dissertation for the philosophy department, but eventually I decided that it wasn't going to work out.

It was purely about syntax, and at this time I had no idea of semantics.
It doesn't any longer seem to me problematic to define the syntax as precisely as we wish, and its clear that the way to do that is not to chose the simplest possible notation for the purpose.

By the time I got to the end of the degree I had some definite ideas for reasearch relating to the foundatiosn of mathematics.
One was that I wanted to work on computerised formalisation of mathematics.
The kind of thing which was actually being done round about then in Edinburgh (except that their logic LCF was a bit to weak, though it would eventualy be traded up to HOL).
The other was to work on support for use of computable reals.
I don't believe that I had any original ideas on how these were to be done.

\subsection{Philosophy - 1973-5}

I did half a degree in philosophy, part of which was mathematical logic and the philosophy of mathematics.
I was not a good philosophy student, I was more interested in working things out for myself than in studying the works of other philoophers, and quite unsuited to the latter.
In the examinations one was expected I think even when asked a question about some particular problem without reference to any other philospher, to show some knowledge of what other philosphers had said about the problem.
I think the model answers were demonstrations of scholarly knowledge peppered with small amounts of original analysis.
However, I didn't have the scholarly knowledge and I was pretty slow.
I liked to think about the problem posed and come up with a position on the spot, with no more reference to other philosophers than could be avoided.

I recall an obscure conversation with Jonatham Dancy on a bus during the period after taking the exams but before getting the result.
He said that for the philosophy I had been on the list of those considered for viva (meaning that I was on a borderline), but that they had decided against giving me one.
He said he had argued that the style of the essays should be taken into account, evidently he thought this a strong point, but there just wasn't enough {\it content} so they wouldn't have it.
I think Dancy thought he was telling me something from which I could conclude that I would be getting a first overall (to get a first in a joint honours you needed a first in one subject but only an upper second in the other) and he must have heard enough about my maths to think that I would have no doubt about a first in mathematics.

I digress, mainly to suggest that {\it originality} is in my blood.
Not in the laudatory sense of having meritorious ideas which noone else has had.
In the sense of ignoring what has been done before and thinking things out from scratch.
Creating some solution of my own, not necessarily new to the world, not necessarily of outstanding merit.
Originality as a bad habit, or a pathology, like autism.

As far as ideas from this time which still have something for me, I can remember the following:

\begin{description}
\item[words] I didn't like the idea that philosphy was just about words.
In fact I didn't like the idea that philosophy was about words at all!
I even made an attempt to articulate methods for disengaging from the meaning of words, this in an essay in political philosophy.
I was particularly unimpressed by the philosophy of Wittgenstein, both the early and the late.
\item[politics] I wanted to talk about anarchism, as a political doctrine.  I don't think I got anywhere but the attempt was also my first attempt to wriggle out of entanglement with words.
\item[ethics] possibly my worst essay was on ethics, consdering the question ``Is morality necessary''.
In fact this was bound up with ``anarchism'' as I construed it.
\end{description}

\subsection{Expert Systems in Decision Support - 1982}\label{1982}

I wrote this paper while working on microcode architectures for mainframes (CME), when I had decided it was time to move on.
The paper was never published, never even submitted for publication so far as I recall, but did help to get me a job in ICL working with expert systems.

\subsection{Knowledge Bases - 1985}

In 1985 I moved from expert systems (not impressed) to database management software.
While working professionally on relational database software I thought privately about knowledge bases.

This topic combines an interest in AI with one in foundations, which is typical of my interest.
I thought up an architecture and made some steps toward implementing it on an ICL PC (with a Z80 processor).The starting point for this is the idea that intelligence involves reflexive reasoning, so an artificial intelligence should be a self applicative piece of software.
To make it easy to reason about itself, this should be in a nice functional language, and at this time the state of the art in implementation of functional programming languages (embodied in Miranda) used combinators.
So the knowledge base is a combinator, part of which is a program which takes the knowlege base (including itself of course), as an argument, and computes a new value for the knowledge base,
Actually, it was to be a worm, not overwriting the database but continually adding new versions of it to a list, the space cost being mitigated by the sharing one gets for free in functional systems.

The foundational element comes in when you start considering the combinator which is the knowledge base not as a data structure but as a proposition, and want to take the computations which update it not as mere computations but as inferences.
So what kind of a logic do we want for this?
Well, the self applicative bit made me think that this had to be a type-free system.
It was going to be reasoning about a function which was to be applied to something which contained itself.
The obvious answer to this need seemed to be combinatory logic, about which I knew next to nothing.
So that's how I got interested in combinatory logic, and how I resumed thinking about the foundations of mathematics.

Somewhere in this period I went to a workshop at Appin in Scotland which was sponsored by ICL and was on persistent databases, so I wrote this paper:
``Persistent Applicative Heaps and Knowledge Bases'', as my offering (which was a bit irrelevant since I was really there because ICL was paying).
I also got a slot to talk.
After hearing the tenor of the papers I sensed a concensus with which I disagreed, which was that languages with persistent storage had to have dynamic type systems.
I decided not to talk about my paper at all, but instead to argue, on the fly as it were, the falsity of this common ground.
The argument was along the following lines.
We would expect none of these programs to raise type errors during execution.
We would expect this to be provable.
It must therefore be statically determinable, and this static determination could be built into a type system.
Of course, I don't really remember the details of my argument, my memory isn't that good.
But I still think there is a case that this is possible.
Possibly not with a decidable type system, but the main point was not to advocate a static type system but simply to challence the assumption that a dynamic type system was essential.
My talk caused an uproar and I loved it.
Like so many conferences and workshops in computing the average talk went by with very little if any comment and no serious discussion.
I livened up the proceedings considerably.

Some of the academics talked sympathetically to me afterwards, clearly thinking I had been through a terrible ordeal, which I must be regretting.
I wasn't, I was very pleased with it all.
Not that the discussion was wonderful, I only had something like twenty minutes, and the discussion had to be curtailed.
But my presentation on was quite brief, and it caused instant uproar.
In fact, discussion had to be curtailed simply so that I could complete the presentation of my argument (most people wanted to object without actually hearing the argument).

Its not that I crave infamy, but it was all pretty stodgy up 'til then.

\subsection{Creative Foundations - 1986}

Having decided that combinatory logic was the appropriate foundation system to use in a ``knowledge base'' I was disappointed to discover that combinatory logics, when they were consistent were weak, I spent
some time trying to devise a consistent and strong illative combinatory logic.

The first red herring on this trail was the idea that the coding of recursive functions in combinatory logic could be exploited to yield a strong system.
Noone understood the idea, not even well enough to tell me why it was a duff one.
I wrote two essays before I figured out what the problem was.
The first was ``Logical Foundations and Formal Verification'' which was presented at an Ada Verification workshop in South Carolina, but possibly not included in the proceedings.
The second was ``Creative Foundations for Program Verification'' which I thought a really neat paper, and was published in the proceedings of Milcomp86 a military computing show with a pretence at being a conference.

It wasn't till I had some conversations with Peter Aczel and tried to explain it to him that the penny dropped for me.
He asked me what was the proof theoretic strength of the system, and I said it didn't really have one.
He also spent some time explaining proof theoretic strength to me, and explaining some of his systems to me.
However, I was looking for something particular, and he took offense I think that I said that his systems were not quite what I was looking for.
I think he was thinking of me as if I was one of his students, and students it seems don't do that kind of thing.
I think they are supposed to be more like disciples.

This was for me I believe a very instructive error, though its still hard to explain exactly what was the error (mainly because its hard to make clear the rationale which made me think that the ``creative theory'' was a foundation system.

After this I continued to think about reflexive foundation systems, particularly in combinatory logic, and went down quite a few blind alleys.
This only stopped when I got deeper into well-founded set theories and concluded that what they offered was really the neatest kernel of the foundational problem, and that reflexivity if thought desirable could be done somewhere other than the foundations.

I now think that reflexive foundations if we really want them may be best approached via set theories with a universal set.
These contain well-founded sets as well as ill-founded ones of course, and it seems that you can make them as strong as you like by talking about the well-founded part.

\subsection{Well Founded Foundations 1988}

In 1988 I was for a while assigned as ICL's representative (and the secretary) on the VDM standardisation panel.
VDM was a formal specification language with a kind of domain theoretic semantics, which came from Brian Monahan.
I had an agenda which I had been pressing for a couple of years which said that specification languages should be foundation systems, and that ideally foundation systems should be reflexive.
Well VDM and Z were both well founded specifation languages, but the former was not really much of a foundation system so far as I could see.
Ontologically it did have a heirarchy of types progressing through a function space constructor.
But the function spaces were spaces of continuous functions, good enough for modelling higher order computable functions, but not for mimicking higher order logic.
So VDM looked to me rather like a first order logic, an elaborate version of LCF, to weak to do serious mathematics.
I don't know whether I was right about his, possibly not.

Anyway the problem of finding a foundation system which was suitable both for Z and for a strong VDM seemed interesting.
It seemed to me that the key problems to be solved relative to the known well-founded foundations such as ZFC and HOL, were the need for polymorphism and the need for structuring.
Structuring relates both to local definitions (which don't work in HOL in the way that they do in ML and in which one needs them to work in any serious specification language) and to support for modularity.

The game plan for this work was to do the work from semantic models in Cambridge HOL.
First axiomatise ZFC in HOL (not worrying about the fact that the result would be strictly stronger than the first order version).
This gives a rich ontology within which ontologies of the desired systems could be constructed.
Then three theories were to be constructed in turn.
The first was to change the ontology from an ontology of sets to one of functions.
This is done, roughly, by taking the heriditarily functional sets from the domain of ZFC in HOL.
There were some tweaks to this to make the resulting theory of pure functions extensional.
The way I worked with this was to define a new type based on these pure functions, define various operations over these functions, think up an axiomatisation of the theory and prove the ``axioms''.
The adequacy of the ``axioms'' could then be established by doing the reverse construction, going back to the theory of sets using a ``hereditarily'' subset of the pure functions which mimics the sets of ZFC in HOL.
I didn't to the last bit, and I didn't complete the proofs of the proposed axioms.

The next two theories were the theory of polymorphic functions, and that of ``structured functions''.
A polymorphic function was a function over the pure functions, in which the functions in the domain are interpreted as assignments of types to type variables.
So they are families of functions indexed by ``type'' assignments.
I should mention that this is all really ``type free''.
I'm heading for something like an illative combinatory logic except that it isn't really reflexive.

There is just an illusion of reflexiveness of the kind you get in a polymorphic type system.
To explain this another way, the idea is like HOL without the types.
Its like HOL in that everything is in the semantic domains, all the logical oonnectives and quantifiers, unlike first order logic in which there is a distinction between terms and formulae and only the terms denote values in the semantic domain (the domain of an interpretatio).
To do this in HOL without running into consistency problems you have the type system.
In the proposed system you don't actually have types, consistency is realised through well-foundedness.
There is no type system, but the well-foundedness gives you the same problems that you get with a type system, which is why we still have polymorphism.
The problems here are the problem of the non-existence of functios you would like to have, like the identity function, the equality predicate, and of course the quantifiers.
So we settle instead for families of functions.
e.g. the family of identity functions retricted to some domain.
The family of restricted quantifiers.

The ``structured functions'' where polymorphic functions defined in contexts where various identifiers are thought of as external, perhaps because they are defined in some other module, perhaps because they are defined in some local definition.
The value of the polymorphic function depends upon the values of some identifiers in relevant context.
The context is again represented by a function, which is understood as a map from names to values.

To make this work you need some constraints on the function spaces which are used to represent the polymorphic and structured functions.
I didn't progress this work far enough to be sure what the necessary conditions are.

This work petered out for several reasons, firstly there was an influx of theoreticians from Denmark into the standardisation process sponsored by Dines Bjorner, who had there own strong sense of what should be done with the semantics of VDM which was quite different from my ideas.
Second I was taken off the VDM work and John Dawes was put back (for reasons nothing to do with me).
Thirdly, doing all this formally would have been to large an undertaking.
This was one of a long series of formal experiments from which a little is learnt but which could not hope to be completed with the kind of effort available.

The idea of making novel well-founded foundation systems by filtering the sets of ZFC was however one which I think is quite fun.
I also have tinkered with category theoretic foundations in the same vein.

\subsection{Stealing Proof Theoretic Strength}

Before I gave up on non-well-founded foundation systems the method I was thinking in terms of stealing proof theoretic strength from ZFC.
The idea is to start with a weak illative combinatory logic which includes a weak arithmetic with standard semantics (i.e. the numbers really are the natural numbers).
Then you strengthen it by adding more arithmetic truths, one obvious contender is the one which says that ZFC is consistent.
There is a result of Feferman's which isn't proved in this context but which one could hope to make work in this context.
It says roughly that if you add to Robinson's Q an axiom stating the consistency of some other first order theory then that theory becomes interpretable in the extension to Q.
Consequently adding the consistency claim gives you all the proof theoretic strength of the system you assert consistent (plus a bit).

\subsection{Embedding Z in HOL - 1990-1993}

This was one of the few good ideas which I had which actually got implemented because I got a team at ICL to do it!
The result was ProofPower.
Not a startling idea, obvious but effective.

\subsection{Philosophical Revival - 1994 onwards}

In 1994 I got my first web site after struggling some time to get web access through ICL, it eventually happened, and with the web access came through a backdoor an external website.
In the Finnish arm of ICL I found an outfit which had an externally visibile website, contrary I think to ICL policy on firewalls, and which was willing to cross mount webspace on one of our Sun workstations, making it externally visible.

The primary purpose of this was to put up information about ProofPower, but I also put up my own personal wenspace, which was philosophical.
I did some experiments with converting philophical classics into hypertext, of which the modern ancestors (actually not a lot different) are now on rbjones.com.
The hypertext classics are not significant.
What was significant was the gradual revival of my philosophical thinking, beyone the scope of the foundations of mathematics.
This was a very tentative process, evident initially only in the few extended periods away from work (i.e. vacations).
Its possible to persue technical problems in private time (though I can't say the results are spectacular, this is what I have done all my life), but it was much harder to take up philosophy on that basis.
I don't actually know when this started, but it was very roughly at the time when I started experimenting with the web.

At the time I got into hypermedia I was very taken by it and utterly convinced that it was the right medium for me.
It has taken very many years for me gradually to come to the conclusion that I was wrong.

1994 was also the beginning of the end for the formal methods team in ICL.
CESG was running into problems with some of its high security developments and soon there was to be a change of policy and they would simply stop funding this kind of R\&D.
The hole was partly plugged by safety critical applications but there was not enough of this to keep the formal methods unit going.
The honeyoon period for the Defence Technology Centre was past, and the focus was once more on profits. not research.

In 1994 I volunteered for other kinds of work, in the hope that a slimmed down formal methods team would have have a better chance of survival, and believing that such a slimmed unit would have to be headed by someone less senior than myself to be cost effective.
For me that was the end of interesting work at ICL, and I decided that on my fiftieth birthday I would go it alone in the hope of finding something more congenial.
I then had the sense that I wanted to write, but I had a pretty fluid sense of what I wanted to write.
Philosophy, software, ...
What I really wanted to do was to find a way to earn a living from creative activities.
In particular from doing what I though a good idea rather than what someone else thought a good idea.
I had this sense of being handicapped throughout life by this dichotomy between what I was paid to do at work and the more interesting things which I attempted in my own time.

Attempting this at the age of fifty had the additional advantage that I could fall back on a pension from ICL.
I did this rather faster than I expected to because the year following ICL changed the rules in a way which gave me an incentive to take the pension sooner rather than later.
Gradually the revenues that I was then able to obtain, first from contracts with ICL and later with contracts from Lemma1 has petered out so that we now live on two pensions between us.

From when I left ICL to the present moment is now a period of seven years in which I have failed to get things in order.
I have had what I now think of as ``philosophers block'' (if one can be said to have that without any sign of ever having a philosophical capability which might have been blocked), the beginnings of which were almost immediate, and which may just possibly be now disappearing.
Nothwithstanding this ``block'' there has been quite a bit of intellectual and philosophical development during that period which is hard to trace chronologically.

For me it is important however, to exhume at least some of this stuff, so I shall attempt it in the following without worrying to much about the chronology.

\subsection{Artificial Intelligence}

A major theme in this period has lain on the boundaries of artificial intelligence and formal mathematics.
This began with something I called ``Engineering Logic'' and progressed first though ``The Global Superbrain'' to ``X-Logic'', all different takes on essentially the same theme, and all engineering projects bound up with philosophy.

I was not attempting to do philosophy when I started ``Engineering Logic'' but I was then seeking to put forward an archicture for, and an approach toward artificial intelligence which was primarily rooted in producing software first which would not be intelligent, in framework which might eventually lead to intelligent software.
The rationale for this framework could not be explained without getting into philosophy, and the philosophy proved awkward to explain, becuase it was old fashioned philosophy, closer to logical positivism than to anything which philosophers did at the time.
It was based on tenets which seemed generally discredited (especially in the marginal world of online philosophising).

I'm going to say what I can about the engineering side of this in this section, and deal with the more philosophical aspects later.

\subsubsection{Intelligent Logic}

The idea of engineering logic is simply the idea of automating engineering design through formalisation.
This kind of work, not itself conceived of as artificial intelligence was intended to form a basis on which intelligent capabilities might later be established, but which was {\it just} a special kind of software engineering, in which logic is applied first to the formalisation and automation of mathematics and thence to science and ultimately to engineering.

Underlying this of course is a story about how one ideally can formalise science and engineering which is in spirit if not in detail similar to what logical positivists such as Carnap were engaged in, inspired to a significant extent by the prior work of Russell in the formalisation of mathematics in Principia Mathematica.
Intelligent logic is intended as an ``intelligent'' overlay on engineering logic.

\subsubsection{Global Superbrain}

This is the second in three stages of evolution which began with the Engineering Logic.
The tag ``Global Superbrain'' ties in which various other speculative notions only tenuously related.
My own conception was divided into two parts which I called the analytic and the holistic superbrains.

The analytic superbrain was a networked verion of intelligent engineering and intelligent logic.
The holistic version was the use of global networks to transform the operation of markets.
An important part of this was its intended role in achieving greater transparency in the total costs and effects of products and companies upon the issues of greatest importance to us all.
This is about the future of democratic institutions, capitalism and free markets.

\subsubsection{X-Logic}

This is a further evolution along the Intelligent Logic, Global Superbrain axis trying to lock into XML technologies.

\subsection{Formal Philosophy}




%{\raggedright
%\bibliographystyle{klunamed}
%\bibliography{rbj,fmu}
%} %\raggedright

\end{article}
\end{document}
