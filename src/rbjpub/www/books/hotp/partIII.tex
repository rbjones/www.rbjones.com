% $Id: partIII.tex,v 1.4 2010/04/05 16:05:16 rbj Exp $

\part{The Twentieth Century}\label{partIII}

The term \emph{analytic} as a kind of philosophy was first introduced to describe a new conception of philosophy appearing at the beginning of the twentieth century in the work of Bertrand Russell\index{Russell, Bertrand} and G.E.~Moore\index{Moore, G.E.}.
These philosophers, until about 1898 had accepted a form of Hegelian idealism, as then taught in Cambridge by James Ward\index{Ward, James}, G.F.~Stout\index{Stout, G.F.} and McTaggart\index{McTaggart}, originating in the work of T.H.~Green\index{Green, T.H.} and F.H.~Bradley\index{Bradley, F.H.}.

The rejection of idealism was lead by Moore, in which Russell followed for a couple of years until his assimilated of the work of Peano in 1900.
Russell then worked intensively on the philosophy and foundations of mathematics until the completion of \emph{Principia Mathamatica} \cite{russell10}\index{Principia Mathematica}, and came to a conception of philosophical analysis which giving a central role to the new mathematical logic.

For my present purposes it is convenient to view the course of analytic philosophy in the twentieth century as consisting of three lines of development.
The first two occupied the first half of the century, and constituted the development of the conceptions of analysis due to Russell and Moore.
In the first the use of mathematical logic was central and was intended to yield a new and logically rigourous philosophical method and to extend the application of the new logic into mathematics and science.
In the second, common sense and ordinary language played the central role, and the aspirations of philosophers to idealised languages and special kinds of knowledge were rejected.
In the second half of the century the rejection of both these conceptions of philosophical analysis became perhaps one of few unifying features of analytic philosophy.

My primary concern is with the thread of which Russell was the source, and its legacy in the twenty first century which will concern us in Part \ref{partIV}.
For the purposes of considering that legacy it is desirable to consider both its merits and defects as progressed in the twentieth century, and the criticisms which were then thought to be decisive against it.
This is a period in which technical advances in logic were continous and rapid, and occurred not only in philosophy and mathematics, but also eventually in computer science, and in which there was continuous evolution in analytic methods in philosophy and for science.

\chapter{Russell and Wittgenstein}

\section{The Theory of Types}

\section{Wittgenstein's Tractatus and Logical Atomism}

\section{Russell's Conception of Philosophical Analysis}

\chapter{Mathematical Logic - to 1931}

The work of Russell and Wittgenstein on the logical foundations of mathematics, were not the only sources of innovation in these areas.
Set theory had made substantial progress despite Cantor's awareness of ``inconsistent multiplicities'', and it was natural to expect that mathematicians interested in set theory would seek a solution to the antinomies which had minimal impact on established methods.

\chapter{Rudolf Carnap}

\index{Carnap, Rudolf}

\section{Early Days}

Though Carnap is closely associated with the Vienna Circle\index{Vienna Circle} and Logical Positivism\index{Positivism!Logical}, for the purposes of this narrative important and enduring aspects of Carnap's philosophical outlook predated his involvement in the circle, and can therefore be presented before we consider the influences of his time in Vienna.

Rudolf Carnap's conceived of himself as progressing Russell's\index{Russell, Bertrand} conception of a scientific philosophy whose method was mathematical logic.

His importance is in the efforts he made to articulate methods for philosophy conceived in this way, one purpose of which was to pass on the benefits of these methods to science.

His first substantial work was the application of formal methods in an attempted phenomenological reduction and resulted in the work with which his name has since been most closely associated ever since, \emph{Der Logicshe Aufbau Der Welt} \cite{carnap28}.

\section{Carnap and The Vienna Circle}

The Vienna Circle provided a highly stimulating environment in which Carnap's ideas developed.

When Carnap's association with the Vienna Circle began he already had a draft of his \emph{aufbau} which is one of the works which were read and discussed by the circle.
Another important and more broadly influential work discussed by the circle was Wittgenstein's \index{Wittgenstein, Ludwig} \emph{Tractatus Logico Philosophicus} \cite{wittgenstein1921}.

Among the many sources of influence during this period three are of particular significance for our narrative:

\begin{itemize}
\item Wittgenstein
\item Schlick
\item Godel
\item Tarski
\end{itemize}

Of these the first three are significant for Carnap's next major innovation, which is the conception of philosophical analysis articulated in \emph{The Logical Syntax of Language} \cite{carnap34,carnap37} (and \emph{Philosophy and Logical Syntax} \cite{carnap35}).
Tarski's relevance is greater to Carnap's later work on semantics.

\section{Philosophy and Logical Syntax}

\section{Carnap on Semantics}

\chapter{Carnap and Quine}

\section{Quine}

\index{Quine, W.V.O.}

Quine majored in mathematics as an undergraduate at Oberlin College with honours reading in mathematical philosophy and mathematical logic (the reading list for which included Russell's \emph{The Principles of Mathematics} \cite{russell03} and Whitehead and Russell's \emph{Principia Mathematica} \cite{russell10}.
His honours thesis was an eighteen page formal proof of a new result in the system of \emph{Pricipia Mathematica}, which gave Quine a deeper and more practical understanding of \emph{Principia Mathematica} than could have been had by any other means, securing him a scholarship at Harvard and enabling him to complete his doctoral dissertation in just two years.

Quine's doctoral dissertation presented a new logical system achieving the effects of \emph{Principia Mathematica} with greater simplicity and clarity.
These included the elimination of intensional objects and simplification of notations, and reduced the mathematical content of \emph{Principia Mathematica} to a mere 290 pages of formal proof.
After further improvements which Quine undertook as a graduate fellow this work appeared as \emph{A system of Logicistic} \cite{quineASL}.

Quine was awarded his doctorate on April 1st 1932, and there ensued four years of graduate fellowship at Harvard. the first of which was a Sheldon travelling fellowship permitting Quine to travel to Europe and begin a lengthy dialogue with Carnap which would twenty years later in the publication by Quine of \emph{Two Dogmas of Empiricism} \cite{quine51}.

\index{Quine, W.V.O.}

\section{Logical Syntax}

\index{Carnap, Rudolf}

\index{Carnap, Rudolf}

Quine's significance here is his rejection of the analytic/synthetic distinction, the reception which this rejection received among analytic philsoophers and its impact on the course of analytic philosophy in the second half of the twentieth century.
This rejection was a turning point in the fortunes of Logical Positivism in North America, for which support rapidly drained away, and with it any idea of the systematic application of logic in analytic philosophy, or of any consistent method intended to unify the practice of analytic philosophy.

It is this episode, Quine's doctrine and its effects, which I propose to make a central example for the analysis from multiple perspectives of the place of rationality in the practice of analytic philosophy, which will in turn inform the ideas presented in Part \ref{partIV} on analytic methods.

\section{Two Dogmas}

I shall now examine closely one of the most influential papers in twentieth century analytic philosophy, \emph{Two Dogmas} by W.V.Quine \cite{quine51}.
The two dogmas referred to in the title were the existence of an analytic/synthetic distinction and the verification principle, both these ideas at that time being central to logical positivism and the philosophy of Rudolf Carnap.
The verification principle had already been criticised and moderated within logical positivism for some time.
Its residue in Carnap's philosophy was attenuated and inessential.

The analytic/synthetic distinction was however, fundamental to the entire philosophical program which Carnap had progressed throughout his life, and if it were shown to be in serious doubt Carnap's approach to philosophy would be devastated.
However, the untenability of the analytic/synthetic distinction is also the untenability of the distinction bewteen deductive and other forms of reasoning, and its destruction undermined rationality itself.

Quine's paper was highly influential throughout the second half of the twentieth century, constituting the single largest factor in the desmise of logical positivism and preventing any serious philosophical use of the analytic/synthetic distinction.
We will consider further the character of this influence, but first I will look closely at the paper itself and present an analysis of what the paper established.

In the following section I provide a detailed concise summary of Quine's paper.
In subsequent sections I discuss the response by Grice and Strawson, offer a further detailed critique, and outline the effect this has on Carnap's philosophy and on analytic philosophy more generally.

\section{Content of the Paper}

\subsection{Quine's Theses}

These are:
\begin{itemize}
\item the analytic/synthetic distinction
\item phenomenalistic reductionism\index{reductionism!phenomenalistic}
\end{itemize}

Quine states his intent in the introductory paragraphs to show that both of these dogmas are ill-founded.
This is a relatively moderate statement of his position, there are more less moderate claims which appear later, and which I shall mention here to bring together the available explicit statements of his theses.

The remainder follows Quine's section headings.

\newtheorem{TD}{}{}{}

\subsection{Background for Analyticity}
\index{analyticity}
Quine, from the outset, is at pains to buttress his attack on the analytic/synthetic distinction by showing that he understands this concept as well as anyone, possibly better than anyone else.

Quine attributes the analytic/synthetic ``cleavage'' to Kant\index{Kant}, but observes that it was foreshadowed by Hume's distinction between relations of ideas and matters of fact and by Leibniz's distinction between truths of reason and truths of fact.

Here he comments on the limited value of the following explanations of the notion of analyticity:

\begin{itemize}
\item true in all possible worlds (not possibly false)
\item denial self-contradictory
\end{itemize}

These exhibit complementary pairs of interdefinable concepts, but do not resolve any fundamental doubts we might have.

Kant's explanation in terms of concept inclusion is found to be to narrow in scope, but when charitably restated as ``true by virtue of meanings and independently of fact'' is considered a basis for moving forward, by examination of the concept of ``meaning''.

Quine now draws the distinction between ``meaning'' and ``extension'', both in the case of singular and general terms.
This is a prelude to dismissing \emph{meanings} as entities, the desire for which he attributes to confusion between meaning and reference.
Once the distinction is understood we can construe the theort of meaning as concerned with matters of synonymy of linguistic forms and analyticity of sentences, and abandon meanings as entities. 

So the idea that analyticity can be explicated through meaning is now abandoned and we start afresh.

Now Quine introduces the distinction between logically true and other analytic sentences.
Logically true he delineates using Bolzano's device, truth under arbitrary re-interpretation of all but the logical particles.
He then characterises the other analytic sentences are those which can be turned into a logical truth by substitution of synonymous expressions.
But for this we need to be able to recognise synonyms, which is no less difficult than recognising analyticity.

Next Quine describes Carnap's use of state-descriptions for defining analyticity, and notes that it suffices only to define logical truth.
He now takes the view that the ``major'' problem is not with logical truths, but with the broader notion of analyticity.

\subsection{Definition}

Here Quine criticises the idea that analytic statements reduce to logical truths \emph{by definition}.

First he dismisses dictionary definitions as fulfilling this role, taking them to be records of observed synonymies rather than the ground for claims to synonymy.

Then he considers definitions made by scientists and philosophers.
Some of these he takes the same way, as records of prior synonymy relations.

Next he considers explications.
These too he considers as resting on prior synonymies.
This is because for them to constitute explications they must relate to some prior usage of which they are explications.
There must be some favoured instances whose meaning is to be preserved in the explication.

Quine does then admit an extreme case in which there are no such constraints and the definition does simply introduce a new synonymy relationshop.
In all other cases, he claims, that definition rests on synonymy rather than explaining it.

His discussion of definitions closes with a discussion of the role of definition in formal work, which seems intended to erode even the residual extreme case he has allowed.
He explains the common occurence of having a rich syntax for use of a language and a spartan one which is convenient for metatheoretic purposes.
He presents the relationship between the two as a matter of translating between them, the rules of transformation being the ``so called defintiions'', which are ``best viewed'' not as adjunctions to one language but as correlations between two languages.
Of course, these correlations are not arbitrary.
Here Quine refers back to his previous classification of definitions and the suggestion is that in these cases of rich and sparse language pairs and the definitions which determine the relationship between them, it is once more only in extreme cases that these definitions do not rest on rather than provide for synonymy.

Quine now concludes that even in the case of formal languages, \emph{definitions} do not provide n ``the key'' to synonymy and analyticity.

\subsection{Interchangeability}

In this section Quine considers and dismisses the idea that cognitive synonymy can be defined as interchangeability \emph{salva veritate}.

\subsection{Semantical Rules}

Quine's aim in this section is to counter the idea that analyticity can be defined in terms of semantical rules.

There is a preliminary reference to ``Everything green is extended'' as en illustration of uncertainty about analyticity, in respect of which Quine claims that the uncertainty here is genuinely about the concept of analyticity rather than about the meaning of the sentence.
He intends to counter the suggestion that in the case of a precise artificial language with explicit ``semantical rules'' then the analytic/synthetic distinction would be clear.

He begins by explaining that the problem is to make sense of the claims of the form `S is \emph{analytic} for L' in which `S' and `L' are both variable, and intends to show that this cannot be done \emph{even if} the scope is restricted to artificial languages.

Then he considers Carnap's methods.
Firstly a method in which he specifies the set of analytic sentences by means of rules.
The problem with this, Quine tells us, is that the rules use the word analytic, which we do not understand.
Before we can understand a statement which tells us that some set of sentences is `analytic for' L, we must understand the claim `S is analytic for L' in the general case with both `S' and `L' variable.

Having said this, he concedes the possibility of defining `analytic for L$_0$' understood `as a new simple symbol', but denies that this tells us anything about the concept of analyticity.

This said, he concedes that we know the meaning of `true' well enough that if a set of rules for truth were offered these could be accepted as `quite clear' and it would then be possible to define an analytic statement as one which follows from the given rules for truth.
This Quine claims, fails because it appeals to the unexplained term `semantical rule'.
Eventually he concedes that it is after all possible for define `analytic for L$_0$' using rules, and then falls back to his initial position of denying that this provides a definition of `S analytic in L'.

There follows a discussion comparing rules with postulates, the conclusion of which is that since any set of rules may be chosen no sentence is intrinsically any more `analytic in L$_0$' than any other.

Next he considers the possibility that a language be considered to be an ordered pair of which the first component is a language `in the ordinary sense' and the second is a set of semantical rules.
But then we might just as well have the set of analytic sentences as the second component, which possibility he appears to take as a \emph{reductio absurdum}.

\subsection{The Verification Theory and Reductionism}



\subsection{Empiricism without the Dogmas}

\chapter{Epistemology and the Digital Computer}

During the second half of the twentieth century computers enter into the picture.

It is natural to think of digital computers as ``electronic brains''.
Whereas previous machines automated physical activities, the digital computer performs tasks which are normally considered mental.
That they required detailed prescriptions in terms of simple elementary steps suggests at first that their capabilities will fall short of those of intelligent human thinkers, but results in the theory of computation obtained even before the appearance of digital computers, suggest that any information processing task can be accomplished by these means.
The argument was made by Alan Turing as early as 1950%
\footnote{``Computing Machinery and Intelligence'' \cite{turingCMI}}
 that there was no obstacle in principle which prevented appropriately programmed computers from any mental task which an intelligent human might accomplish.

In practice this proved harder to accomplish than many hoped, the rest of the century passing without quite cracking the nut.
Though computers still fall short of human brains in many areas (and excel them in others), there is no question that they can now be seen as cognitive agents, at the very least appearing to \emph{have knowledge} and \emph{perform inferences} on that knowledge to obtain further knowledge.

The great bulk of what is done by computers is most naturally thought of as information or data processing.
Computers store large amounts of data and obtain yet more from that data by computation.
But from very early in the history of computing, some of that data has been deliberately crafted to represent \emph{propositions} on which computations are performed which constitute sound deductions.
Though the contexts in which computers are intended to be seen as storing propositions and performing inferences are relatively few, the data in general is intended to be accurate data about some aspect of the real world.
The data files when understood as intended can be understood as representing propositions, and the computations as inference.
The distinction between data and knowledge may be just a matter of interpretation.
The perception as data is easier, the bit patterns in the memory can be manipulated blindly accorinding to some algorithm.
The perception as propositions requires more information, one needs not only the bit pattern but some idea of its significance, and this extra information (semantics) is crucial to an appreciation of what inference is accomplished by some computation.





