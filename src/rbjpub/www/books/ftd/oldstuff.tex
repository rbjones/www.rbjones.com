% $Id: oldstuff.tex,v 1.3 2012/02/14 20:42:22 rbj Exp $

% $Id: intro.tex,v 1.18 2015/04/23 09:58:08 rbj Exp $

\chapter{Introduction}\label{Introduction}

This book is about deduction.
About the place of deduction in establishing and applying our knowledge of the world around us for the benefit of us all.
It is theoretical philosophy rather than practical advice, but it is nevertheless forward looking and constructive.

Because of its philosophical focus on particular kinds of knowledge, it belongs to the field of epistemology.
By addressing aspects of how cognitive systems might work, it seeks to contribute to the most abstract beginnings of the design of cognitive systems.
I therefore think of these ideas as \emph{constructive epistemology}\index{epistemology!constructive}.\footnote{But not \emph{constructivist epistemology}.}

There are two related but distinct threads in the history of `western' philosophy with which I sympathise and in which I place this work.

The first is a very sparsely populated thread of those philosophers who have attached the greatest importance to deductive logic.
These are: Aristotle, Leibniz, Frege, Russell and Carnap.

The second is that of \emph{positivist} thought, a moderation of ancient scepticism which is concerned to advance science by making it more rigorous.
To be an enthusiastic participant in a historical phenomenon, is not to applaud everything in its history, and the work of Rudolf Carnap, a leading figure in \emph{logical positivism}, moved beyond significant elements of the previous positivist tradition, such as nominalism and verificationism, while remaining steadfast on some issues which I like to moderate, and apparently backing off in places where I prefer to hold fast.

\chapter{Old Introduction}\label{OldIntroduction}

\ignore{
That is the endeavour which concerns us here, one in which I seek to progress a tradition in which Aristotle's {\it demonstrative science}, Leibniz's {\it Calculus Ratiocinator} and the central programme of Rudolf Carnap's philosophy (a culmination of the {\it Frege-Russell-Carnap} logicist axis) are prominent.

=================

It is the philosophy of David Hume and that of Rudolph Carnap which have encouraged me to count elements of {\it positivism} significant enough to call this {\it positive} philosophy, but just as Carnap himself diverged from positivist tradition so shall I, both in following some of Carnap's innovations and in my own ways.

Philosophical positivism is sometimes said to be an \emph{anti-philosophical} tendency because of its rejection of many philosophical problems and methods.
Positivism, as here presented, is a graduated constructive skepticism which aims to offer a philosophical framework for the conduct of science and engineeering, and for their application to the benefit of society.

The need for a contemporary restatement of positivist philosophy is underpinned by advances in technology which for the first time in human history bring machines which may \emph{know}.
This is an opportunity to do things better, but the possibility of improvement depends upon the perception of shortfall.
Skepticism may aid that perception, but the most radical scepticism also undermines the possibility of improvement.

Progress therefore depends upon a moderate constructive scepticism in which defects are perceived which may not be beyond remedy.
Positivistic philosophy might be cast in this role, but has historically often been too radical a scepticism, advocating an unrealisable remedy.
Among the aims of this book are to review the origins and history of positivism, to offer a moderation of the positivist critique and suggest some improvements to the remedies.
This is unlikely to prove persuasive to professional philosophers, but might possibly furnish a robust philosophical foundation for an engineering enterprise: the automation of reason.
That is my aspiration.

David Hume, an important figure in the history of positivism. emphasised two important distinctions that we might now describe as those between logical and factual truths, and between objective truths and value judgements.
These distinctions are central to the philosophy outlined here, and help to demarcate the scope of the volume.
This volume is concerned primarily with the domain of objective truth, encompassing the truths of logic and mathematics and those of empirical science.

Matters involving values, sometimes called ``practical philosophy'' will be addressed in a separate volume.
Even when concerned primarily with objective truth, the choice of a ``philosophical framework'' of the kind presented here is pragmatic.
Theoretical philosophy is here considered subservient to practical philosophy, and though the subject matter of this volume is theoretical, pragmatic considerations motivate and permeate the discussion.
}%\ignore

\chapter{Introduction}\label{Introduction}

My aim in this volume is to weave together and project into the future certain threads disentangled from the web of history.
The forward projection is intended to be, at the same time, a kind of constructive or positive {\it philosophy} and a kind of architectural {\it engineering}.
Some say that to understand the future one must build it, others that to understand intelligence one must re-construct it.
There are elements of these insights in this enterprise.

Philosophy provides for this venture a conceptual framework, language with which to talk about:
\begin{itemize}
\item \rbjdefined{language} itself,
\item {\it knowledge} as represented in language,\\
  and
\item {\it reasoning} from a body of such knowledge to new insights entailed by that knowledge.
\end{itemize}

In order to construct an architecture for cognition one must surely have some conception of what cognition is.
In the process of synthesising and articulating such an architecture, that conception of cognition will be progressively refined.
Philosophy and engineering are therefore at least closely interrelated in these matters, and perhaps we may say that the single enterprise is at once philosophy {\it and} engineering.

There is a long history in the field of Artificial Intelligence of combining {\it science} and engineering.
It began in Computer Science, which is itself as much an engineering descipline as an empirical or theoretical science, and then became a popular method of research in psychology, before the scientific aspects of artificial intelligence were combined under the umbrella of {\it cognitive science}, built around the idea that "thinking can best be understood in terms of representational structures in the mind and computational procedures that operate on those structures."\footnote{Paul Thagard, \it Stanford Encycopaedia of Philosophy}

The architecture presented here is not offered as a solution to the problem of artificial intelligence.
Insofar as it is concerned with {\it cognition} it is with cognition stripped of psychology, in a manner similar to the way in which modern logic was pioneered by Frege as distinct from if abstracted from ``the laws of thought''.
The questions whether machines can think, or could be conscious, are not ours.
We know that machines can compute, can infer, and we are here concerned with how to do that bigger and better.
We seek to facilitate a general paradigm shift from the transformation of data by computation to the growth and application of knowlege by deduction, completely subsuming the computational.
This does perhaps stretch the notion of deduction.

The architectural proposal is intended as a contribution towards the engineering of systems which organise knowledge and facilitate reasoning which is viable even if the only real intelligence is supplied by the humans using the system, as is the case for present day interactive theorem proving systems.
It is intended to be an architecture within which machine intelligence will fit well, and is offered in the expectation that it will eventually be augmented in that way, and its characteristcs and utility will be then transformed.

Nor is this monograph intended to belong to the philosophy of AI.
Artificial intelligence is not its subject matter, and the knowledge and reasoning we are here concerned with is abstracted away from the study of human cognition, in much the same way that the work of Gottl{\"o}b Frege took the psychologism out of logic.
We are not concerned with laws of thought which govern how cognition takes place in human brains.

In this introductory chapter the core of the conceptual framework is first sketched, and then I outline the way in which this is underpinned and elaborated in the rest of the volume.

\section{Propositions, Entailment and Deduction}

Wittgenstein made much of the diversity of language, likening languages to games.
My interest here is in an idealised kind of language, abstracted from some of the ways in which our natural languages are used.

This kind of language, which I call {\it propositional} language, permits communication via {\it sentences}, which have an objective {\it meaning} which includes {\it truth conditions}.
Truth conditions are conditions which may or may not be satisfied, according to how things are.
When such a sentence is asserted then the literal or explicit content of the assertion is the claim that the way things are satisfies those conditions.
Thus the sentence ``it is raining in Oasby'' has truth conditions which are satisfied if there is at present liquid water precipitating in Oasby, and its assertion communicates that those conditions do in fact obtain, i.e. that liquid water descends from the heavens, falling in Oasby.

{\it Proposition} is the word we use for the things expressed by such a sentence, and it is knowledge represented by such propositions which we can elaborate by deductive reasoning, which is that kind of reasoning whose automation concerns the book.




\chapter{A Theory of Knowledge}\label{TheoryOfKnowledge}

This chapter provides an outline of a contemporary reworking of some of leibniz's central
ideas, particularly the formalisation of knowledge and the automation of deductive reasoning.

This reworking is presented as a pluralistic \emph{framework} for knowledge representation and its
deductive elaboration.

The context required for an understanding of Leibniz's ideas in this area is his
understanding of logic, particularly of language and how it could be made formal
to facilitate the autmation of deduction, both for the purposes of establishing
the truth, and to facilitate innovation.
Intimately involved with this is his metaphysic.

\section{The Evolution of Language}


\chapter{Introduction}\label{IntroductionA}

\ignore{\cite{russell1956}}

This book consists of {\it constructive} or {\it synthetic} philosophy.
By that I mean, a philosophical dissertation whose purpose is to articulate:

\begin{itemize}
\item an idea or objective, or complex of related ideas, to be realised
\item a conceptual framework in which that idea can be made more precise
\item a description of requirements to be satisified in realising the idea
\item an architectural description of a way in which those requirements might be realised
\item some reasoned grounds for believing that the architecture described will meet the specified requirements
\end{itemize}

As philosophy the book belongs to the {\it analytic} tradition, characterised by its use of reason to seek understanding.
In describing it as {\it synthetic} I highlight my intention to talk about, in a constructive manner, not what is, but what might be.

To that end many matters which might otherwise have been discussed in an introductory chapter are here swept aside for an immediate first cut at stating a project goal and refining it to a collection of requirements.
To bring home how philosophy could possibly be constructive in the manner required, the project goal will come from a philosopher and the requirements will arise largely from considering how the views of subseqent philosophers have influenced our reading of that goal, only in the final stages of that history drawing up the ideas of mathematical logicians and computer scientists.

\section{Beginning with Leibniz}

The most distinguished progenitor for the kind of project which we are engaged in is Leibniz, so it is usefull to consider those ideas of Leibniz which presage the present enterprise.

The particular part of Leibniz's work which we take up is his idea of a method for resolving or answering all future disagreements in philosophy and science by codifying all our knowledge in a universal formal language (which he called the {\it lingua characteristica} and then {\it calculating} (aided by calculuting machines) the answer to questions, by an infaliible method which he called his {\it calculus ratiocinator}.

It seems likely that Leibniz was lead to his conception of a {\it calculus ratiocinator} by discovering in his youth a method (what we would now call an algorithm) for deciding the truth of ``categorical propositions'', a form of predication central to Aristotle's logic.
Believing the class of propositions which fell within the scope of his method to be universal, or at least, sufficient to express scientifig knowledge and any conclusions we might derive from it, Leibniz perceived the possibility of resolving both philosophical and scientific issues and problems in an efficient an reliable way by algorithmic, preferably mechanical, computation.

Leibniz was mistaken on important points as a result of which the principal aims of his project we now know to be unacheivable without refinement and qualification.
Nevertheless, subject to such refinements, it is Leibniz's project we seek here to revive.

More cautiously stated I therefore provide here a first statement of objectives clearly related to this early work of Leiniz.

The principal objective is therefore to provide a context in which:

\begin{itemize}
\item most logical, mathematical, scientific and factual knowledge can be formalised
\item reasoning from that body of knowledge can be substantially automated, providing reliable establishment of the results obtained
\end{itemize}

Logic is central to these ideas of Leibniz, it is Aristotle's logic on which Leibniz is building.
 
\section{Hume's Fork}

``Hume's fork'' classifies ``the objects of Human reason or enquiry'' as relations between ideas or matters of fact.
One of the characteristics which distinguish these two kinds of knowledge is {\it certainty}.
Reasoning about relations between ideas, notably in mathematics, yields certain truths, reasoning about matters of fact 

\begin{itemize}
\item The system will be conncerned only with analytic truths
\end {itemize}

\chapter{Introduction}\label{IntroductionB}

This book of philosophy is written in the context of changes in the human
condition, mediated by the onward march of information technology, which
might be expected to have a profound impact on the character of philosophy
and to which philosophy may be expected to contribute.
It aims to reflect upon the nature of these changes and to offer a contribution
to their realisation.

Since the invention of the digital computer, facilitated by continuous advances
in semiconductor technology, progressively wider ranges of intellectual skills
previously confined to human beings are now subject to automation.
Almost all published knowledge is now in electronic form, and the ways in which
computers are able to work with this knowledge are rapidly advancing.
The time will come when machines will be generally accepted as {\it knowing}
and as {\it reasoning} from that knowledge.

Such changes in the world test understanding of our languages, and language
evolves to deal with them.
If it is uncertain today whether inaminate machines might properly be said to
have knowledge and to be intelligent, it nevertheless seems likely that as our
interactions with machines and their contribution to our knowledge increasingly
match or surpass what we expect from humans, then the relevant parts of our
language will evolve to encompass them.

In this evolving intellectual landscape, there is much scope for philosophical
analysis of language, but of greater interest here is not a passive analysis but
an active engagement in the development of language, knowledge and reason, to take
best advantage of the opportunities presented.

My aims here are in some respects similar to those addressed by A.M.~Turing
in his paper ``Computing Machinery and Intelligence''.
In that paper, while discussing machine intelligence, Turing avoids questions
about {\it meanings} by inventing his ``imitation game''.
The imitation game, later dubbed the ``Turing test'', focusses the evaluation of
machine intelligence upon the possibility of machines successfully emulating humans.

Many workers in the field of ``Artificial Intelligence'' seek to emulate
human capabilities much as they are found in people.
But the history of computing shows that automation of human intellectual labour
usually involves a substantial transformation in methods and results.
Machines do things different, even, especially, in those domains in which they
excell.

What will the impact of these changes be on the nature of philosophy?
One answer to that question which I present here is that a new kind of
constructive epistemology will be needed which is at once a philosophical
theory and a part of the cognitive architecture of the future.

In order for this philosophical dissertation to be a plausible contribution
to the cognitive architecture of our future, I propose to render the philosophy
in a way sympathetic to that possibility.
The ways in which research and development are at present conducted in the
areas most significant for the capabilities we are considering will be examined,
particularly the earliest parts of the development cycles and the ways in which
they connect with and draw on pre-existing science and technology and the
broader history of ideas.

The ways in which a philosophical treatise might contribute are unlike those in
which some definite technical contribution would.
It is not expected that the philosophical ideas articulated here be {\it adopted} by developers
in the way in which some more concrete technology would be, but rather that
the ideas might contribute to the development of pre-competitive standards.

I begin with some preliminary discussion of, on the one hand, some relevant
ideas in the philosophical literature, and on the other, some industrially
oriented standardisation activities (in the next two sections).
Then, the needs of industry in connection with cognitive architectures will
be considered, and their connection with academic disciplines of mathematical
logic and philosophy.
The contention is that this problem domain is more demanding of philosophical
context, or will benefit from more substantive philosophical context, than any
 prior technology, because of the special difficulties arising when reasoning
about knowledge.

In the development of information technology, there is continual contention between
the adoption of open standards by large numbers of players, and a contest among
proprietary standards.
A dominant market player will often strengthen his position by retaining proprietary
standards while smaller forces will either try to interface with those standards
or combine with others to compete, which will often be done through open standards.
Subtle variants of this pattern are common.

The philosophy here will be aimed at supporting the development of open standards,
partly because there is a kind of agenda here.

\section{Philosophical Predecessors}

I think of the project here described as a sucessor to the project which
was central to the philosophy of Rudolf Carnap, and as a contemporary ancestor
of a project to which Leibniz dedicated much energy.
Some core features of the philosophy of David Hume provided keystones in
the architecture which Carnap devised.
This first sketch will connect with the ideas of these three philosophers.
Subsequent chapters will make a wider range of historical connections
as the various aspects of the project are examined more closely.

The parts of Leibniz's work which are of interest here are his
{\it lingua characteristica} and \empftdbook.pdfh{calculus ratiocinator} and the
rationale surrounding them.
The {\it lingua characteristica} was intended to be a universal formal language
in which the whole of human scientific knowledge could be expressed precisely,
and the {\it calculus ratiocinator} was an effective method for calculating
the answer to questions raised in that language.

These are precedents for one approach to the development of artificial intelligence
in which some manner of representation for knowledge is chosen and algorithms
are then sought for reasoning intelligently with that knowledge. 
They correspond to more specifically {\it logical} approaches to AI
in which the representation of knowledge is in a language which is thought
of as a formal logic and a core component of the intelligent capability is
deductive inference.

...

It is epistemology because it is concerned with knowledge, with the language
in which it is expressed and the manner in which we can reason about it.
It is constructive rather than descriptive because it does not offer an account
of what knowledge is but a suggestion for what it might be,
This suggestion is itself intended to be constructive in the special sense
of {\it computationally realised} or realisable, but Leibniz's contribution here is
primarily architectural rather than in the detail (though he does go so far as to
offer a decision procedure for the truth of syllogisms, and makes contributions
to the design of mechanical calculators).

One of the principal difficulties which limited the sucess of Leibniz's project
was the weakness of the Aristotelian logic with which he was working.
A revolution in logic was needed.
That revolution began in the second half of the nineteenth century and the seminal
work in this area of Gottlob Frege was to inspire Rudolf Carnap to his own
variant of constructive epistemology.

Unlike Leibniz, Carnap's project was not computational, it had not quite the same breadth.
Carnap sought to transform philosophy and science by the use of these new logical
methods.
Bertrand Russell had shown, with A.N.~Whitehead in {\it Principia Mathematica}\cite{russell1913}
how the new logical methods could be used for the formalisation of mathematical propositions and
their proofs, and he had put forward a vision of a new kind of scientific philosophy
based on these methods.
This provided a second principal impetus to Carnao, who sought to transform philosophy
and science by facilitating the application of the new logical methods in those disciplines.
The role of the philosopher was to furnish formal languages suitable for expressing
empirical theories with deductive systems allowing the consequences of the theories
to be reliably established.
He also addressed the problem of empirical confirmation of scientific theories.
Throughout Carnap is engaged in the theory of knowledge, but this is not a descriptive
analysis, but a constructive or synthetic activity.
He devises languages, with their semantics and deductive systems, and he develops
methods.
The output of his epistemology is not certain theories about what knowledge is, it
is a set of proposals about what it might be.

\section{Technological Perspective}

Having touched upon the philosophical context I want now to sketch the technological context
in which the kind of philosophy which I engage in here may be seen as an early part of
the continuous process of technology development.

In the global information technology industry huge investments are made in the development
and advancement of new technologies ultimately delivering new products for the marketplace.
A new semiconductor fabrication plant might cost as much as \$10B to build and equip, but that
is the end of a decade or more of process development.
Just one of the chips then manufactured might contain billions of transistors interconnected
to realise computational capabilities which have been developed over many years.

Because of the huge costs of developing new semiconductor technologies even the larges companies
will enter into multi-corporation collaboratives in the early part of the development process.
One aspect of the work undertaken by such collaborations will often be standards for the new
technologies under development.
At this stage the technology development can be regarded as {\it pre-competitive}
(though the technology may still be considered to compete with other approaches to delivering
similar benefits).
The purpose of the standards developed (in some cases) is to prepare for a later competitive phase
in which these technologies are brought to market by the companies who have contributed to the
pre-competitive research and development which delivers the standards.

An example is the Hybrid Memory Cube Consortium.
Hybrid memory is a semiconductor technology in which active logic and memory chips are stacked in a single package
achieving higher density and higher performance than intetconnected planar organisation.

\begin{quote}
The goal of the Hybrid Memory Cube Consortium is to facilitate HMC Integration into a wide variety of systems, platforms and applications by defining an adoptable industry-wide interface that enables developers, manufacturers and enablers to leverage this revolutionary technology.
\end{quote}

The consortium consists of nine ``developer members'' who actively participate in the development of a set of standards and have ``equal voice and voting power on the final specifications'', and roughly 150 ``adopter members''.
Typically the developers will be those with the greater financial stake in the outcome, who are planning involvement in the manufacture of the technology in question and are therefore motivated to invest respource or capital in the development of the technology, while adopters will be those who expect to design or manufacture other products which use components delivering the inferfaces and whose product design therefore depends on the specifications.
The aim of all who expect to be involved in this new kind of technology is to prevent a proliferation of competing standards which creates additional expense and risk.

There are many ways in which precompetitive research can be undertaken, and which work best will depend upon the technologies concerned.
Software technologies have pioneered the use of ``open source'' developments in which software is developed by a collaborative team
with the intention of making the software freely available without licence fees.
Often the people and corporations involve will be those who have a commercial interest in exploiting the resulting software, who will perhaps produce other products which depend upon.
This ``open source'' methods have now spread into computer hardware (e.g. the ``openstack'' initialtive for large server farms).

If we track earlier into the development of new technologies then we are likely to find ourselved looking at academic research or collaborations involving industrial and academic partners.
Often academic research which delivers commercially exploitable technologies will result in commercial spin-offs followed by continued collaborative between the original academic institutions and their commercial spin-offs.

Yet further back we can trace {\it ideas} to fundamental research in academic departments seemingly remote from commercial application.
Research in information technology, for example, will be located academically in departments of Computer Science, but may make extensive use of theoretical knowledge from mathematics departments including mathematical logic to which fundamental contributions have been made by philosophers (Aristotle, Leibniz, Frege, Russell, Church, Martin-Lof).

\chapter{Introduction}

{\it
[
The introduction needs now to begin with some discussion of the significance of the automation of reason and of the relevance to it of philosophy.
It is then desirable to sketch the main lines of the relationship between them which will drive the subsequent detailed exposition.
The main lines are:
\begin{itemize}
\item First and foremost the ``fundamental triple dichotomy'' and its historical development.
\item Secondly, the nature of metaphysics, and certain conceptions of metaphysics which connect with the evolution of the triple dichotomy.
\begin{itemize}
\item as an approach to semantics
\item as the synthetic-\emph{a priori}
\item as meaningless
\item as absolute
\item in contrast with skepticism before and positivism after Hume
\end{itemize}
\item 
\item
\end{itemize}

However, my present conception of how the philosophical themes can be put together with the motivating purpose in a systematic and enlightening way is too sketchy for the introduction to be written.
]
}

It is part of the historical role of philosophy to provide a context for the systematic pursuit of knowledge.
Such a context, framework or system, is philosophy for philosopher and non-philosopher alike.
It needs to be compact and focussed.

\section{First Philosophy}

{\it First philosophy}\index{philosophy!first} is the name given by Aristotle to that part of philosophy which is concerned with the most fundamental problems, the study of which demanded and delivered the highest degree of the {\it wisdom} possessed by the greatest philosophers.

Aristotle's characterization of {\it first philosophy} is heavily laden with value judgements from which we glean that Aristotle regarded ability in philosophy, and those who posses it, as superior to all other kinds.
{\it First Philosophy} may therefore be seen as an arrogation of superiority by philosophers over other academic disciplines.
This may be part of the reason for the disdain with which {\it first philosophy} has often been regarded during the last century.

Aristotle's writings on {\it first philosophy} are found in a volume which was entitled by later editors {\it Metaphysics}\index{metaphysics}, and that name has become associated with certain aspects of {\it first philosophy} which philosophers can regard as their own inner sanctum without presuming upon other disciplines.
Metaphysics in its purest form is the philosophical study of what ultimately there is.
Though metaphysics may be thought too far removed from more practical disciplines to impinge directly upon them, its basis has been disputed throughout history, and this dispute has provided a continuous historical dialectic between those philosophers who believe that there is important knowledge of this kind to which philosophers have best access, and those who doubt the reality of knowledge beyond that which may be discovered by scientific methods, belonging to physics itself rather than metaphysics, or to some other scientific discipline.

In ancient Greece the most extreme opponents of meta-physicians were the sceptics, who doubted all.
In modern times, conspicuously with Hume, a synthesis, or principled compromise, was realized between scepticism and dogmatism admitting scientific knowledge but rejecting metaphysics.
The dialectic then continued, not now between large scale dogmatic systems and total scepticism, but between rationalists who sought to justify metaphysics and positivists who continued to deny it.

This work aims to progress this historical dialectic, attempting another synthesis, in which the positivist grounds for rejection of metaphysics are embraced and strengthened, but are seen to apply only against a certain conception of metaphysics, as necessary (or a priori) synthetic truths.
From an understanding of how metaphysics can be seen as intimately related to semantics, a new conception of metaphysics can be reached, and with this we may approach the identification of important metaphysical problems  which can be progressed by philosophical methods.

This is a work of {\it theoretical philosophy}, i.e. philosophy concerned with {\it knowledge}, rather than values or their implications (which topics belong to {\it practical philosophy}).

We approach this new metaphysics by first presenting the historical process restating the case against metaphysics and understanding why existing conceptions of metaphysics are defective.

\index{Hume, David!fork}
Hume's version of this is sometimes called ``Hume's fork''.
It begins:

\begin{quote}
``ALL the objects of human reason or enquiry may naturally be divided into two kinds, to wit, Relations of Ideas, and Matters of Fact.''
\end{quote}

and is presented more fully in section ?.

The idea is not Hume's, it speaks of a division so fundamental that signs of it can be seen throughout the history of western philosophy, but in Hume we first see this distinction, clearly stated, playing a pivotal role in an important philosophical system.
In Hume's exposition are apparent three different characterizations of a single fundamental dichotomy, one based on subject matter (or meaning), one on metaphysical or modal status, and one epistemological.
These three characterizations of the one dichotomy give rise to the title of this monograph.
That they are all characterization of the same fundamental dichotomy, or indeed that any of them is even meaningful, remains controversial after more than 2000 years of philosophical debate. 

Progress in philosophy is often felt to be elusive or illusory.
Hume's fork, its origins and its modern manifestations, provide a tantalizing combination of evidence for and against the thesis that there is progress in philosophy.
In its history we find continuing interplay with some of the most important ideas at the core of Western philosophy.

\chapter{The Project}
\subsection{Carnap?}

The impact ot the latter is significant for the \emph{representation} of propositions, which in Leibniz's idea was required to effectively encode fully expanded definitions of all the concepts involved, so that a calculator, without access to an distinct body of propositions might decide the truth of the single proposition submitted to it.

Russell, in his analysis of the philosophy of Leibniz observes that ``all sound philosophy should begin with an analysis of propositions''.
Without necessarily agreeing with Russell on this point, that is where I propose to begin.
It is probably more correct to call what is offered here a theory of propositions than of knowledge,
insofar as we are concerned with the representation of propositions, the organisation of large bodies of
propositions, and the things which one might expect to do with such a body of propositions, notably
its extension by definitional or inferential means.
This is a contemporary alternative to the Leibniz's universal language, characteristic and calculus,
which can (and should be) very different to Leibniz's conceptions because of the various important
developments which have taken place since his time.


\chapter{Restatement}\label{Restatement}

\section{Descriptive Language}

The definitions given here are intended to limit consideration to languages which ``have'' a semantics of a certain form.
This term ``have'' is not intended in any concrete sense, but in a sense similar to notions of existence in mathematics, i.e. it is required that such a semantics exists, not that we know it, understand it, can write it down or even that it could be written down (as in ``there exists a real valued function'').

\index{language!descriptive}
The term {\it descriptive language} is used here to refer to languages in which one may make statements about the ``real'' world.
For present purposes I intend this to exclude languages whose subject matter is entirely abstract, such as set theory.

In such languages {\it indicative} sentences are those which (given certain contextual information) say something about the world, rather than, for example, conveying a command.

\index{statement}
A {\it statement} is an indicative sentence together with sufficient context to disambiguate the sentence.
Disambiguation here means determining the proposition expressed by the sentence in this context.

\index{proposition}
A {\it proposition} is the meaning of an indicative sentence which encompasses the truth conditions of the sentence.

\section{Justification}

\index{justification}
For some purposes the justification of propositions is considered, for example, in considering whether a proposition is known.
A justification is said to be {\it a priori} if it depends on no information about the actual state of the universe, and is otherwise {\it a posteriori}.

Individuals or institutions may take a view on what kind of justification is appropriate for any given proposition or class of propositions.
In that case a proposition may be said to be {\it a priori} if an {\it a priori} justification is thought the be appropriate for it.
Such classifications concern the {\it epistemic status} of propositions.

The epistemic status of a proposition in this sense is not dependent upon whether the proposition is know, or even whether it can be known, it depends only on the kind of justification which is admissible for that proposition or class of propositions.

\section{The Dichotomies}

\index{possible!world}\index{proposition}
The term ``possible world'' here refers generally to the kind of circumstance relative to which the truth conditions of a proposition are given (and may be language specific).

\index{necessary}
A proposition is {\it necessarily t} if it has truth value ``t'' in every possible world (I do not insist on there being just two truth values, the number of truth values is determined by the semantics of the language).

\index{contingent}
A proposition is {\it contingent} if it does not have the same truth value in every possible world.

\index{analytic}
A sentence is {\it analytically t} for some truth value ``t''	if the proposition it expresses (its meaning) is ``necessarily t''

\index{synthetic}
A sentence is {\it synthetic} if it is not ``analytically t'' for any truth value ``t''.

\index{a priori}
A justification for some claimed proposition is {\it a priori} if it makes no reference to any empirical observation or any contingent proposition.
Note however, that the constraint does not apply to any aspect of the justification of a statement	which is concerned exclusively with establishing its meaning (i.e. establishing which proposition is expressed by the statement)

I propose that we should accept only ``a priori'' justifications for necessary propositions, and only ``a posteriori'' justifications for contingent propositions.

Its intended that there are no substantive claims in the above, these
are all proposals for usage, except the last, which is some other
kind of proposal.

\section{Elaborations}

\subsection{Epistemic Status}

Two factors which do not influence the epistemic status of a proposition under this proposal should be understood.

Firstly, since we have defined epistemic status exclusively in terms of justification, the manner in which the truth of a proposition is apprehended or discovered is not in itself relevant to its epistemic status.
The epistemic status under this account depends exclusively upon the kind of justification which is deemed appropriate for the proposition.

Secondly, in considering the epistemic status of some proposition the manner in which the proposition is understood from some statement which we may suppose to express it is immaterial to the epistemic status of the proposition.

Under some circumstances the meaning of a statement may be difficult to ascertain, for example, if the meaning of a name is the thing named, then sentences involving that name may not be well understood by those little acquainted with the thing named.
Consequently, empirical investigation may be necessary to establish the meaning of a statement (or the proposition expressed by it), and these considerations may need to be mentioned in the context of a justification of the proposition.
Such facts are for present purposes not regarded as facts about the world appearing in the justification.
The relevant facts are those which participate in the justification of the proposition proper, not those which may participate in the identification of the proposition expressed by some statement.

\section{Some Consequences}

If we confine consideration to languages with two truth values (i.e.
in which a proposition is either true or false in every possible world)
then there are three essentially coincident dichotomies.

The identity of the distinctions is more conspicuous if the definitions
of necessary and contingent, are extended to statements in the obvious
way,


\chapter{The Project}\label{TheProject}

It is my aim here devise a philosophical framework suitable to
underpin a particular enterprise, \emph{the project}. 
This might sound like a narrowly scoped philosophy, but ``the
project'' is broad enough to encompass the whole of mathematics,
science and engineering when undertaken by deductively sound methods. 
The project is, in brief, the automation of deductive reason and its
applications, undertaken in a particular manner which I hope to make
clear. 
The relationship between that project and the philosophical ideas
which I offer as a supporting context is complex. 
A full and detailed account of the project depends upon the
philosophy, but the project plays an important role in the
articulation of the philosophy, they are hand-in-glove. 

In this section I make a first attempt at describing the project
trying to minimize reference to the underpinning philosophy. 
In subsequent chapters the philosophical issues are entered into in
earnest, and in this way it is hoped that aspects of the project are
made more clear. 

The scope of the phrase ``automation of deductive reason'' is intended
to include \emph{intelligent} reasoning, but not to encompass much of
the aims or methods of that field known as artificial or machine
intelligence. 

Here and in subsequent sections explanations I use try to make the
ideas clearer partly by talking about their historical evolution. 
In this section the connection with some of the pioneers and
visionaries who have contributed to the formalization and automation
of reason in ways particularly relevant to out project are drawn out. 
The principle figures in this are Gottfried Wilhelm Leibniz and Rudolf
Carnap, as exemplars of the philosophers with similar projects, and
Alan Turing is discussed for a contrast with the kind of automation of
reason I have in mind here. 

\section{Leibniz, Characteristic and Calculus}

Leibniz was a \emph{rationalist}, a philosopher who was particularly
concerned with what can be established by reason rather than
observation. 
The distinction between the two he recognized in the dictum:

\begin{quote}
``There are two kinds of truths, truths of reason and truths of fact.''
\end{quote}

Despite recognizing this distinction, he perceived that all these
truths might be codified formally, so that the distinction between
truths and falsehoods could be determined by computation. 

His vision was \emph{universalistic} in several respects.
He envisaged a \emph{universal
  characteristic}\index{universal characteristic}, which was to be a
formal logical language in which all knowledge might be codified, and
a \emph{calculus ratiocinator}\index{calculus~ratiocinator}, a method
of calculating the truth value of any sentence in his universal
characteristic. 

These two ideas provide the first prototype for this work.

Leibniz did not imagine that the truth of scientific hypotheses could
be established in this way, rather that the corpus of scientific
knowledge could be encoded in the universal characteristic, the
calculus then settling questions in the context of that knowledge. 
In consequence, Leibniz also promoted the collaborative development of
an encyclopedia, of scientific academies and journals. 
Leibniz perhaps also guessed that the computations involved might be
non-trivial, and contributed also to the development of the
information technology of his age, calculating machines. 

Leibniz in these ideas was at least three centuries ahead of his time.
The logic he knew was essentially that of Aristotle, and fell short of
what is needed for the formalization of science by a wide margin. 
The necessary innovations in logic did not appear for another two
hundred years. 
Beyond the adequacy of modern formal languages to express the entire
corpus of scientific knowledge, there lie known limitations in the
extent to which formal deduction can capture truth in these systems. 
Mechanical decision procedures are known not to exist, so for these
reasons we know that no calculus could be relied upon to settle all
well formulated problems in the universal characteristic. 

These limitations are perhaps of only marginal significance for
applications in science and engineering, but even within these
limitations there are serious problems of computational
intractability. 
For many or most problems whose answer is in principle computable, it
will not be accomplished in a reasonable timescale or through the
deployment of available resources. 
Brute computation will therefore not suffice in any but the most
simple cases, and something closer to the workings of human
intelligence would be needed, to come close to an effective
implementation of Leibniz's calculus. 

The technology of calculating machines was even further from sufficiency.
It remains moot whether today's information technology is up to the task.
Beyond the adequacy of the hardware, there are problems with the
software, potentially even less tractable. 

Leibniz's ideas in these matters had little influence in his own time
or for centuries following, not just because they were so far removed
from what was then realizable, but also because they were not even
published. 
His largest impact pressed matters in the opposite direction, and came
from his independent invention of the differential and integral
calculi, and particular for the notation which he devised for this
epoch making mathematical innovation. 
The epoch thus spawned was two centuries of rapid development of
mathematics applicable in science and mathematics. 
These enormous advantages took place despite the \emph{reduction}
consequent on the introduction of infinitesimal quantities. 
Right at the beginning of this period the philosopher Berkeley
criticized these new developments, but it was two hundred years before
mathematicians began to take the problems of rigour seriously and the
rigorization of analysis began, ultimately leading to the new
developments in logic which made it sufficient for Leibniz's project. 

The rigorization of analysis was accomplished first by the
displacement of infinitesimals in a precise notion of limit and by
construction of real numbers from natural numbers, effectively
reducing analysis to arithmetic. 
This done, the next challenge taken up by Kettle's Frege was to show
that arithmetic was simply a matter of logic, requiring no special
metaphysical insights. 
In rising to this challenge Frege, inspired in part by the example of
Leibniz, re-invented logic in the form of his \emph{Begriffsschrift}
or concept notation, which provided the basis not merely for the
logicisation of arithmetic, but also potentially for Leibniz's
universal characteristic. 

Frege's project was more narrowly scoped, but even the formalization
of arithmetic was an arduous undertaking, into which Frege had
invested decades of industry when Bertrand Russell pointed out to him
the inconsistency of his basic principles. 
At about the time when Russell and Whitehead were completing their own
assault on the logicisation of mathematics (a substantial hurdle in
which was ensuring against the kind of inconsistency found in Frege's
system) the young Rudolf Carnap was attending as an undergraduate
Frege's lectures on his new logic and absorbing much of Frege's
attitude to rigour in deductive reasoning and its general
applicability. 

\section{Carnap's Programme}

Carnap was first apprised of modern logic as an undergraduate by
Frege's lectures on his `Begriffsschrift''
\cite{frege1879,heijenoort67}. 
At this stage in his development Carnap clearly showed an interest
both in philosophy and in mathematics and science. 
He was also strongly inclined towards the precision of language which
he found in Frege's logic which he contrasts with the teaching of
logic in philosophy. 
Within the sciences, he preferred physics because of its greater
conceptual clarity. 
He also perceived the distinction between ethical, evaluative, emotive
and metaphysical language and scientific doctrine. 

From this position as an undergraduate just before the great war he
moves forward in a period of about seven years to the point at which
we can see the formulation of the central ideas which motivated his
work through the rest of his life. 
The most significant new influence in forming these ideas came from
Bertrand Russell. 
Carnap became acquainted with \emph{Principia
  Mathematica}\cite{russell10} and began to prefer its notation to
that of Frege. 
He also begins to feel that a concept is not clearly understood until
he can see how to express it in symbolic language. 

At the end of 1921 Carnap read Russell's \emph{Our Knowledge of the
  External World}\cite{russell1921} and was inspired by Russell's
characterization of ``logico-analytic method'' in philosophy. 
It is at this point that Carnap self-consciously devotes himself to
this philosophical method and begins intensive reading of Russell's
writings on the theory of knowledge and the methodology of science. 

Russell, in his work on \emph{Principia Mathematica} had undertaken
with Whitehead a task similar in character to Frege's project. 
However, Frege's focus had been on the logicisation of mathematics.
Russell had a broader conception of the applicability of the methods,
and advocated a kind of philosophy in which such methods were used
exclusively. 
Carnap took up this challenge enthusiastically.

Carnap's philosophical programme therefore involved first the idea
that philosophy in general should be \emph{analytic} in the specific
sense that its methods and results are logical, and should be obtained
by the new logical methods pioneered by Frege and Russell. 
Secondly Carnap conceived of the role of the philosopher as being
primarily concerned with facilitating the progress of empirical
science. 
The kind of facilitation he had in mind was analogous to the
innovations in mathematics undertaken by Frege and Russell, the
establishment of new languages in which scientific laws could be
precisely enunciated and the surrounding theoretical and
methodological framework for the formalization of science. 

The work of Frege and Russell had been \emph{universalistic} in the
sense that they sought a single new language in which the whole of
mathematics could be developed. 
At this stage Carnap's thinking was along similar lines, but since he
was trying to carry forward the ideas into empirical science, it did
not seem feasible to stick with the same purely logical systems. 
Carnap's aims at this point may therefore be thought similar to
Leibniz's desire for a \emph{universal} characteristic in which all of
science could be formalized. 
Later Carnap became more pluralistic, but the idea of using formal
logic to encode scientific knowledge and of formalizing deductive
reasoning about science places his enterprise within the scope of
Leibniz's. 

Like Leibniz, Carnap's ideas were ahead of their time.
He was working in the context of modern symbolic logic, which is (I
shall argue), no longer shackled by the limitations of Aristotelian
syllogistic. 
But strict formality in language and proof is arduous, and good
mechanical support a prerequisite to widespread adoption of such
methods. 
\emph{Principia Mathematica} formalized a significant part of
mathematics, and was very influential during the formative years of
the new academic discipline of \emph{mathematical logic}. 
These new developments did have a significant impact on Mathematics,
which was made more rigorous through the systematic use of axiomatic
set theory. 
But mathematicians did not follow the example of Russell and Whitehead
by taking up strictly formal notations or formal proofs. 
Not even in mathematical logic did this happen, for mathematical logic
became a meta-theoretic discipline in which formal systems were
studied rather than applied. 
Proofs in mathematical logic may often be concerned with formal
systems, but they are not themselves formal. 

Not only was formalization rejected by mathematics and science, it was
soon to be rejected, together with Carnap's entire philosophical
outlook, by philosophy. 
The first major assault on Carnap's position was by Quine, who had
been sniping at some of the core doctrines, notably the concept of
analyticity, ever since his first exposure to Carnap's philosophy as a
Harvard postgraduate visiting Carnap in Vienna. 
Quine's critique modulated into outright repudiation of the central
tenets of Carnap's philosophy in the his ``Two Dogmas of
Empiricism''. 
It was not long before an attack came on another flank from Saul
Kripke, who dismantled the identification of analyticity and necessity
which were inter-definable in Carnap's conceptual scheme and thereby
invented a new kind of metaphysics. 

The idea of Russell and Carnap, that philosophy should consist of
logical analysis and of Carnap that it should also be conducted
formally both disappeared. 
Symbolic or mathematical logic does play a substantial role in
analytic philosophy, but it is the meta-theoretic techniques of
mathematical logic which are used in philosophy. 
There is no general adoption of formality as a way of achieving rigour
in philosophy, no general recognition that there is a deficit in
rigour might requires such a remedy. 

Another impediment to the realization of Leibniz's project was, during
Carnap's lifetime, beginning to be dissolved. 
The digital electronic computer was invented and the first steps
toward using this technology for the automation of deduction were in
progress. 
The torch was about to pass from philosophy, not to mathematical
logic, but to Computer Science. 

\section{Information Technology}

These two philosophers strove to realize ambitions which were soon to
be made more feasible by the invention of the stored program digital
computer, and with it another academic discipline, Computer Science,
which over the second half of the 20th century would conduct an
enormous amount of research relevant to both of their projects.
The first home of logic, Philosophy, and the new discipline of
mathematical logic, treated logic in a meta-theoretically.
They took formal logic primarily as something to be studied rather
than directly used (by contrast with the earlier work by Frege and
Russell and Whitehead in which large parts of mathematics were
formally derived).
Computer Science, as well as conducting theoretical and
meta-theoretical investigations relevant to computing, found reason to
undertake proofs formally, with the assistance of their computing
machinery.

For these reasons, the primary academic locus of research relevant to the
ambitions of Leibniz and Carnap moved from Philosophy to Computer
Science.
However, the idea of using computers for science was more
predominantly pursued by purely computational rather than formally
logical methods.
I hope to make this distinction clearer, to make the case that
logical methods deserve to be given special consideration, to give a
philosophical context in which it make sense to do that on a
substantial scale, and to consider some aspects of how this might be progressed.

\subsection{Alan Turing}

Alan Turing was a mathematical logician, computational engineer and a
visionary thinker whose ideas on artificial intelligence have been
influential on research in the automation of reasoning.

For our present purposes it is primarily his writing on artificial
intelligence which is of interest, as encompassing objectives even
broader than our own, but Turing was an important figure in a
milestone in our understanding of computation which was reached during
the 1930s.

One of the tenets of the philosopher and mathematician David Hilbert
in the early part of the 20th century was that all definite
mathematical problems are susceptible of solution.
This thesis was held to be equivalent to the effective decidability of
validity in first order predicate logic, which was called the \emph{entscheidungsproblem}.
To make the problem precise enough to be given a definitive
mathematical answer it was necessary to make precise the notion of effective calculability.
This resulted in several different logicians putting forward different
notations in which arbitrary algorithms (methods of solution) could be
expressed.
Church came up with concise notation for functional abstraction known
as ``the lambda calculus'', Kleene with a system for defining
numerical functions by recursion, Emil Post came up with a system
based on transforming strings using a set of ``productions'' which
defined transformations on the strings.
All these systems provided ways of defining effectively computable
functions over the natural numbers, but the one which looked most like
a description of a computing machine was that invented by Alan Turing,
since called the Turing machine \cite{turingOCN}.

These different ways of describing effective computational processes
all turned out to be similarly expressive, and this remarkable
discovery underpinned the idea that they did indeed all capture the
notion of effective calculability.
The \emph{entscheidungsproblem} having by these means been made more
definite, Church and Turing independently solved the problem by
exhibiting problems which were provably unsolvable (by any effective procedure).

This result limits what could possibly be achieved by Leibniz's
\emph{calculus ratiocinator}, as did G\"odel's previous result on the
incompleteness of arithmetic.
It seems from Leibniz's description that he probably did imagine that
any definite question within the scope of the scientific knowledge
codified in the \emph{lingua characteristica} would be answerable
using his calculus and a sufficiently rapid calculator.
The G\"odel and Church-Turing results show that this cannot be the case.
I will look a little closer later at these and other limiting factors
and consider their significance for ``the project''.

Turing also wrote on Artificial Intelligence, and his conception of
Artificial Intelligence provides an alternative ideal for the
automation of reason which is not predicated on machines achieving the
impossible.
His seminal paper in this area was \emph{Computing Machinery and Intelligence}\cite{turingCMI}.
Turing's essential idea was that human intelligence, though very
differently implemented, is not fundamentally distinct from or more
capable than the kind of information processing which could be
undertaken by a sufficiently complex and powerful Turing machine.
In addressing the question whether a machine can think, Turing
described an ``imitation game'' to make this question more precise,
this later became known as the Turing test.
The Turing test involves human beings interacting with a person and a
machine through similar interfaces which conceals which of the two was
involved, i.e. using a keyboard to converse with someone or something
in a distant or private place.
If the observer cannot tell the difference between the man and the
machine when he interacts with it in this way, then perhaps we should
be ready to acknowledge that the machine thinks, and hence exhibits
some important aspects of human intelligence.

\subsection{The Science of Computing}

During the first half of the 20th century the technology of
computation had  moved rapidly.
The Turing machine provided a very simple abstract prototype for an
important transition, from special purpose to general purpose
computational engines.
It anticipated the general purpose stored program digital computer,
and these relatively complex calculating machines were just becoming
technically feasible.
They first appeared in the 1940s using technologies such as
electromagnetic relays, and the electronic vacuum tube.
Soon the transistor emerged, and the technology of computation began a
long period of progressive miniaturization yielding ever smaller and
faster building blocks for digital computers.

With the invention of the digital computer came the new academic
discipline of Computer Science, and enthusiasm for formal systems and
the automation of reason passed from Philosophy and Mathematical Logic
(itself just an infant) to Computer Science.
Computer scientists were interested in formal languages because they
allowed algorithms to be described precisely for execution by a computer.
The complexity of these algorithms rapidly increased and correctness
became an issue.
How could one be sure that the instructions for achieving some
computational objective would realize their intended aim?
Since formally defined algorithms could be construed as mathematical
entities, it seems that certainty might best be realized by a
mathematical (i.e. a deductive) proof.
Unfortunately these proofs turned out themselves to be even more
complex than the programs whose correctness they were intended to
show, and the questions then arose how one could facilitate the
construction of these proofs and how one could be sure that the proofs
were correct?
The computer itself provided one answer to these questions.
The computer could assist in the construction of the proofs, and since
it is in the nature of formal proofs that their correctness can be
checked mechanically, they could also check the proofs.
In this way, that part of Computer Science which was particularly
interested in ensuring that computer programs are correct was drawn
into the the use of formal notations, formal deductive systems and the
automation of reason.

Meanwhile another branch of Computer Science developed which sought to
program computers so that instead of merely doing large scale
drudgery, they exhibited some kind of intelligence.
This was the field of Artificial Intelligence, and later the related
interdisciplinary enterprise of Cognitive Science.
Within these disciplines a variety of approaches to the problem were
pursued, but despite this variety a single important cleavage was
captured by the contrast between ``neats'' and ``scruffs''.
The project around which this book is constructed may be thought of
leading towards an extremely ``neat'' AI, so this distinction can be
helpful in initial sketches of the project.

The distinction between neats and scruffs may be seen through the
contrast between ``connectionist'' AI and methods based on theorem proving.
The connectionist approach to AI approximates the human brain by
simulation of a neural network using highly parallel processing.
The idea is to devise a network which is capable of learning and then
to teach it the required skills.
If such a system achieved a competence in a complex deductive science
it would do so indirectly.
Such competence would be an application of its general intelligence,
not a source or means of attaining that intelligence.

``neats'', on the other hand, think more like Leibniz.
For them the intelligent capabilities are build on a foundation which
includes a formal language for representing propositional knowledge
and a deductive inferential capability.
This does not necessarily mean that they are aimed at different
problem domains to the ``scruffs''.
Neats may seek systems capable of ordinary language discourse and
common sense reasoning, but still approach this on logical foundations
which would be unfamiliar to most people.

The neat/scruffy distinction is concerned with means rather than ends.
There is a related distinction which concerns ends rather than means.
This is the distinction between taking the aim of a research programme
to be the replication of some aspect (or the whole of) human
intelligence, of whether some other characterization, independent of
the methods or competence of human beings, is give of the objective of
the research.

\subsection{Automation and Intelligence}\label{AutomationAndIntelligence}

We arrive then at my first characterization of the project which this
philosophical dissertation seeks to underpin.

The aim of the project is a comprehensive formalization of the
deductive aspects of philosophy, mathematics, empirical science and
engineering design.

\subsection{Some Distinctions}

Developments since Leibniz and Carnap give us better insights into
the extent to which their projects are realizable.
The diversity of related research which has been undertaken enables us
to discriminate many different similar kinds of project and to
identify more precisely the kind of projects which Leibniz and Carnap
might have entertained if they were working today.

\section{The Philosophy}\label{ThePhilosophy}

Here are the bare bones of a philosophical framework to underpin ``the project''.

The philosophy is positivistic, insofar as it delineates a particular
approach to empirical science and its application, which it is
suggested may in some ways be preferable to extant methods.
In this I am not being prescriptive, I do not assert that science
\emph{should} be conducted in this way.

The framework is, in the first instance, conceptual.
This consists to a large extent in the choice of particular meanings
for terms which have a long history of shifting usage.
Some of the most fundamental of these come in pairs as dichotomies,
i.e. disjoint concepts which together exhaust some significant larger
domain.
The most fundamental of these is the distinction between logical and
empirical truths.
Simple though it might appear to be, it is a source of endless
philosophical controversy, and it will therefore be necessary to
consider in detail the evolution of this distinction over its entire
history and come to as precise an understanding of this fundamental
cleavage as possible.

Such fundamental concepts are not mere accidents of language, and are
one element of the philosophical framework which we may think
constitute a kind of \emph{metaphysics}.
\footnote{On this my disagreement with Carnap lies only in the scope
  of applicability of the term \emph{metaphysics}.
It does not constitute metaphysics under either of the two principle
categories which constitute metaphysics for Carnap.
I take great care to make the meaning of these concepts definite and
clear, so meaninglessness, I hope, is avoided.
Nor does this kind of metaphysics constitute, in our framework,
\emph{a priori} justifications about \emph{synthetic} claims.
}%footnote
