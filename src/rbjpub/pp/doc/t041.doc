=IGN
$Id: t041.doc,v 1.7 2011/02/21 12:02:40 rbj Exp $
=TEX

The idea is to obtain an exotic model for illative lambda-calculi by methods analogous to those employed for set theory in \cite{rbjt027}, and then to use that as a semantic foundation for the definition of one or more finitary illative lambda-calculi with systems of type assignment.

The work is conducted by conservative extension in the context of a higher order set theory established axiomatically in HOL, which I will refer to as HOL/GSU, or just GSU\cite{rbjt042}.
The end result is intended to be a semantic embedding of an illative lambda-calculus into HOL/GSU.
This end is to be realised in stages as follows:

\begin{itemize}
\item Establish an infinitary illative combinatory logic.
\begin{itemize}
\item Define the infinitary syntax by transfinite recursion in GSU.
\item Define the semantics, by determining a partial equivalence relation and a notion of reducibility over the syntax.
This involves taking a least fixed point of a recursive definition of the relation and proving a result analogous to the Church-Rosser theorem to establish coherence and non-triviality of the results.
\end{itemize}
\item Using this as a semantic domain, a new type is then introduced, which will be the domain over which the operations in the illative lambda-calculus will be defined. 
The theory is then developed by defining further operations as necessary and proving result which establish the required type assignment and inference rules for the embedded calculus.
\end{itemize}

At this moment after many iterations the syntax of the infinitary system may now be stable, and I have begun work on the semantics, which remains at an early stage.

\subsection{Type Assignments}

The systems of type assignments I am interested in have the following features:

\begin{itemize}
\item A universal type.
\item Dependent product and sum (function and pair) types.
\item A heirarchy of Universes, not all well-founded, each closed under dependent constructions and (this has the effect of power set and replacement).
\item A well founded part in which classical mathematics can be conducted in the normal way, and which admits arbitrarily risky axiomatic extensions analogous to (possibly even identical to) large cardinal axioms (with no greater risk here than in ZFC).
\end{itemize}

The difficult question with such a shopping list, is whether it can be consistently fulfilled, and the principal purpose of this document is to explore an idea about how to construct an interpretation which might allow the equiconsistency of the systems considered here with ZFC (plus large cardinals where appropriate) to be established.
Having said that, the procedure is \emph{semantics first}, so I aim to construct the interpretation first, and then to derive logical systems of which it is an interpretation.
This method guarantees that the resulting system is consistent relative to my set theory (which is `A Higher Order Theory of Well-Founded Sets (with Urelements)' (GSU\index{GSU}), see \cite{rbjt042}).
This is a modification of the pure set theory GS to admit urelements.

In the talk which follows about syntax and semantics there are two levels involved, that of the infinitary calculus (which is the interpretation constructed in GSU) and that of the finitary calculus which will be based on it.
From the point of view of our end objective, all aspects of the infinitary calculus are part of the semantics of that finitary language.

\subsection{Consistency}

A few more words about consistency may be in order.

The approach here is to ensure consistency in the desired logic by working from semantics to proof rules.
The logic determined by proof rules is bound to be consistent because the proof rules are either theorems proven about the chosen semantic domain or else derived rules implemented in our metalanguage for reasoning in the new language.
This is a natural outcome of the method which consists in implemented the desired language as a shallow embedding in a higher-order set theory.

In fact, all the action in this document precedes the semantic embedding, it is preliminary work on the semantic domain in which the embedding will take place.

Adoption of this method does not in itself solve the consistency problem, the problem appears in the necessary semantic preliminaries for the embedding.
To succeed it is necessary to understand how the consistency problem appears and have some idea of how it can be resolved.
In this case, the consistency problem for an illative lambda-calculus is to be resolved by providing a syntactic model in an infinitary illative combinatory logic.
The consistency problem re-appears in obtaining a satisfactory account of the infinitary combinatory system.
The infinitary syntax only becomes a model when the illative combinator of equivalence is defined over it.
The definition of this is recursive and is not well founded.
It is probable that if there was a total solution then one could use this with a `liar' (Epimenides) -like construction to obtain a contradiction (or possibly one can get to Curries paradox even easier).
It is not therefore to be expected that this combinator will be total.
Allowing this equivalence to be partially defined, in particular taking it to be the least fixed point of the defining equations under an appropriate ordering, is what gets us out of the paradox and should yield a good semantics.
This device is to be combined with steps intended to make this semantics as rich as a strong first order set theory (one in which inaccessible cardinals can be proven to exist).
Whether this will also yield a system of type assignments along the lines desired remains to be seen.

The equivalence relation is compounded from several components of which only one is `illative' and contentious.
There is a question how to organise these separate components and how much to do prior to devising the functor of which the least fixed point gives the semantics of equivalence.
There is a pragmatic reason for doing as much as possible beforehand.
If we first define the equivalence arising from all the pure combinators (including the infinitary ones), and then create a new type using these equivalence classes, we have then maximised what we will be able to do with rewriting in our final model, for two terms which are equivalent in this sense will be equal in the new type.

The final step will not yield an equivalence which can be incorporated into a new type definition. 

\section{The Infinitary Interpretation}

I have had quite a few (lost count) iterations in my conception of the syntax of the infinitary system which I use for the semantics of the target illative lambda-calculus.

My first attempt was an infinitary illative lambda calculus in which there was infinitary abstraction (abstraction over infinitely many variables at once) and application (application of an infinitary abstraction to an infinite collection of arguments).
There was something unsatisfactory about this approach (a muddle about the scope of the variables, which I used to tag the arguments in an application) and by the time I had sorted it out the infinitary abstraction had been dumped (in favour of infinitary function displays).
Unfortunately the new version left me with five syntactic constructors, and, because the (infinitary) abstract syntax is hand cranked, I have a strong incentive to keep its complexity to an absolute minimum.
So I decided to ditch abstraction, and with it, variables.

Several attempts on I now have an infinitary illative combinatory logic with just one syntactic constructor.

I call this syntax infinitary because the syntax has large (inaccessible) cardinality.
It isn't actually a deductive system, but it is a language, for which we have syntax and semantics.
We have a notion of truth and can prove the truth of expressions of our infinitary language in the metalanguage (which is HOL/GSU, a higher order set theory).

The semantic intent explains the infinitary nature of the system considered, this is so that we have underlying our ultimate language (which will be a finitary untyped illative lambda-calculus with a system of type assignments) a basis for the development of exactly the same (``classical'') applicable mathematics as is more often considered in the context of ZFC or HOL.
For this purpose there are intended to be, within the ontology, structures which mirror or mimic the hierarchy of well-founded sets, and particularly, full function spaces over well founded subsets of the universe.

The idea is to define a kind of syntactic interpretation for the lambda-calculus and to give a semantics to it.
Lambda terms in the target language will denote equivalence classes of infinitary combinators in the underlying language.
The equivalence classes over the combinators are generated by the defining equations for the combinators except for the sole illative combinator, which will be equivalence (aka convertibility).
The tricky bit is to determine the semantics of this equivalence relation, since the formal definition follows the previous sentence in being recursive, and the recursion will probably not be well-founded.
This is done by treating it as a partial equivalence, giving the recursive definition in the form of a functor over partial approximations to convertibility, and then taking the least fixed point of this functor, and praying that there will be enough in there.

An important departure from the method adopted for non-well-founded set theory in \cite{rbjt027} is the acceptance that the domain of discourse will be full of junk (e.g. non-normalising terms), and that the application of a lambda-calculus based on this interpretation will depend on reasoning almost exlusively within the confines of well-behaved subdomains which are delimited by an appropriate system of type-assignment (even though the terms themselves will be un-typed).
This is intended to yield something which will look a bit like a typed lambda-calculus with subtyping and a universal type (plus some other exotic features to make it at least as strong as ZFC) but which differs from it in a manner similar to the difference between the simply-typed lambda-calculus and a system of type assignments to the pure lambda-calculus.

=SML
open_theory "misc3";
force_new_theory "Ûicombİ";
force_new_pc Û"'icomb"İ;
merge_pcs ["'savedthm_cs_¶_proof"] "'icomb";
new_parent "equiv";
set_merge_pcs ["misc31", "'icomb"];
=TEX

\subsection{Infinitary Syntax}

The syntax of an infinitary illative combinatory logic is to be encoded as sets in a higher order set theory.

Since I will probably have to prove something like the Church-Rosser theorem and the syntax can be made very simple, this will be a bare bones treatment of the syntax, by contrast with my previous similar enterprise for non-well-founded set theory in \cite{rbjt027}.

There will be just one constructor, which is the ordered pair constructor constrained to operate on sequences of combinators.
We can therefore go immediately to specification of the required closure condition for the syntax.

The closure condition is:

¹HOLCONST
Ü ÛCrepClosedİ: 'a GSU SET ­ BOOL
÷üüüüüüüüüüü
Ü µ s· CrepClosed s ¤
Ü	(µc i· Fun‰u i ± Ordinal‰u (Dom‰u i) ± X‰u (Ran‰u i) € s ´ c í‰u i  s)
°

The well-formed syntax is then the smallest set closed under these constructions.

¹HOLCONST
Ü ÛCsyntaxİ : 'a GSU SET
÷üüüüüüüüüüü
Ü Csyntax = ¥{x | CrepClosed x}
°

I have contrived to arrange the semantics which follows as a monotone function over a complete partial order, so that when I start to look for fixed points of the semantic functor (to give the equivalence relation for an interpretation of an illative lambda-calculus) I can look at the least and greatest fixed points, and either prove one of them total or otherwise employ them to find a total fixed point.

\subsubsection{Closure}\label{Closure}

=GFT
Ûcrepclosed_csyntax_lemmaİ =
	ô CrepClosed Csyntax
=TEX
=GFT
Ûcrepclosed_csyntax_thmİ =
	ô µ c i· Fun‰u i
		± Ordinal‰u (Dom‰u i)
		± (µ x· x  X‰u (Ran‰u i) ´ x  Csyntax)
         ´ c í‰u i  Csyntax
=TEX
=GFT
Ûcrepclosed_csyntax_thm2İ =
   ô µ c i· Fun‰u i
		± Ordinal‰u (Dom‰u i)
		± (µ x· x ‰u Ran‰u i ´ x  Csyntax)
	´ c í‰u i  Csyntax
=TEX
=GFT
Ûcrepclosed_csyntax_lemma1İ =
	ô µ s· CrepClosed s ´ Csyntax € s
=TEX
=GFT
Ûcrepclosed_csyntax_lemma2İ =
	ô µ p· CrepClosed {x|p x} ´ (µ x· x  Csyntax ´ p x)
=TEX

\ignore{
=SML
val CrepClosed_def = get_spec ¬CrepClosed®;
val Csyntax_def = get_spec ¬Csyntax®;

set_goal([], ¬CrepClosed Csyntax®);
val _ = a (rewrite_tac [CrepClosed_def] THEN strip_tac);
val _ = a (rewrite_tac [Csyntax_def, CrepClosed_def]
	THEN REPEAT strip_tac
	THEN REPEAT (asm_ufc_tac[]));
val _ = a (lemma_tac ¬(µ x'· x'  X‰u (Ran‰u i) ´ x'  s)®
		THEN1 (REPEAT strip_tac THEN REPEAT (asm_ufc_tac[])));
val _ = a (asm_ufc_tac[] THEN asm_rewrite_tac []);
val crepclosed_csyntax_lemma = pop_thm();

val crepclosed_csyntax_thm = save_thm ("crepclosed_csyntax_thm",
	pure_rewrite_rule [get_spec ¬CrepClosed®,
		get_spec ¬$€:('a SET­('a SET ­BOOL))®] crepclosed_csyntax_lemma);

val crepclosed_csyntax_thm2 = save_thm ("crepclosed_csyntax_thm2",
	rewrite_rule [get_spec ¬X‰u®] crepclosed_csyntax_thm);

local val _ = set_goal([], ¬µs· CrepClosed s ´ Csyntax € s®);
val _ = a (rewrite_tac [get_spec ¬Csyntax®]
	THEN prove_tac[]);
in val crepclosed_csyntax_lemma1 = save_pop_thm "crepclosed_csyntax_lemma1";
end;

local val _ = set_goal([], ¬µp· CrepClosed {x | p x} ´ µx· x  Csyntax ´ p x®);
val _ = a (rewrite_tac [get_spec ¬Csyntax®] THEN REPEAT strip_tac);
val _ = a (asm_fc_tac[]);
in val crepclosed_csyntax_lemma2 = save_pop_thm "crepclosed_csyntax_lemma2";
end;
=TEX
}%ignore

\subsubsection{Recursion and Induction Principles and Rules}\label{Induction}

We need to be able to define functions by recursion over this syntax.
To do that we need to prove that the syntax is well-founded.
This is the case relative to the transitive closure of the membership relation, but to get a convenient basis for reasoning inductively over the syntax and for defining functions by recursion over the syntax it is best to define an ordering in terms of the syntactic constructors for the syntax.

This could be done strictly over the well-formed syntactic constructs, but this would involve more complexity both in the definitions and in subsequent proofs than by defining it in terms of the syntactic constructors whatever they are applied to.

¹HOLCONST
Ü ÛCscPrecİ : 'a GSU REL
÷üüüüüüüüüüü
Ü µÁ Ç· CscPrec Á Ç ¤ ¶c i· Á ‰u (Ran‰u i) ± Ç = c í‰u i
°

=GFT
ÛCscPrec_tc__thmİ =
	ô µ x y· CscPrec x y ´ tc $‰u x y

Ûwell_founded_CscPrec_thmİ =
	ô well_founded CscPrec
=TEX

\ignore{
=SML
val CscPrec_def = get_spec ¬CscPrec®;

local val _ = set_goal([], ¬µx y· CscPrec x y ´ tc $‰u x y®);
val _ = a (rewrite_tac (map get_spec [¬CscPrec®]));
val _ = a (REPEAT strip_tac THEN asm_rewrite_tac [í‰u_tc_thm]);
val _ = a (all_fc_tac [tc‰u_incr_thm]);
val _ = a (fc_tac [tc‰u_Ran‰u_thm]);
val _ = a (lemma_tac ¬$‰u›+ i (c í‰u i)®
	THEN1 rewrite_tac [tc‰u_í‰u_right_thm]);
val _ = a (all_fc_tac [tc‰u_trans_thm]);
val _ = a (POP_ASM_T ante_tac THEN rewrite_tac[get_spec ¬$‰u›+®]);
in val CscPrec_tc__thm = pop_thm();
end;

local val _ = set_goal ([], ¬well_founded CscPrec®);
val _ = a (rewrite_tac [get_spec ¬well_founded®]);
val _ = a (REPEAT strip_tac);
val _ = a (asm_tac (µ_elim ¬s® gsu_cv_ind_thm));
val _ = a (lemma_tac ¬µ x· (µ y· tc $‰u y x ´ s y) ´ s x®
	THEN1 REPEAT strip_tac);
(* *** Goal "1" *** *)
val _ = a (lemma_tac ¬µ y· CscPrec y x ´ s y®
	THEN1 (REPEAT strip_tac THEN all_fc_tac [CscPrec_tc__thm]
		THEN asm_fc_tac []));
val _ = a (asm_fc_tac[]);
(* *** Goal "2" *** *)
val _ = a (asm_fc_tac[]);
val _ = a (asm_rewrite_tac[]);
in val well_founded_CscPrec_thm =  save_pop_thm "well_founded_CscPrec_thm";
end;
=TEX
}%ignore

=GFT
Ûwell_founded_tcCscPrec_thmİ =
	ô well_founded (tc CscPrec)
=TEX

\ignore{
=SML
set_goal([], ¬well_founded (tc CscPrec)®);
val _ = a (asm_tac well_founded_CscPrec_thm);
val _ = a (fc_tac [wf_tc_wf_thm]);
val well_founded_tcCscPrec_thm = save_pop_thm ("well_founded_tcCscPrec_thm");
=TEX
}%ignore

=SML
val ÛCSC_INDUCTION_Tİ = WFCV_INDUCTION_T well_founded_CscPrec_thm;
val Ûcsc_induction_tacİ = wfcv_induction_tac well_founded_CscPrec_thm;
=TEX

The set Csyntax gives us the syntactically well-formed phrases of our language.
It will be useful to have some predicates which incorporate well-formedness, which are defined here.

=GFT
Ûcsc_fc_thmİ =
   ô µ x· x  Csyntax ´
	(¶c i· Fun‰u i ± Ordinal‰u(Dom‰u i)
	± (µ y· y ‰u Ran‰u i ´ y  Csyntax)
	± x = c í‰u i)
=TEX
=GFT
Û³š‰u__csyntax_lemmaİ =
   ô ³ š‰u  Csyntax

Û³š‰u__csyntax_lemma2İ =
   ô µ x· x  Csyntax ´ ³ x = š‰u

Û³š‰u__csyntax_lemma3İ =
   ô µ V x· x  V ± V € Csyntax ´ ³ x = š‰u
=TEX

\ignore{
=SML
local val _ = set_goal([], ¬µ x· x  Csyntax ´ (¶c i· Fun‰u i ± Ordinal‰u(Dom‰u i) ± (µ y· y ‰u (Ran‰u i) ´ y  Csyntax) ± x = c í‰u i)
®);
val _ = a (contr_tac);
val _ = a (lemma_tac ¬CrepClosed (Csyntax \ {x})®
	THEN1 (rewrite_tac [get_spec ¬CrepClosed®] THEN REPEAT strip_tac));
(* *** Goal "1" *** *)
val _ = a (lemma_tac ¬(µy· y  X‰u (Ran‰u i) ´ y  Csyntax)®
	THEN1 (REPEAT strip_tac));
(* *** Goal "1.1" *** *)
val _ = a (all_asm_fc_tac []);
(* *** Goal "1.2" *** *)
val _ = a (ALL_FC_T rewrite_tac [crepclosed_csyntax_thm]);
(* *** Goal "2" *** *)
val _ = a (lemma_tac ¬(µy· y ‰u (Ran‰u i) ´ y  Csyntax)®
	THEN1 (REPEAT strip_tac));
(* *** Goal "2.1" *** *)
val _ = a (lemma_tac ¬y  X‰u (Ran‰u i)®
	THEN1 (asm_rewrite_tac [X‰u_def]));
val _ = a (all_asm_fc_tac []);
(* *** Goal "2.2" *** *)
val _ = a (spec_nth_asm_tac 5 ¬c®);
val _ = a (spec_nth_asm_tac 1 ¬i® THEN all_asm_fc_tac []);
val _ = a (swap_nth_asm_concl_tac 1 THEN asm_rewrite_tac[]);
(* *** Goal "3" *** *)
val _ = a (asm_tac crepclosed_csyntax_lemma1);
val _ = a (spec_nth_asm_tac 1 ¬Csyntax \ {x}®);
val _ = a (spec_nth_asm_tac 1 ¬x®);
in val csc_fc_thm = save_pop_thm "csc_fc_thm";
end;

set_goal([], ¬³ š‰u  Csyntax®);
a (contr_tac);
a (fc_tac [csc_fc_thm] THEN POP_ASM_T ante_tac THEN rewrite_tac[]);
val ³š‰u__csyntax_lemma = save_pop_thm "³š‰u__csyntax_lemma";

set_goal([], ¬µx· x  Csyntax ´ ³ x = š‰u®);
a (contr_tac THEN var_elim_nth_asm_tac 1
	THEN POP_ASM_T ante_tac
	THEN rewrite_tac [³š‰u__csyntax_lemma]);
val ³š‰u__csyntax_lemma2 = save_pop_thm "³š‰u__csyntax_lemma2";
 
set_goal([], ¬µV x· x  V ± V € Csyntax ´ ³ x = š‰u®);
a (REPEAT strip_tac
	THEN lemma_tac ¬x  Csyntax® THEN1 PC_T1 "hol1" asm_prove_tac[]
	THEN fc_tac [³š‰u__csyntax_lemma2]);
val ³š‰u__csyntax_lemma3 = save_pop_thm "³š‰u__csyntax_lemma3";

add_pc_thms "'icomb" [³š‰u__csyntax_lemma];
set_merge_pcs ["misc31", "'icomb"];
=TEX
}%ignore

=GFT
Ûcsc_fc_thm2İ =
   ô µc i· c í‰u i  Csyntax ´ Fun‰u i ± Ordinal‰u (Dom‰u i) ± (µ x· x ‰u (Ran‰u i) ´ x  Csyntax)

Ûcscprec_fc_thmİ =
   ô µ c i x· x ‰u Ran‰u i ´ CscPrec x (c í‰u i)
=TEX

\ignore{
=SML
local val _ = set_goal([], ¬µc i· c í‰u i  Csyntax ´ Fun‰u i ± Ordinal‰u (Dom‰u i) ± (µ x· x ‰u (Ran‰u i) ´ x  Csyntax)®);
val _ = a (REPEAT strip_tac THEN fc_tac[csc_fc_thm] THEN all_var_elim_asm_tac THEN REPEAT strip_tac
	THEN asm_fc_tac[]);
in val csc_fc_thm2 = save_pop_thm "csc_fc_thm2";
end;

local val _ = set_goal([], ¬µc i x· x ‰u (Ran‰u i) ´ CscPrec x (c í‰u i)®);
val _ = a (rewrite_tac [get_spec ¬CscPrec®]);
val _ = a (REPEAT strip_tac);
val _ = a (¶_tac ¬c® THEN ¶_tac ¬i® THEN asm_rewrite_tac[]);
in val cscprec_fc_thm = save_pop_thm "cscprec_fc_thm";
end;
=TEX
}%ignore

Inductive proofs using the well-foundedness of ScPrec are fiddly.
The following induction principle simplifies the proofs.

=GFT
Ûcsyn_induction_thmİ =
   ô	(µc i· Fun‰u i ± Ordinal‰u(Dom‰u i)
		± (µx· x ‰u (Ran‰u i) ´ x  Csyntax ± p x)
		´ p (c í‰u i))
	´ (µ x· x  Csyntax ´ p x)
=TEX

\ignore{
=SML
set_goal([], ¬(µc i· Fun‰u i ± Ordinal‰u(Dom‰u i) ± (µx· x ‰u (Ran‰u i) ´ x  Csyntax ± p x) ´ p (c í‰u i))
	´ (µ x· x  Csyntax ´ p x)®);
a (REPEAT strip_tac);
a (POP_ASM_T ante_tac THEN csc_induction_tac ¬x® THEN strip_tac);
a (fc_tac [csc_fc_thm]);
a (lemma_tac ¬µ x· x ‰u Ran‰u i ´ x  Csyntax ± p x®
	THEN (REPEAT strip_tac THEN all_asm_fc_tac[] THEN_TRY asm_rewrite_tac[]));
a (lemma_tac ¬CscPrec x t®
	THEN1 (asm_rewrite_tac[CscPrec_def]));
(* *** Goal "1" *** *)
a (¶_tac ¬c® THEN ¶_tac ¬i® THEN asm_rewrite_tac[]);
(* *** Goal "2" *** *)
a (fc_tac [tc_incr_thm] THEN all_asm_fc_tac[]);
val csyn_induction_thm = save_pop_thm "csyn_induction_thm";
=TEX
}%ignore

Using this induction principle an induction tactic is defined as follows:

=SML
fun Ûicomb_induction_tacİ t (a,c) = (
	let val l1 = mk_app (mk_Ì (t,c), t)
	    and l2 = mk_app (mk_app (mk_const ("", ”'a GSU ­ 'a GSU SET ­ BOOL®), t),
					mk_const ("Csyntax", ”'a GSU SET®))
	in  let val l3 = mk_µ (t, mk_´ (l2, l1))
	in  LEMMA_T l1 (rewrite_thm_tac o rewrite_rule[])
	THEN DROP_ASM_T l2 ante_tac
	THEN LEMMA_T l3 (rewrite_thm_tac o rewrite_rule[])
	THEN bc_tac [csyn_induction_thm]
	THEN rewrite_tac[]
	THEN strip_tac
	end end) (a,c);
=TEX

This tactic expects an argument $t$ of type $TERM$ which is a free variable of type $'a GSU$ whose sole occurrence in the assumptions is in an assumption ¬‘t®  Csyntax®, and results in two subgoals, one requiring a proof for atomic and the other for compound formulae (with the benefit of the induction hypothesis in the assumptions).

\subsubsection{Recursion Theorem}\label{Recursion}

The following recursion theorem supports definition by primitive recursion of functions over the syntax.

The following function provides domain restriction of a function over 'a GSU.
Since this is an operation on total functions, the effect is achieved by delivering a function which returns the same value for all arguments outside the restricted domain.
The purpose is to constrain recursion to be well founded, so the possibility of returning a function completely unconstrained in what it does off the restricted domain does not suffice (we would not be able to prove that the domain restriction had done anything at all).


=SML
declare_infix(310, "ò‰u‰e");
=TEX

¹HOLCONST
Ü $Ûò‰u‰eİ : 'a GSU ­ ('a GSU ­ 'b) ­ ('a GSU ­ 'b)
÷üüüüüüüüüüü
Ü µs f· s ò‰u‰e f = Ìt· if t ‰u s then f t else Åx·T
°


A recursion lemma suitable for consistency proofs of primitive recursive definitions over our syntax can now be proven:

=GFT
Ûcsc_recursion_lemmaİ =
   ô µaf· ¶f· µc i· f (c í‰u i) = af ((Ran‰u ò‰u‰e i) f) c i
=TEX


\ignore{
=SML
val ò‰u‰e_def = get_spec ¬$ò‰u‰e®;

set_goal([], ¬µ(af:('a GSU ­ 'b) ­ 'a GSU ­ 'a GSU ­ 'b)· ¶(f:'a GSU ­ 'b)·
	µc i· f (c í‰u i) = af ((Ran‰u i) ò‰u‰e f) c i®);
val _ = a (REPEAT strip_tac);
val _ = a (lemma_tac ¬¶g:((('a)GSU­'b)­('a)GSU­'b)·
	g = Ìf x· if (¶c i· x = c í‰u i) 
		then af ((Ran‰u (Snd‰u x)) ò‰u‰e f) (Fst‰u x) (Snd‰u x)
		else Åx·T®
	THEN1 prove_¶_tac);
val _ = a (lemma_tac ¬g respects CscPrec®
	THEN1 (asm_rewrite_tac [get_spec ¬$respects®] THEN REPEAT strip_tac));
(* *** Goal "1" *** *)
a (cond_cases_tac ¬¶ c i· x = c í‰u i®);
a (LEMMA_T ¬(Ran‰u (Snd‰u x)) ò‰u‰e g' = (Ran‰u (Snd‰u x)) ò‰u‰e h® rewrite_thm_tac);
a (rewrite_tac [ò‰u‰e_def] THEN strip_tac);
a (cond_cases_tac ¬x' ‰u Ran‰u (Snd‰u x)®);
a (lemma_tac ¬CscPrec x' x® THEN1 (rewrite_tac [get_spec ¬CscPrec®]));
(* *** Goal "1.1" *** *)
a (¶_tac ¬c® THEN ¶_tac ¬i® THEN asm_rewrite_tac[]);
a (POP_ASM_T ante_tac THEN asm_rewrite_tac[]);
(* *** Goal "1.2" *** *)
a (fc_tac [tc_incr_thm]);
a (asm_fc_tac []);
(* *** Goal "2" *** *)
a (¶_tac ¬fix g®);
a (asm_tac well_founded_CscPrec_thm);
a (all_fc_tac [get_spec ¬fix®]);
a (POP_ASM_T ante_tac THEN asm_rewrite_tac[] THEN strip_tac);
a (GET_NTH_ASM_T 1 (once_rewrite_thm_tac o map_eq_sym_rule));
a (rewrite_tac[] THEN REPEAT strip_tac);
a (cond_cases_tac ¬¶ c' i'· c = c' ± i = i'®);
a (spec_nth_asm_tac 1 ¬c®);
a (spec_nth_asm_tac 1 ¬i®);
val csc_recursion_lemma = save_pop_thm "csc_recursion_lemma";
=TEX
}%ignore

This is (when proven) plugged into proof context {\it 'icomb} for use in consistency proofs.

=SML
add_¶_cd_thms [csc_recursion_lemma] "'icomb";
set_merge_pcs ["misc31", "'icomb"];
=TEX

\subsubsection{Auxiliary Concepts}

This is just to test the recursion theorem.

¹HOLCONST
Ü ÛCscRankİ : 'a GSU ­ 'a GSU
÷üüüüüüüüüüü
Ü µc i· CscRank (c í‰u i) =  Ş‰u (Imagep‰u Suc‰u ((Imagep‰u ((Ran‰u i) ò‰u‰e CscRank)) (Ran‰u i)))
°

\subsubsection{Derived Syntax}

Our syntax does not include the standard finitary application.
For this we will use an infix bare subscript $c$.

=SML
declare_infix (350, "‰c");
=TEX

¹HOLCONST
Ü $Û‰cİ : 'a GSU ­ 'a GSU ­ 'a GSU
÷üüüüüüüüüüü
Ü µf a· f ‰c a = let fc = Fst‰u f
		and fa = Snd‰u f
		in fc í‰u (fa @‰u (Unit‰u (š‰u í‰u a)))
°

We also define a function corresponding to a constant constructor.
This gives a combinator with an empty list of arguments.

¹HOLCONST
Ü $ÛMkCconİ : 'a GSU ­ 'a GSU
÷üüüüüüüüüüü
Ü µn· MkCcon n = n í‰u š‰u
°

=GFT
=TEX

\ignore{
=SML
val MkCcon_def = get_spec ¬MkCcon®;

set_goal([], ¬µx:'a GSU· MkCcon x  Csyntax®);
a (strip_tac);
a (rewrite_tac [MkCcon_def]);
a (lemma_tac ¬Fun‰u (š‰u:'a GSU)
         ± Ordinal‰u (Dom‰u (š‰u:'a GSU))
         ± (µ x:'a GSU· x  X‰u (Ran‰u š‰u) ´ x  Csyntax)®
	THEN1 rewrite_tac[Ordinal‰u_š‰u]);
a (all_fc_tac [crepclosed_csyntax_thm]);
a (asm_rewrite_tac[]);
val MkCcon__Csyntax_thm = save_pop_thm "MkCcon__Csyntax_thm";

add_rw_thms [MkCcon__Csyntax_thm] "'icomb";
add_sc_thms [MkCcon__Csyntax_thm] "'icomb";
=TEX
}%ignore

Using which we name the primitive combinators.
First two finitary pure combinators:

¹HOLCONST
Ü $ÛS‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü S‰c = MkCcon (Nat‰u 0)
°

¹HOLCONST
Ü $ÛK‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü K‰c = MkCcon (Nat‰u 1)
°

Then the sole illative combinator, which is equality or equivalence.

¹HOLCONST
Ü $Ûé‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü $é‰c = MkCcon (Nat‰u 2)
°

Various useful combinatorial expressions may now be named.

=GFT
	I = Ìx·x
=TEX

¹HOLCONST
Ü $ÛI‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü I‰c = (S‰c ‰c K‰c) ‰c K‰c
°

The truth values may be represented as two projections from the argument list.

=GFT
	F = Ìx y· x
=TEX

¹HOLCONST
Ü $ÛT‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü T‰c = K‰c
°

=GFT
	F = Ìx y· y
=TEX

¹HOLCONST
Ü $ÛF‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü F‰c = K‰c ‰c I‰c
°

Conditionals may then be represented by applying the condition to the two alternatives:

=GFT
	if x then y else z = xyz
=TEX

¹HOLCONST
Ü $ÛIf‰cİ : 'a GSU ­ 'a GSU ­ 'a GSU ­ 'a GSU
÷üüüüüüüüüüü
Ü µx y z· If‰c x y z = (x ‰c y) ‰c z
°

Natural numbers may be represented as iterators:

Thus, zero is the identity function.

¹HOLCONST
Ü $Û0‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü 0‰c = I‰c
°

=GFT
	Suc n = Ìf x· f((n f)x)
	= Ìf· Ìx· f((n f)x)
	= Ìf· S (K f) (n f)
	= S (Ìf· S (K f)) n
	= S (S (K S) K) n
	= Ìf· ((S (K S) K) f) (n f)
	= Ìf· ((Ìx· ((K S) x) (K x)) f) (n f)
	= Ìf· ((Ìx· S (K x)) f) (n f)
	= Ìf· S (K f) (n f)
	= Ìf x· ((K f x) ((n f) x))
	= Ìf x· f ((n f) x)
=TEX

¹HOLCONST
Ü $ÛSuc‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü Suc‰c = S‰c ‰c (S‰c ‰c (K‰c ‰c S‰c) ‰c K‰c)
°

However, we require a representation of transfinite ordinals.
It is not clear how this could be obtained as iterators. 

It is probable that arithmetic will be arrived at in a manner more similar to that adopted in a well-founded set theory.
Such a set theory could be derived within the target illative lambda-calculus as a theory of characteristic functions, provided that we have a sufficiency of such functions, which the infinitary combinators are intended to ensure.

\subsection{Infinitary Combinators}

The idea is to get a system which is ontologically equivalent to the standard interpretations of well-founded set theory with large cardinal axioms.
By equivalent here I mean something like mutually interpretable, but the interpretations at stake here are correspondences between the ontologies, not interpretability of theories.
However, this is the case without the infinitary combinators, so what I am looking for is a bit more.

I want to ensure that the functions available as combinators are all functions with small graphs (and a decent collection of those with large graphs, but they are not our present concern).
The infinitary combinators are introduced to permit a function to be defined in extension, so long as its graph is ``small'' (i.e. smaller than the universe of discourse).

It is not entirely straightforward to do this.
The present proposal is to use three infinitary combinators.

First an inert combinator which is used to construct lists or sequences.

In the following definition the argument should be a sequence of combinators.

¹HOLCONST
Ü $Û†‰cİ : 'a GSU ­ 'a GSU
÷üüüüüüüüüüü
Ü µs· †‰c s = (Nat‰u 3) í‰u s
°

Such combinators are irreducible and injective, and it is therefore possible in principle to extract the components, for which we supply the following projection combinator.

The projection combinator takes two sequences, the first effectively determining an element of the second to be extracted.
Normally this would be supplied with two sequences of equal length and the element to be extracted from the second would be the one which corresponds to the first element of the first sequence which reduces to `T', provided that all previous values reduce to `F' (otherwise no element is selected, i.e. no reduction is possible).

¹HOLCONST
Ü $Û—‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü —‰c = MkCcon (Nat‰u 4)
°

One may think of the first sequence supplied as an argument to $—‰c$ as an ordinal $Á$ and of $—‰c\ ‰c\ Á\ ‰c\ Â$ as selecting the $Á^{th}$ element of $Â$, but when we do eventually come to the theory of ordinals we will not use this representation.
Furthermore note that this way of indicating the element to be selected is determined primarily because it is convenient for constructing infinitary `case' constructions, and hence for the definition of arbitrary functions.

To achieve this effect we need one further infinitary combinator, a mapping combinator.

This combinator expects its second argument to be a sequence, and maps its first argument over the elements of the sequence, returning a sequence which consists of the elements of the original sequence transformed by the function supplied as the first argument.
Of course, the intended ``transformation'' will only take place as the combinators in the new sequence are themselves reduced, the reduction arising from this combinator is just to apply the function to each element giving a sequence of applications.

¹HOLCONST
Ü $Û™‰cİ : 'a GSU
÷üüüüüüüüüüü
Ü ™‰c = MkCcon (Nat‰u 5)
°

These three combinators together may be used to define a function as a graph in the following way.
Form two corresponding sequences, the first of values in the domain of the desired function, the second having at each position the value of the function at that point.
The required function takes some value $x$, and maps $¬é ‰c\ v®$ over the first argument, and then uses that list to determine which value to select from the second list.

An infinitary case combinator might therefore be obtained from these three combinators as follows.

=GFT
	Gfun‰c	= Ìx y z· — ‰c (™ ‰c (é ‰c z) ‰c x) ‰c y
=TEX

It is not expected that this will ever be done, it is important only that it \emph{could} be done (if only by some inaccessibly infinite deity), and this is intended to ensure that we can do `classical' mathematics in pretty much the normal way within our target calculus, which will probably be demonstrated by reconstructing a strong set theory within it.
The ability to represent arbitrary functions of infinite domains (e.g. over the reals) by such means depends upon the axiom of choice, which we do have at our disposal.
It is intended also that the target illative lambda calculus will benefit (or perhaps in some eyes be blighted by) a choice principle.

\subsection{Semantics}

The semantics is defined as a partial equivalence relation over the abstract syntax.
The partial equivalence relation is represented by a disjoint pair of relations, a positive part and a negative part.

The positive part is an equivalence relation which corresponds to convertibility.

The negative part is an approximation to distinctness.
This part is ultimately discarded, but plays a role in the definition of the positive part, because the an application of an equivalence combinator reduces to $F‰c$ only if the two arguments are related under this negative part of the partial equivalence relation.
Of course, the negative part itself is not an equivalence relation.

You may think of this partial equivalence relation alternatively as represented by a three-valued equivalence relation, the pairs which map to true correspond to the pairs in the positive part of the relation, and those which map to false correspond to those in the negative part.
The requirement that this is an equivalence relation is simply the usual conditions (reflexive, symmetric and transitive),  on the positive part.

This partial equivalence relation is obtained as the least fixed point of a monotone operator over these partial equivalence relations.
The ordering over these is the conjunction of the orderings under inclusion of the two component relations.

The functor is defined in two parts, the positive part and the negative part.

\paragraph{positive part}

The positive part is defined in three stages.
First \emph{direct reduction} is defined for the \emph{Pure} combinators \index{combinator!pure}.
These are combined into a closure operator which obtains from any relation the smallest equivalence relation closed under direct reduction subject to a rule of extensionality (equivalent functions applied to equivalent arguments give equivalent combinators).
In this context the pure combinators are those for which direct reduction is definable independently of the other combinators.

The second stage is the definition of direct reducibility for the illative equivalence combinator, which is done \emph{relative to} some given partial equivalence relation.

The third stage is to combine the two previous definitions into a partial functor, which takes a partial equivalence relation and delivers the positive part of a partial equivalence relation.
It does this by applying the definition of direct reducibility of equivalence to the partial equivalence to get a first version of the positive part, and then closing this under the closure operator obtained from the definitions of the other combinators.

\paragraph{negative part}

There are two parts to this.

Firstly a fixed part under which all constants are known to be distinct.

Secondly we infer that two combinatorial expressions are distinct if when applied to equal arguments they yield distinct results.
To obtain such results you need to have both positive and negative results, so this part has to be defined as a function over a partial equivalence relation.

I now see that the negative part is derivable from the positive part, in which it is incorporated as reductions of equations to $F‰c$.
Its not obvious whether it is better to extract the information in that way or to maintain it separately as I first set out to do.
I will hedge my bets a bit until I get a stronger sense of which is the best way to go.

\subsubsection{The Combinators}

The question of what are the primitive combinators must therefore now be addressed.

My inclination is to work with five combinators, S, K, $é$, $—$ (projection), and $™$ (map), of which the last two are infinitary, the first three being much the same as you would expect in a finitary illative combinatory logic in which the illative primitive is equality.
I toyed with the idea that S should be made infinitary, but have decided to see whether it works without.
The map combinator can be used to make an infinitary S, so it looks like S is redundant.

The rationale for this is that the infinitary aspect is of marginal significance, and may be thought of as supplying strength, but just as in the role of large cardinals in set theory, the strength is bound up with ontological plenitude.
It should be like an afterthough, the main features of the system should arise in the finitary case from the first three combinators, and the principle innovation is in the approach to giving meaning to $é$.

The definitions of the pure combinators (all except $é$) are given as conversion rules, whose reflexive symmetric transitive closure give a first approximation to the meaning of $é$.
If we assume given some meaning for $é$ and obtain from it a second version by combining it with the conversion rules for the other combinators, then we have a functor over possible meanings for $é$, which can be defined so as to be monotone relative to some appropriate ordering.
The least fixed point will then be used to determine the semantics of the infinitary combinatory logic.

\subsubsection{Direct Conversions for the Pure Combinators}

These are defined as relations over \emph{Csyntax}.

¹HOLCONST
Ü ÛKredİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· Kred s t ¤ ¶x y· s = (K‰c ‰c x) ‰c y ± t = x
°

¹HOLCONST
Ü ÛSredİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· Sred s t ¤ ¶x y z· s = ((S‰c ‰c x) ‰c y) ‰c z ± t = (x ‰c z) ‰c (y ‰c z)
°

The projection combinator is more complicated.

¹HOLCONST
Ü Û—‰r‰e‰dİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· —‰r‰e‰d s t ¤ (¶k l m n· Dom‰u k = Dom‰u m
		± Ordinal‰u (Dom‰u k) ± Ran‰u k = Unit‰u F‰c
		± s = —‰c ‰c (†‰c (k @‰u l)) ‰c (†‰c (m @‰u n)) 
		± t = —‰c ‰c (†‰c l) ‰c (†‰c n))
	² (¶k m· š‰u í‰u T‰c ‰u k
		± š‰u í‰u t ‰u m
		± s = —‰c ‰c (†‰c k) ‰c (†‰c m))
° 

As is the infinitary ``map''.

¹HOLCONST
Ü Û™‰r‰e‰dİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· ™‰r‰e‰d s t ¤ ¶f l m· Dom‰u l = Dom‰u m
Ü		± Ordinal‰u (Dom‰u l)
Ü		± m = (Ì‰u x· f ‰c x)(Dom‰u l)
Ü		± s = (™‰c ‰c f) ‰c (†‰c l)
Ü		± t = †‰c m
°

Direct combinatorial reducibility is the union of these relationships.
Because the infinitary combinators are so much more complex than the finitary combinators in ways which are probably not pertinent to the method of defining equivalence, I propose to separate out the two kinds of reduction, and undertake the development in the first instance using only the finitary part.

The finitary combinators yield this notion of reducibility:

¹HOLCONST
Ü ÛDComRedİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· DComRed s t ¤ Kred s t ² Sred s t
° 

With the following for the infinitary combinators, which we will consider no further until we have demonstrated the viability of our method using only the finitary combinators.

¹HOLCONST
Ü ÛDiComRedİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· DiComRed s t ¤ —‰r‰e‰d s t ² ™‰r‰e‰d s t 
° 

¹HOLCONST
Ü ÛDbComRedİ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü µs t· DbComRed s t ¤ Kred s t ² Sred s t ² —‰r‰e‰d s t ² ™‰r‰e‰d s t 
° 

\subsubsection{Extraction of Negative Part}

Since the negative part of the partial equivalence relation (and the positive part for that matter) is encoded in the positive part through reductions of equations, it is possible to recover it from the positive part.

This is how it is done:

¹HOLCONST
Ü ÛNpİ : ('a GSU ­ 'a GSU ­ BOOL) ­ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü µr· Np r = Ìx y· r (($é‰c ‰c x) ‰c y) F‰c
°
\subsubsection{Equality}

We now consider the question, when can we know that two combinators are equal or not equal.

The first obvious principle is that if two combinators are convertible then they are equal.
However, we cannot adopt the converse principle, that two combinators which are not convertible are distinct, because the equality conditions feed into the conversion rules through the equality combinator.
So we have to have some definite criteria for distinctness which we are confident will not include any combinator pairs which might ever be found to be convertible.

There are three parts to these criteria for distinctness.

The first part is that all the constants are to be considered distinct.
This is consistent with the reduction rules for those constants to which we assign a definite meaning.

This provides an initial value for the inequality relation.

¹HOLCONST
Ü ÛIneq0İ : 'a GSU ­ 'a GSU ­ BOOL
÷üüüüüüüüüüü
Ü Ineq0 = Ìx y·	¶v w· x = MkCcon v ± y = MkCcon w ± ³ v = w	
° 

The second part is that if two combinators when applied to equal lists of arguments reduce to combinators which are known to be distinct, then they are themselves distinct.

We need a closure operation which will take a notion of inequality and add to it any further inequalities which are immediately apparent from that inequality relation using the second rule just cited.

¹HOLCONST
Ü ÛEqSeqİ : ('a GSU ­ 'a GSU ­ BOOL) ­ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü µeq· EqSeq eq = Ìv w· Fun‰u v ± Fun‰u w ±  Dom‰u v = Dom‰u w ± Ordinal‰u (Dom‰u v)
Ü		± µx· x ‰u Dom‰u v ´ eq (v ‰u x) (w ‰u x)
°

¹HOLCONST
Ü ÛEqStepİ : ('a GSU ­ 'a GSU ­ BOOL) ­ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü µeq· EqStep eq = Ìv w· ¶c i1 i2· c í‰u i1  Csyntax ± c í‰u i2  Csyntax
Ü	± Dom‰u i1 = Dom‰u i2 ± (µx· x ‰u Dom‰u i1 ´ eq (i1 ‰c x) (i2 ‰c x))
°

¹HOLCONST
Ü ÛIneqStepİ : ('a GSU ­ 'a GSU ­ BOOL) ­ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü µeq· IneqStep eq = Ìx y· Np eq x y ² ¶v w· EqSeq eq v w ± Np eq (x ‰c v) (y ‰c w)
°

\subsubsection{Illative Reduction}

Reduction for the illative combinator $é‰c$ is intended to encapsulate reducibility as a whole.
We could define such a notion here in terms of closure of the reducibility relation for the pure combinators, but this would fall short of the entire reducibility relation by not recognising the reductions it introduces.
The definition needs to be recursive, reducibility needs to be defined in terms of itself.

Such a recursive definition can be realised by taking a fixed point of a functor which defines reducibility given some supposed definition of reducibility.

In constructing such a functor we need to specify the reductions which take place on applications of the equality combinator, which will be done using the supplied equivalence relation.
This will be a partial relation in the form of two disjoint relations, one positive and one negative.
If the positive relation holds over the arguments the equation reduces to $T‰c$ if the negative relation holds the equation reduces to $F‰c$.

¹HOLCONST
Ü Ûé‰r‰e‰dİ : ('a GSU ­ 'a GSU ­ BOOL) ­ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü µeq· é‰r‰e‰d eq = Ìx y·
Ü		¶l m· x = (($é‰c ‰c l) ‰c m)
Ü			± (EqStep eq x y ± y = T‰c ² IneqStep eq x y ± y = F‰c)
°

\subsubsection{Closure}

There must be a name for this.

I have two versions, not sure yet which to use.

¹HOLCONST
Ü ÛRedClosed1İ : ('a GSU ­ 'a GSU ­ BOOL) ­ BOOL
÷üüüüüüüüüüü
Ü µr· RedClosed1 r = µc i1 i2· c í‰u i1  Csyntax ± c í‰u i2  Csyntax
Ü	± Dom‰u i1 = Dom‰u i2 ± (µx· x ‰u Dom‰u i1 ´ r (i1 ‰c x) (i2 ‰c x))
Ü	´ r (c í‰u i1) (c í‰u i2)
° 

¹HOLCONST
Ü ÛRedClosed2İ : ('a GSU ­ 'a GSU ­ BOOL) ­ BOOL
÷üüüüüüüüüüü
Ü µr· RedClosed2 r = µc d e f g h· c í‰u e  Csyntax ± d í‰u f  Csyntax
Ü	± r (c í‰u e) (d í‰u f) ± EqSeq r g h 
Ü	´ r (c í‰u e @‰u g) (c í‰u f @‰u h)
° 

I'll use them both pro-tem.

¹HOLCONST
Ü ÛRedClosureİ : ('a GSU ­ 'a GSU ­ BOOL) ­ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü µr· RedClosure r = Ìx y· µr1· RedClosed1 r1 ± RedClosed2 r1 ± (Csyntax, r) € (Csyntax, r1)
			´ r1 x y
° 

\subsubsection{Functor Constructor}

The functor with which we define equivalence must a monotone functor over partial equivalence relations.
It requires, or rather consists of a positive and a negative closure operator, each of which has access to the partial equivalence relation and delivers one half of the resulting partial equivalence relation.

\subsubsection{Pure Equivalence}

Pure infinitary combinatorial equivalence is then:

¹HOLCONST
Ü ÛPIComEqİ : 'a GSU SET ¸ ('a GSU ­ 'a GSU ­ BOOL)
÷üüüüüüüüüüü
Ü PIComEq = EquivClosure (Csyntax, RedClosure DbComRed)
° 

=GFT
ÛEquiv_PIComEq_thmİ = ô Equiv PIComEq
=TEX

\ignore{
=SML
val PIComEq_def = get_spec ¬PIComEq®;

set_goal([], ¬Equiv PIComEq®);
a (rewrite_tac [PIComEq_def, Equiv_EquivClosure_thm]);
val Equiv_PIComEq_thm = save_pop_thm "Equiv_PIComEq_thm";
=TEX
}%ignore

We now define a set of equivalence classes which will form a new type of combinators.

¹HOLCONST
Ü ÛPureInfCombİ : 'a GSU SET ­ BOOL
÷üüüüüüüüüüü
Ü µx· PureInfComb x ¤ x  QuotientSet Csyntax (Snd PIComEq)
° 

=GFT
ÛPureInfComb_¶_lemmaİ =
   ô µ x· x  Csyntax ´ EquivClass PIComEq x  PureInfComb
Û¶_PureInfComb_lemmaİ =
   ô ¶ x· x  PureInfComb
=TEX

\ignore{
=SML
val PureInfComb_def = get_spec ¬PureInfComb®;

set_goal([], ¬µx· x  Csyntax ´ PureInfComb(EquivClass PIComEq x)®);
a (rewrite_tac [PureInfComb_def, PIComEq_def, get_spec ¬EquivClass®, get_spec ¬QuotientSet®]
	THEN REPEAT strip_tac);
a (¶_tac ¬x® THEN asm_rewrite_tac[get_spec ¬EquivClass®, EquivClosure_def] THEN REPEAT strip_tac);
val PureInfComb_¶_lemma = save_pop_thm "PureInfComb_¶_lemma";

set_goal([], ¬¶x· PureInfComb x®);
a (¶_tac ¬EquivClass PIComEq (MkCcon š‰u)®);
a (lemma_tac ¬MkCcon š‰u  Csyntax® THEN1 rewrite_tac[MkCcon__Csyntax_thm]);
a (all_fc_tac [PureInfComb_¶_lemma]);
val ¶_PureInfComb_lemma = pop_thm ();
=TEX
}%ignore

\subsection{A Church-Rosser Theorem}

At this point it is desirable to prove something like the Church-Rosser theorem for this system, so that we know that not all combinators are equivalent.
Since this is probably hard I am exploring a bit more before digging in to the proof.

\subsection{The Type of Infinitary Combinators}

=SML
new_type_defn (["IC"], "IC", ["'a"], ¶_PureInfComb_lemma);
=TEX


\subsection{Monotonicity}

To get a least fixed point of \emph{EqFunctor} we need to identify an ordering relative to which it is monotone.

=SML

commit_pc "'icomb";

force_new_pc "Ûicombİ";
merge_pcs ["misc3", "'icomb"] "icomb";
commit_pc "icomb";

force_new_pc "Ûicomb1İ";
merge_pcs ["misc31", "'icomb"] "icomb1";
commit_pc "icomb1";
=TEX


\section{The Finitary System}

This is a marker for something in the future.
It is possible that in the exploration of the semantic ideas I may have to sketch some things out here before coming here to consider this level more seriously.

\subsection{The System of Type Assignment}

=SML
set_flag ("subgoal_package_quiet", false);
=TEX


