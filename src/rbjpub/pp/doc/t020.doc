=IGN
$Id: t020.doc,v 1.4 2006/11/09 12:05:24 rbj01 Exp $
open_theory "poly-sets";
set_merge_pcs ["hol1", "'savedthm_cs_∂_proof"];
=TEX
\documentclass[11pt,a4paper]{article}
\usepackage{latexsym}
\usepackage{ProofPower}
\ftlinepenalty=9999
\usepackage{A4}

\def\ExpName{\mbox{{\sf exp}}}
\def\Exp#1{\ExpName(#1)}

\tabstop=0.4in
\newcommand{\ignore}[1]{}

\title{PolySet Theory}
\makeindex

\author{Roger Bishop Jones}
\date{$ $Date: 2006/11/09 12:05:24 $ $}
\usepackage[pdftex]{hyperref}

\begin{document}
\begin{titlepage}
\maketitle
\begin{abstract}
A construction similar in effect but rather different in method to the Oswald-Church construction is defined in a generic way.
The purpose of the construction is to build from a well-founded extensional membership structure another membership structure containing the original but having many other sets in addition, often not well-founded, typically including a universal set.

The generic construction is then applied to create a model which we call poly-sets.
poly-sets are sets generated from a proforma set by filling in values for wildcards.
The wildcards are represented by a subset of the ordinals, and as the wildcards are instantiated the remaining ordinals are reduced by the number of ordinals used as wildcards.

This construction is intended to reflect the intuition that certain kinds of polymorphic function, particularly those which arise in the simple polymorphism found in LCF, ML and HOL, work by not looking at values whose type is a type varisble, so that only the superficial structure of the arguments is significant for such a function.
The function can therefore be represented by a set which gives the graph using wildcards in the positions where such values are expected.
\end{abstract}

\vfill

\begin{centering}

\href{http://www.rbjones.com/rbjpub/pp/doc/t020.pdf}
{http://www.rbjones.com/rbjpub/pp/doc/t020.pdf}

$ $Id: t020.doc,v 1.4 2006/11/09 12:05:24 rbj01 Exp $ $

\bf Copyright \copyright\ : Roger Bishop Jones \\

\end{centering}

\thispagestyle{empty}
\end{titlepage}
\newpage
\addtocounter{page}{1}
%\section{DOCUMENT CONTROL}
%\subsection{Contents list}
\tableofcontents
%\newpage
%\subsection{Document cross references}

\subsection*{To Do}
\begin{itemize}
\item Poly-set specific definitions
\item Proofs
\end{itemize}

{\raggedright
\bibliographystyle{fmu}
\bibliography{rbj,fmu}
} %\raggedright

\newpage
\section{INTRODUCTION}

It is the purpose of this document to introduce a new 
\footnote{As far as I know}
set theory with a universal set.

In this introduction I want to first of all give an account of how I arrived at the key ideas, which I hope will go some way toward motivating its study and use.
I also want to say a few words about how this document goes about introducing this theory.

\subsection{Origins}

These ideas come after a fairly prolonged if intermittent interest on my part in non-well-founded foundation systems, which I first became actively interested in in 1095 when I concluded that they were desirable for the kind of logical approach to Artificial Intelligence which I was then considering.
The seeds of antipathy to the constraint of well-foundedness had however been sown many years earlier, so that when I first came (for example) to Russell's writings on his Theory of Types I was disinclined to allow that circulariy was always, or even often vicious.
I don't propose to go into this long history of (not very fruitful) interest here, for there are intelligible motivators in the near term.

I have recently been attempting the construction of non-well-founded category theoretic foundation systems, following up the obvious possibility (which I have long neglected) that NF or NFU could be used as a base from which to construct such a system.
I did this primarily in order to give me an entertaining task which would improve my acquaintance with NF and NFU.
In this objective it has been successful in small measure, for I have come to understand rather early in this process how awkward it is to work (using my preferred tools) with NF or NFU.

This provoked me into thinking anew about what kind of non-well-founded ontology would be more suitable for my present purposes.
NF and NFU are based primarily on liberalisation of the constraint on abstraction in simple type theory along lines suggested by the typical ambiguity which Russell and Whitehead adopted in Principia Mathematica.
The intuition here seems syntactic rather than semantic.

I prefer to work, as well-founded set theories do, from an intuition about ontology to an axiomatisation of the theory of that ontology, rather than from an idea about liberalisation of theory not based in any definition conception ontology.
Poly-sets are based on such an intuition, which is also rooted as it happens in something close to the notion of typical ambiguity in type theory, but which translated more readily into an ontology.

We consider what kinds of non-well-founded set we want to have, then the examples which come to mind are the functions in the pure lambda calculus, for example the identity function.
It is the fragmentation of this kind of function (considering predicates as propositional functions) which made typical ambiguity an essential expedient in the application of Russel's theory of types, and which lead Robin Milner to introduce a very simple kind of polymorphism into Scott's Logic for Computable Functions, and into the programming language ML, and later into Mike Gordon's adaptation of Church's Simple Theory of Types \cite{church40} for use in the HOL theorem prover.

If we observe the kinds of non-well-founded function provided by this kind of polymorphism (usually identified by attribution to various combinations of Milner, Hindley and Henessey) we find that the sets non-well-founded sets all have what I will call here a {\it superficial} structure.
The functions are polymorphic in the most simplistic way, they work because the parts of the structures which they manipulate which are polymorphic are simply ignored or copied, but never examined.
To chose one of the most simple examples, the polymorphic function which computes the length of a list of values can be polymorphic in the type of the values because it works only on the structure of the list, and ignores the values in the list.
However the great the complexity, however high the rank of a list of values supplied to it, the length function looks only at its superficial structure in order to determine its length.

This suggests that this kind of non-well-founded function might be modelled by the use of sets which are permitted to contain wild-cards.
The set described in this way would be one whose members are all those sets which can be obtained by some substitution of sets for the wildcard.

We can implement the wildards as ordinals.
A poly-set can be represented by an ordered pair of well-founded sets of which the first is a VonNeumann ordinal.
Every occurence in the second set of an ordinal which is a member of the first set is interpreted as a wild card.
Every occurrence of an ordinal which is not in that set (i.e. which is equal to or larger than the first set) is interpreted as that ordinal minus the number of wild cards.
If the first set is zero, there are no wildcards and the second set is the value of the poly-set, so the poly-sets include all the well-founded sets.
If the first set is non-sero then the second set is interpreted as a pro-forma for the elements of a non-well-founded poly-set whose elements are all the values which can be obtained from that proforma by substituting sets for the ordinals which are wild cards (the same value for different occurrences of the same wild card).
Thus, the length function would be a poly-set in which the first set is the ordinal $\omega$.
The second set would then be a countably infinite set of ordered pairs in which the flrst is a finite list of distinct finite ordinals and the second is the length of the list.

The above sketch needs further elaboration in two respects, the details of which will appear in the formal treatment which follows.
The purpose of these two elaborations is first to allow that the members of a poly-set be themselves poly-sets, and secondly to arrange for the resulting collection of poly-sets to be extensional.

\subsection{The Formal Treatment}

The idea here is to introduce a new theory by first constructing a model of that theory and then demonstrating properties suitable for use as axioms in a theory in which that model is the intended interpretation.
I am working with software implementing a version of Higher Order Logic and the development including the necessary proofs will be formal and machine checked.

The construction of the model for the theory of poly-sets will be based on an assumed model for a well-founded set theory.
I have in mind a standard model of a pure well-founded set theory which is closed under the construction of grothendiek universes, i.e. in which every set is a member of a set with closure properties similar to those of ZF (notably closure under replacement).
However, no specific well-founded set theory will be used.
The construction will be based on some arbitrary membership structure, and the proofs of properties of the constructed model will be based on minimal assumptions about the properties of the membership structure on which it is built.

The construction will take place following methods addressed in \cite{rbjt007} and \cite{rbjt004}.
It will first use a generalised Hereditarily poly-set construction (analogous to the idea of hereditarily finite sets with the property of being a poly-set substituted for that of finiteness).
It will then use the method from \cite{rbjt004} for collapsing an arbitrary membership relation into an extensional collection.

We will then reason about the properties of the constructed model, formulate a property which corresponds to a reasonable axiomatisation of the theory and prove that this property obtains if the initial membership relationship is a standard model of a well-founded set theory with ``universes''.
Having thus validated the putative axiomatisation, we could then work in the theory of poly-set by adopting this axiom system, or we could set up the system conservatively using a set theory in HOL already in place with adequate strength.

Since my motivation for performing the construction is to use this as a basis for the a further construction, the theory will not need to be established as similar methods can be adopted in the second construction.

\subsection{Church-Oswald Models}

I wrote the above in ignorance of Church-Oswald models, which are described in the last chapter of \cite{forster92}.
Then I thought I had better have a rummage around to see if there was anything similar already studied, just in case enough is known about this model to put me off it.

There certainly are some similarities between the kind of cnstruction I have in mind here and the things that Forster describes as Church-Oswald constructions.
So with only the most superficial knowledge of these things I will make a first sketch here of the similarities and differences.

First the similarities.
I think the basic idea with the CO constructions is that you start with a model of a well-founded set theory such as ZFC and use this to represent a broader collection of sets which includes a universal set.
Slightly stronger than that, the construction provides for additional set forming operations such as, for example, complementation.

The construction goes in several stages, first a set is chosen for taggings sets, with one element of the set used to identify the old fashioned set formation processes and the other elements to identify new operations.
So in the simplest case there might be only two values one for ordinal set constructions, the other for forming a complement (and this simple case corresponds to Oswald's model).
You have to have a bijection {\it k} between V and V ∏ K where K is the set of such tags and this is used in defining a new membership relation over V in which the new operations feature.

What I have in mind may well be equivalent, I'm not sure yet so I will have to give that more consideration as I work my way through it.
The idea is to work with the subset of V consisting of those sets which are hereditarily ordered pairs with elements of K on the left, and to define a new membership structure over these without needing a bijection between V and V ∏ K.

Going beyond the generic procedure for constructing (what Forster calls) P-extensions of models of Z, there is the question of the details of the particular construction, and in this it seems more likely than my plan is novel.
The notion of superficial sets described above provides a different take on what ill-founded sets are desirable.

Forster says that extensionality is a big problem, and I therefore conclude that there must be something amiss with my naive plan to collapse the membership relationship into and extensional relationship using the function {\it ExtRel} defined in \cite{rbjt004}.
Presumably I will eventually discover what the problem is when I start trying to do proofs about that function.

\section{GENERIC P-EXTENSIONS}

First we have a new theory.

=SML
open_theory "membership";
force_new_theory "poly-sets";
new_parent "fixp";
set_merge_pcs ["hol1", "'savedthm_cs_∂_proof"];
=TEX

The plan is:

\begin{itemize}
\item Define an operator on membership structures which constructs a set of poly-sets.

\item Define the membership relation over the poly-sets (in terms of the original membership relation, which will have to be well-founded).

\item Collapse the new membership structure into an extensional membership structure.

\item Derive properties of poly-sets from properties of the underlying well-founded sets.
In particular we are looking to derive from strong closure properties of the underlying set theory similarly strong closure properties of the poly-sets.
The principles derivable for the well-founded polysets should be identical to those on the underlying set theory.
We also expect a principle of abstraction specific to non-well-founded poly-sets which reflects fairly directly the intuition and the construction.

\end{itemize}

\subsection{The Set of Poly-Sets}

To define this set we define the relationship between a poly-set and the poly-sets from which it is constructed, i.e. the (Von-Neumann) ordinal on the left and the well-founded set on the right and then obtain a fixed point from this relationship.
Both of these will be themselves poly-sets
\footnote{I don't know any reason why the ordinals from the membership structure rather than poly-set ordinals could not be used on the left, but my hunch is that it will work out better with poly-sets on both sides.}
, and we therefore need the predicate ``ordinal'' for polysets to define this function.

The construction is therefore undertaken in three stages as follows:

\begin{itemize}
\item define the injection from the well-founded sets into the poly-sets
\item define a generic putative {\it P-extension} construction (since I now suspect the proposed procedure may be equivalent to a Church-Oswald construction, and a generic account may make it easier to check this out).
\item define the specifics of the poly-sets construction for fitting into the generic construction.
\end{itemize}

\subsection{The Canonical Injection}

As in Forster this is done by transfinite recursion.
For the sake of making as much of this generic as possible the definition of the injection is parameterised by the zero element of K.
In the particular construction I had in mind this would be the zero poly-ordinal, but it doesn't make sense to plumb that into the injection.

The canonical injection works informally as follows.
It takes the set and maps the canonical injection over the members of the set, and then puts the resulting set of poly-sets into the right hand element of an ordered pair of which the left element is the nominated "zero" K value.

\ignore{
=SML
set_goal([], ¨∂CanInj∑ µ xms z s∑ is_XMS xms ± s ç Carâx xms ¥
	CanInj xms z s = Opâx xms
	  (z, Absâx xms {x:'a | ∂y∑ y ç Carâx xms ± Inâx xms y s ± x = CanInj xms z y})
Æ);
a (prove_∂_tac THEN REPEAT strip_tac);
a (lemma_tac ¨∂G:('a ≠ 'a) ≠ ('a ≠ 'a)∑ µf s∑ G f s = Opâx xms' (z',
	Absâx xms' {x | ∂ y∑ y ç Carâx xms' ± Inâx xms' y s ± x = f y})Æ
	THEN1 prove_∂_tac);
a (lemma_tac ¨FunctRespects G (Carâx xms', Inâx xms')Æ
	THEN1 (rewrite_tac [get_spec ¨FunctRespectsÆ]
		THEN REPEAT strip_tac
		THEN asm_rewrite_tac[]));
(* *** Goal "1" *** *)
a (LEMMA_T ¨{x'|∂ y∑ y ç Carâx xms' ± Inâx xms' y x ± x' = g y}
	= {x'|∂ y∑ y ç Carâx xms' ± Inâx xms' y x ± x' = h y}Æ
	 rewrite_thm_tac
	THEN1 (rewrite_tac[] THEN REPEAT strip_tac));
(* *** Goal "1.1" *** *)
a (∂_tac ¨yÆ THEN asm_rewrite_tac[] THEN all_asm_fc_tac[]);
(* *** Goal "1.2" *** *)
a (∂_tac ¨yÆ THEN asm_rewrite_tac[] THEN ALL_ASM_FC_T rewrite_tac []);
(* *** Goal "2" *** *)
a (lemma_tac ¨is_XMS xms' ¥ WellFounded (Carâx xms', Inâx xms')Æ
	THEN1 (rewrite_tac [get_spec ¨is_XMSÆ]
		THEN REPEAT strip_tac
		THEN asm_rewrite_tac[]));
(* *** Goal "2.1" *** *)
a (∂_tac ¨≈x∑ TÆ	THEN strip_tac THEN asm_rewrite_tac[]);
(* *** Goal "2.2" *** *)
a (fc_tac [recursion_theorem]);
a (fc_tac [get_spec ¨UniquePartFixpÆ]);
a (∂_tac ¨fÆ THEN REPEAT strip_tac);
a (fc_tac [get_spec ¨PartFunEquivÆ]);
a (ASM_FC_T (rewrite_tac o list_map_eq_sym_rule) []);
a (asm_rewrite_tac []);
save_cs_∂_thm(pop_thm());
=TEX
}%ignore

Though the definition is quite simple, {\Product} does not have the competence automatically to prove its consistency.
The author has supplied an appropriate proof script which has been checked by {\Product} before accepting the definition.

πHOLCONST
‹ €CanInj›: 'a XMS ≠ 'a ≠ 'a ≠ 'a
˜¸¸¸¸¸¸¸¸¸¸¸¸¸¸¸
‹ µ xms z s∑ is_XMS xms ± s ç Carâx xms ¥
‹	CanInj xms z s = Opâx xms
‹	  (z, Absâx xms {x | ∂y∑ y ç Carâx xms ± Inâx xms y s ± x = CanInj xms z y})
∞

\subsection{The Domain of the New Structure}

We now construct the domain of the new structure.
Lets call these P-sets.
A P-set is a hereditarily-ordered-pair of which the first element is an element of some arbitrary set of tags and the second is a set of P-sets.
It is a transfinite recursive datatype.

The definition is accomplished by defining the relationship which holds between a P-set and the P-sets which are its immediate constituents.
A least fixed point is then taken of the function on sets which maps a set of (putative P-)sets into the set obtained by adding all the P-sets which can be formed immediately from the P-sets in the set.
This relation is parameterised by the original membership structure and a set of tags.

I have some reservations about this method, and will probably find a nicer way to do this before attempting any proofs.
The form of this relation is tailored to the requirements of the function {\it HeredRel} which gives the fixed point, and in particular it is required that a set which is not a candidate new set (e.g. because it is not an ordered pair, or for any reason other than that its constituents are not new sets, relates to at least itself, at as written here to everything else as well.
This ensures that the existence of its constituents is never possible.
Its a device for coding a well-formedness predicate into the content relation.


πHOLCONST
‹ €Pset_content›: 'a XMS ≠ 'a SET ≠ 'a ≠ 'a ≠ BOOL
˜¸¸¸¸¸¸
‹ µ xms tags s t∑ Pset_content xms tags s t §
‹	(∂tag psets∑ tag ç tags ± psets ç (Carâx xms) ± Inâx xms s psets ± t = Opâx xms (tag, psets))
‹ ≤	(≥∂ tag psets∑ tag ç tags ± psets ç (Carâx xms) ± t = Opâx xms (tag, psets))
∞

The set of Psets is then defined:

πHOLCONST
‹ €Psets›: 'a XMS ≠ 'a SET ≠ 'a SET
˜¸¸¸¸¸¸
‹ µ xms tags∑ Psets xms tags = HeredRel (Pset_content xms tags)
∞

\subsection{Defining The Membership Relation}

The membership relationship cannot of course be defined without more information specific to the Pset construction.

The only things which are generic in this are the treatment of the "zero tag" and the conversion to an extensional relationship.

Let us suppose that the specifics of the membership are given by an ordered pair of which the first is the zero tag and the second is a function from tag to a relationship between sets of P-sets and P-sets.

πHOLCONST
‹ €PsMemNx›: 'a XMS ≠ ('a SET ∏ 'a ∏ ('a ≠ 'a ≠ 'a ≠ BOOL)) ≠ ('a ≠ 'a ≠ BOOL)
˜¸¸¸¸¸¸
‹ µ xms (tags, zt, f) s t∑ PsMemNx xms (tags, zt, f) s t §
‹	∂ tag psets∑ t = Opâx xms (tag, psets)
‹		± if tag = zt then Inâx xms s psets else f tag psets s
∞

The we convert this into an extensional relationship (over equivalence classes of the original sets).

πHOLCONST
‹ €PsMem›: 'a XMS ≠ ('a SET ∏ 'a ∏ ('a ≠ 'a ≠ 'a ≠ BOOL)) ≠ ('a SET SET ∏ ('a SET ≠ 'a SET ≠ BOOL))
˜¸¸¸¸¸¸
‹ µ xms (tags, zt, f)∑ PsMem xms (tags, zt, f) = ExtRel (Psets xms tags, PsMemNx xms (tags, zt, f))
∞

\section{POLY-SETS}

The tags for the poly-sets are to be the set of ordinal poly-sets.
Everything continues to be parameterised by a î'a XMSÆ.
The main task here is to define the membership relation over the poly-sets.

This works as follows.
Lets call a poly-set with left zero an mpoly-set, or where the context allows simply mono.
One with a non zero tag will be a ppoly-set or poly.
The image of the canonical injection is the poly-sets which are hereditarily mono.
The mpoly-sets are similar to the low sets (as defined by Forster) in a Church-Oswald construction.

Ppoly-sets have a non-zero poly-set ordinal on the left, and this is the set of poly-sets whose occurrences in the set of poly-sets on the right should be treated as wild cards.
The extension of a ppoly-set is the set of values which can be obtained by taking a member of the set on the right (a proforma) of the ppoly-set and an assignment of poly-sets to the poly-set ordinals which are wildcards, and substituting the sets in the assignment for the instances of the relevant ordinals in the proforma while subtracting the number of wild cards from every ordinal which is larger than all the wild cards.

So to define membership we need to be able to apply a substitution to a poly-set while doing a bit of arithmetic on poly-set ordinals.
Since we have no bound variables this should be straightforward.

\ignore{
 πHOLCONST
‹ €PolySetTags›: xms ≠ 
˜¸¸¸¸¸¸
‹ µ xms∑ PolySetTags = {t | }
 ∞
}%ignore

\ignore{
=SML
=TEX
} %ignore

\ignore{
=SML
=TEX
} %ignore

\ignore{
 πHOLCONST
‹ €› :
˜¸¸¸¸¸¸
‹
 ∞
} %ignore

{\let\Section\section
\newcounter{ThyNum}
\def\section#1{\Section{#1}
\addtocounter{ThyNum}{1}\label{Theory\arabic{ThyNum}}}
\include{poly-sets.th}
}  %\let

\twocolumn[\section{INDEX}\label{index}]
{\small\printindex}

\end{document}
