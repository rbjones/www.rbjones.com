=IGN
$Id: t020.doc,v 1.7 2006/12/20 09:06:08 rbj01 Exp $
open_theory "poly-sets";
set_merge_pcs ["hol1", "'savedthm_cs_¶_proof"];
=TEX
\documentclass[11pt,a4paper]{article}
\usepackage{latexsym}
\usepackage{ProofPower}
\ftlinepenalty=9999
\usepackage{A4}

\def\ExpName{\mbox{{\sf exp}}}
\def\Exp#1{\ExpName(#1)}

\tabstop=0.4in
\newcommand{\ignore}[1]{}

\title{PolySet Theory}
\makeindex

\author{Roger Bishop Jones}
\date{\ }
\usepackage[unicode,pdftex]{hyperref}
\hypersetup{pdfauthor={Roger Bishop Jones}}
\hypersetup{colorlinks=true, urlcolor=black, citecolor=black, filecolor=black, linkcolor=black}

\begin{document}
\begin{titlepage}
\maketitle
\begin{abstract}
This document contains an approach to providing an interpretation of the first order language of set theory.
The purpose of the interpretation is to provide semantic foundation for logical systems which are suitable for the large scale formalisation of mathematics and its applications.
Improved support is sought for the management of context both in the small (as in the ML ``let'' clause) and in the large (as in the handling of theories or modules, and in the development and appication of abstract mathematical structures).
The right kinds of ``Polymorphism'' are important at all levels, as is illustrated in the small by the differences between the ``let'' clause in ML and its much less satisfactory rendition in HOL.

A series of innovations (at least, of techniques which I have devised in ignorance of any prior use) have been deployed to this end, for the details of which read on.
However, the trail began with a single insight into the nature of polymorphic functions in ML which inspired a particular conception of what non-well-founded sets should be included in the ontology.

This intuition of what sets there should be was realised in the first instance by a construction based on a well-founded set theoretic ontology yielding an extended ontology, including both the original well-founded sets and a collection of non-well-founded sets intended to include (inter alia) the graphs of the polymorphic functions definable in ML.
This done with a somewhat naive hope that this kind of polymorphism might not only provide us in a logical context with better management of local context (i.e. an ML-like `let' clause in a HOL-like language), but would also provide better management of the larger scale context (defining abstract algebraic structures and applying the resulting theories in diverse other contexts).

Eventually I concluded that more was needed.
The most conspicuous absence was complementation, but the richness of the poly-sets as extrapolated into set theory from ML-polymorphism appeared to be inconsistent with the existence of all complements.
Combined with set abstraction capabilities which included infinitary unions (suggestive of existential quantification) complementation threatens to provide the effect of full comprehension.

The generic construction is then applied to create a model which we call poly-sets.
poly-sets are sets generated from a proforma set by filling in values for wildcards.
The wildcards are represented by a subset of the ordinals, and as the wildcards are instantiated the remaining ordinals are reduced by the number of ordinals used as wildcards.

This construction is intended to reflect the intuition that certain kinds of polymorphic function, particularly those which arise in the simple polymorphism found in LCF, ML and HOL, work by not looking at values whose type is a type varisble, so that only the superficial structure of the arguments is significant for such a function.
The function can therefore be represented by a set which gives the graph using wildcards in the positions where such values are expected.
\end{abstract}

\vfill

\begin{centering}
{\footnotesize
Created 2006/10/15

Last Changed $ $Date: 2006/12/20 09:06:08 $ $

\href{http://www.rbjones.com/rbjpub/pp/doc/t020.pdf}
{http://www.rbjones.com/rbjpub/pp/doc/t020.pdf}

$ $Id: t020.doc,v 1.7 2006/12/20 09:06:08 rbj01 Exp $ $

\copyright\  Roger Bishop Jones; Licenced under Gnu LGPL \\

}%footnotesize
\end{centering}

\thispagestyle{empty}
\end{titlepage}
\newpage
\addtocounter{page}{1}
%\section{DOCUMENT CONTROL}
%\subsection{Contents list}
{\parskip=0pt\tableofcontents}
%\newpage
%\subsection{Document cross references}

{\raggedright
\bibliographystyle{fmu}
\bibliography{rbj,fmu}
} %\raggedright

\newpage
\section{INTRODUCTION}

It is the purpose of this document to introduce a new 
\footnote{As far as I know}
set theory with a universal set.

In this introduction I want to first of all give an account of how I arrived at the key ideas, which I hope will go some way toward motivating its study and use.
I also want to say a few words about how this document goes about introducing this theory.

\subsection{Historical Note}

These ideas come after a fairly prolonged if intermittent interest on my part in non-well-founded foundation systems, which I first became actively interested in in 1095 when I concluded that they were desirable for the kind of logical approach to Artificial Intelligence which I was then considering.
The seeds of antipathy to the constraint of well-foundedness had however been sown many years earlier, so that when I first came (for example) to Russell's writings on his Theory of Types I was disinclined to allow that circulariy was always, or even often vicious.
I don't propose to go into this long history of (not very fruitful) interest here, for there are intelligible motivators in the near term.

In September 2006 I with a view to improving my understanding of NF in anticipation of a meeting on NF planned by Thomas Forster for the next year, I began to explore the construction of non-well-founded category theoretic foundation systems, following up the obvious possibility (which I have long neglected) that NF or NFU could be used as a base from which to construct such a system.
Before long I became dissatisfied with NF, primarily because of the lack of a convincing story about ontology, which gave me no basis for confidence that it would provide the right collection of non-well-founded sets for my purposes.

I prefer to work, as well-founded set theories do, from an intuition about ontology to an axiomatisation of the theory of that ontology, rather than from an idea about liberalisation of theory not based in any definition conception ontology.
Poly-sets are based on such an intuition, which is also rooted as it happens in something close to the notion of typical ambiguity in type theory, but which translated more readily into an ontology.

We consider what kinds of non-well-founded set we want to have, then the examples which come to mind are the functions in the pure lambda calculus, for example the identity function.
It is the fragmentation of this kind of function (considering predicates as propositional functions) which made typical ambiguity an essential expedient in the application of Russel's theory of types, and which lead Robin Milner to introduce a very simple kind of polymorphism into Scott's Logic for Computable Functions, and into the programming language ML, and later into Mike Gordon's adaptation of Church's Simple Theory of Types \cite{church40} for use in the HOL theorem prover.

If we observe the kinds of non-well-founded function provided by this kind of polymorphism (usually identified by attribution to various combinations of Milner, Hindley and Henessey) we find that the sets non-well-founded sets all have what I will call here a {\it superficial} structure.
The functions are polymorphic in the most simplistic way, they work because the parts of the structures which they manipulate which are polymorphic are simply ignored or copied, but never examined.
To chose one of the most simple examples, the polymorphic function which computes the length of a list of values can be polymorphic in the type of the values because it works only on the structure of the list, and ignores the values in the list.
However the great the complexity, however high the rank of a list of values supplied to it, the length function looks only at its superficial structure in order to determine its length.

This suggests that this kind of non-well-founded function might be modelled by the use of sets which are permitted to contain wild-cards.
The set described in this way would be one whose members are all those sets which can be obtained by some substitution of sets for the wildcard.

We can implement the wildards as ordinals.
A poly-set can be represented by an ordered pair of well-founded sets of which the first is a VonNeumann ordinal.
Every occurence in the second set of an ordinal which is a member of the first set is interpreted as a wild card.
Every occurrence of an ordinal which is not in that set (i.e. which is equal to or larger than the first set) is interpreted as that ordinal minus the number of wild cards.
If the first set is zero, there are no wildcards and the second set is the value of the poly-set, so the poly-sets include all the well-founded sets.
If the first set is non-sero then the second set is interpreted as a pro-forma for the elements of a non-well-founded poly-set whose elements are all the values which can be obtained from that proforma by substituting sets for the ordinals which are wild cards (the same value for different occurrences of the same wild card).
Thus, the length function would be a poly-set in which the first set is the ordinal $\omega$.
The second set would then be a countably infinite set of ordered pairs in which the flrst is a finite list of distinct finite ordinals and the second is the length of the list.

The above sketch needs further elaboration in two respects, the details of which will appear in the formal treatment which follows.
The purpose of these two elaborations is first to allow that the members of a poly-set be themselves poly-sets, and secondly to arrange for the resulting collection of poly-sets to be extensional.

\subsection{The Formal Treatment}

The idea here is to introduce a new theory by first constructing a model of that theory and then demonstrating properties suitable for use as axioms in a theory in which that model is the intended interpretation.
I am working with software implementing a version of Higher Order Logic and the development including the necessary proofs will be formal and machine checked.

The construction of the model for the theory of poly-sets will be based on an assumed model for a well-founded set theory.
I have in mind a standard model of a pure well-founded set theory which is closed under the construction of grothendiek universes, i.e. in which every set is a member of a set with closure properties similar to those of ZF (notably closure under replacement).
However, no specific well-founded set theory will be used.
The construction will be based on some arbitrary membership structure, and the proofs of properties of the constructed model will be based on minimal assumptions about the properties of the membership structure on which it is built.

The construction will take place following methods addressed in \cite{rbjt007} and \cite{rbjt004}.
It will first use a generalised Hereditarily poly-set construction (analogous to the idea of hereditarily finite sets with the property of being a poly-set substituted for that of finiteness).
It will then use the method from \cite{rbjt004} for collapsing an arbitrary membership relation into an extensional collection.

We will then reason about the properties of the constructed model, formulate a property which corresponds to a reasonable axiomatisation of the theory and prove that this property obtains if the initial membership relationship is a standard model of a well-founded set theory with ``universes''.
Having thus validated the putative axiomatisation, we could then work in the theory of poly-set by adopting this axiom system, or we could set up the system conservatively using a set theory in HOL already in place with adequate strength.

Since my motivation for performing the construction is to use this as a basis for the a further construction, the theory will not need to be established as similar methods can be adopted in the second construction.

\subsection{Church-Oswald Models}

I wrote the above in ignorance of Church-Oswald models, which are described in the last chapter of \cite{forster92}.
Then I thought I had better have a rummage around to see if there was anything similar already studied, just in case enough is known about this model to put me off it.

There certainly are some similarities between the kind of cnstruction I have in mind here and the things that Forster describes as Church-Oswald constructions.
So with only the most superficial knowledge of these things I will make a first sketch here of the similarities and differences.

First the similarities.
I think the basic idea with the CO constructions is that you start with a model of a well-founded set theory such as ZFC and use this to represent a broader collection of sets which includes a universal set.
Slightly stronger than that, the construction provides for additional set forming operations such as, for example, complementation.

The construction goes in several stages, first a set is chosen for taggings sets, with one element of the set used to identify the old fashioned set formation processes and the other elements to identify new operations.
So in the simplest case there might be only two values one for ordinal set constructions, the other for forming a complement (and this simple case corresponds to Oswald's model).
You have to have a bijection {\it k} between V and V ¸ K where K is the set of such tags and this is used in defining a new membership relation over V in which the new operations feature.

What I have in mind may well be equivalent, I'm not sure yet so I will have to give that more consideration as I work my way through it.
The idea is to work with the subset of V consisting of those sets which are hereditarily ordered pairs with elements of K on the left, and to define a new membership structure over these without needing a bijection between V and V ¸ K.

Going beyond the generic procedure for constructing (what Forster calls) P-extensions of models of Z, there is the question of the details of the particular construction, and in this it seems more likely than my plan is novel.
The notion of superficial sets described above provides a different take on what ill-founded sets are desirable.

Forster says that extensionality is a big problem, and I therefore conclude that there must be something amiss with my naive plan to collapse the membership relationship into and extensional relationship using the function {\it ExtRel} defined in \cite{rbjt004}.
Presumably I will eventually discover what the problem is when I start trying to do proofs about that function.

\section{EXTENDING WELL-FOUNDED INTERPRETATIONS}

There are general methods for producing interpretations of the first order language of set theory by beginning with a well founded interpretation of that language (perhaps a standard model of ZFC) and adding non-well-founded sets.
Such an extension of a well-founded interpretation, in which the original interpretation is preserved intact inside the new are called in \cite{forster85,forster2006} as \emph{P-extensions}.

First we have a new theory.

=SML
open_theory "GS";
force_new_theory "poly-sets";
new_parent "fixp";
new_parent "bvi";
set_merge_pcs ["hol1", "'savedthm_cs_¶_proof"];
=TEX

The plan is:

\begin{itemize}
\item In a well-founded set theory construct a set of representatives for poly-sets.

\item Define a functor over boolean valued interpretations which captures the intended meaning of the representatives and the notion of extensional equivalence over these representatives.

\item Explore the partial fixed points of this functor.

\end{itemize}

\subsection{The Set of Poly-Sets}

This is done in stages.

First the a subset of the Poly-Set representatives isomorphic to the Von Neumann ordinals in well-founded set theory is defined.
Then the full set of Poly-Set representatives is defined using that special representation of ordinals.

The set is defined inductively as a fixed point of a monotonic function.

¹HOLCONST
Ü Ûmk_PSRÝ: GS ¸ GS ­ GS
÷üüüüüü
Ü µor s· mk_PSR (or, s) = or íg s 
°

The following functor maps a set of sets to the set of PSRs which can be constructed from it (assuming that they are all themselves PSRs).

¹HOLCONST
Ü ÛPSR_funcÝ: GS SET ­ GS SET
÷üüüüüü
Ü µgss· PSR_func gss =
Ü	{s
Ü	| ¶or psrs· Ordinal or
Ü	± Xg psrs  gss
Ü	± s = mk_PSR (or, psrs)}
°

Now we take the least fixed point.

¹HOLCONST
Ü ÛPSRÝ: GS SET
÷üüüüüü
Ü PSR = HeredFun PSR_func
°

\ignore{
=SML
push_pc "hol";
set_goal([], ¬µs· (µt· t  s ´ PSR_func t  s) ´ PSR  s®);
a (rewrite_tac [get_spec ¬PSR®, HeredFun_induction_thm2]);
val PSR_induction_thm = save_pop_thm "PSR_induction_thm";
pop_pc();
=TEX
}%ignore

=GFT
PSR_induction_thm =
	ô µ s· (µ t· t  s ´ PSR_func t  s) ´ PSR  s
=TEX

\subsection{The Domain of the New Structure}

We now construct the domain of the new structure.
Lets call these P-sets.
A P-set is a hereditarily-ordered-pair of which the first element is an element of some arbitrary set of tags and the second is a set of P-sets.
It is a transfinite recursive datatype.

The definition is accomplished by defining the relationship which holds between a P-set and the P-sets which are its immediate constituents.
A least fixed point is then taken of the function on sets which maps a set of (putative P-)sets into the set obtained by adding all the P-sets which can be formed immediately from the P-sets in the set.
This relation is parameterised by the original membership structure and a set of tags.

I have some reservations about this method, and will probably find a nicer way to do this before attempting any proofs.
The form of this relation is tailored to the requirements of the function {\it HeredRel} which gives the fixed point, and in particular it is required that a set which is not a candidate new set (e.g. because it is not an ordered pair, or for any reason other than that its constituents are not new sets, relates to at least itself, at as written here to everything else as well.
This ensures that the existence of its constituents is never possible.
Its a device for coding a well-formedness predicate into the content relation.

\subsection{Defining The Membership Relation}

The membership relationship cannot of course be defined without more information specific to the Pset construction.

The only things which are generic in this are the treatment of the "zero tag" and the conversion to an extensional relationship.

Let us suppose that the specifics of the membership are given by an ordered pair of which the first is the zero tag and the second is a function from tag to a relationship between sets of P-sets and P-sets.


\section{POLY-SETS}

The tags for the poly-sets are to be the set of ordinal poly-sets.
Everything continues to be parameterised by a 'a XMS®.
The main task here is to define the membership relation over the poly-sets.

This works as follows.
Lets call a poly-set with left zero an mpoly-set, or where the context allows simply mono.
One with a non zero tag will be a ppoly-set or poly.
The image of the canonical injection is the poly-sets which are hereditarily mono.
The mpoly-sets are similar to the low sets (as defined by Forster) in a Church-Oswald construction.

Ppoly-sets have a non-zero poly-set ordinal on the left, and this is the set of poly-sets whose occurrences in the set of poly-sets on the right should be treated as wild cards.
The extension of a ppoly-set is the set of values which can be obtained by taking a member of the set on the right (a proforma) of the ppoly-set and an assignment of poly-sets to the poly-set ordinals which are wildcards, and substituting the sets in the assignment for the instances of the relevant ordinals in the proforma while subtracting the number of wild cards from every ordinal which is larger than all the wild cards.

So to define membership we need to be able to apply a substitution to a poly-set while doing a bit of arithmetic on poly-set ordinals.
Since we have no bound variables this should be straightforward.

\ignore{
 ¹HOLCONST
Ü ÛPolySetTagsÝ: xms ­ 
÷üüüüüü
Ü µ xms· PolySetTags = {t | }
 °
}%ignore

\ignore{
=SML
=TEX
} %ignore

\ignore{
=SML
=TEX
} %ignore

\ignore{
 ¹HOLCONST
Ü ÛÝ :
÷üüüüüü
Ü
 °
} %ignore

{\let\Section\section
\newcounter{ThyNum}
\def\section#1{\Section{#1}
\addtocounter{ThyNum}{1}\label{Theory\arabic{ThyNum}}}
\include{poly-sets.th}
}  %\let

\twocolumn[\section{INDEX}\label{index}]
{\small\printindex}

\end{document}
