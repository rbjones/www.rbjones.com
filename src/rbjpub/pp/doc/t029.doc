=TEX
\def\rbjidtDFdoc{$$Id: t029.doc,v 1.2 2009/07/03 13:58:37 rbj Exp $$}

\subsection{Formal Methods in Philosophy}

At least three kinds of work are described by philosophers as constituting ``formal philosophy''
\footnote{This discussion is primarily based on the accounts by philosophers of their involvement in formal philosophy published in \cite{hendricks2005,hendricks2006}.}
.
\begin{enumerate}
\item the use of mathematics in addressing philosophical problems
\item the use of metamathematics or meta-logic in addressing philosophical problems
\item the conduct of philosophy using formal deductive arguments where possible.
\end{enumerate}

Of these the first two dominate.
Arguably only the third is truly formal.

I will expand this discussion, but this document will primarily be concerned with explaining one approach to item 3.

\subsection{Formal Methods in Information Engineering}

\section{Formal Deductive Modelling} \label{FDM}

\ignore{
=SML
open_theory "rbjmisc";
force_new_theory "fmphil";
=TEX
}%ignore


\subsection{Languages}

Two formal languages are used in this document.
One is a language, called HOL for Higher Order Logic, with a deductive system sufficient for the formal development of mathematics, or for other applications susceptible of formalisations.

The other is a metalanguage known as SML, which stands for Standard Meta-Language.
This is used for giving exective instructions to software which provides support for use of the HOL language and for the contruction and verification of formal proofs in the HOL logic.

\subsubsection{HOL}

The principle language used here (apart from English) is a language (and logic) called HOL.
HOL is an acronym for Higher Order Logic, of which there are many different varieties, and is also widely used for a specific variant of higher order logic which has been implemented in several computer programs providing support for formal specification and proof.

For full details of this language you would need to refer to the documentation which comes with these tools \cite{ds/fmu/ied/spc001} or some of the papers published about them.
See below (Section \ref{ProofPower}) for information relating to the tool used for producing this document, \ProductHOL.

The language HOL is a direct descendent of Russell's {\it Theory of Types}\cite{russell1908}, the logic which he and Whitehead used in {\it Principia Mathematica}\cite{russell1913}.
To get from Russell's {\it Theory of Types} to HOL you do the following (names in brackets give credit to the person who thought of the step):

\begin{itemize}
\item discard the ramifications (Ramsey \cite{ramsey25})
\item simplify by basing on typed lambda-calculus (Church \cite{church40})
\item add polymorphism (Gordon/Milner \cite{gordon87,milner78})
\end{itemize}

To do serious work you need a proof tool, see (Section \ref{ProofPower}).

The following are the most important features of this language/logic which distinguish it from those typically considered by philosophers.

\begin{itemize}
\item It is a foundation system, i.e. it suffices for the development of mathematics by conservative extension (definitions) alone.
\item It has a type system, and allows new types to be defined.
\item It is supported by computer software which checks specifications, assists in constructing proofs and rigorously checks proofs.
\end{itemize}

\subsection{Methods}

The principle technique used here is a method which has some of the theoretical merits of a metatheoretic treatment, but is less arduous and provides better support for reasoning in the object language.

We imagine ourself devising a formal language in which to talk about Aristotle's metaphysics, and in which to formalise the kind of metaphysical arguments which are found in Aristotle.
To do this rigorously, we need to deal first with the semantics of the language, and establish a deductive system which is sound with respect to that semantics.

A standard formal treatment of this material would involve a specification of the syntax of an appropriate language, the development of semantics, probably as some kind of model theory, the specification of a deductive system for the language and a proof of soundness of that system (this would be a version of Aristotle's Syllogistic logic).
This is feasible with the languages and tools we are using, but arduous.
The results would be good for metatheory, but not necessarly convenient for conducting proofs in the language thus defined, i.e. for reasoning in the new object language.

There is another manner of proceeding which better suits our present purposes.
This consists in extending our already available language, using the definitional facilities and the flexibility in its syntax (e.g. fixity declarations) to create a language extension which looks something like and behaves exactly like the intended object language.

We begin with something like model theory, defining new data types which model the kinds of thingd that the new language is to be about.
The constructs in the language are then given definitions in terms of these new data tupes.
By deduction within HOL we are then able to prove results which correspond to results in the intended object language.

There ia a technical term for this kind of treatment of languages in HOL, they are called {\it shallow semantic embeddings}, and this term indicates that the expressions of the target language are represented by expressions in HOL which are syntactically similar (though perhaps not identical) to those of the intended object language, and which do have the same meaning as the target language expressions.
For a fuller description of this kind of method (used in theoretical computer science) see \cite{gordon88}.

If you have not come across this kind of thing before this probably does not make much sense at this point, but I hope that eventually the material which follows will provide an intelligible example of this method.

\subsubsection{Schemas and Higher Order Quantification}

Much of the semi-formal material which we are trying to fully formalise involves general talk about the kinds of things which are found in categories.
Possibly the formulae are intended as schemas in a first order predicate calculus.
This is not the way we will treat them, so a few words explaining why not are in order here.

We are working here in a higher-order logic.
In a first-order logic, it is not possible for quantify over anything but individuals.
In first order set theory we get around that restriction by having ``individuals'' which are surrogates for all kinds of higher order objects.
In set theory we can, by quantifying over the individuals encompass objects which represent properties of functions of every conceivable type.
Some pragmatic issues remain which we need not go into here.

When a first-order formalisation is attempted without benefit of the machinery of set theory, it often proves necessary to use schemata, which are a syntactic surrogate for quantification over higher types.
A well known example is the theory PA, a first order version of Peano's axioms for arithmetic.
Peano himself formulated his axioms for arithmetic before first order logic was invented, before indeed the foundational problems which provoked the development of type theories.
His axiom of induction involved quantification over properties along the following lines:

=GFT
	ô µp· p(0) ± (µx· p(x) ´ p(x + 1)) ´ µx· p(x)
=TEX

Which we may paraphrase:
\begin{quote}
for all properties {\it p}, if {\it p} holds for 0 and, whenever {\it p} is true of some natural number, it is true also of its successor, then {\it p} will be true of all natural numbers
\end{quote}

In the first order formalisation of Peano Arithmetic, known as PA, we cannot quantify over properties, so we use instead an axiom schemata, which lifts the quantification into the metalanguage and changes from quantifying over numbers to quantifying over formulae.
Thus we have instead something like:

=GFT
	ô P(0) ± (µx· P(x) ´ P(x + 1)) ´ µx· P(x)
=TEX

Where $P$ is not a predicate in the object language, but a syntactic function in the metalanguage which yields formula.
This first order axiom schema describes an infinite set of properly first order axioms obtained by substituting arbitrary formulae (in which $0$ occurs) for $P(0)$, and corresponding formulae for $P(x)$ and $P(x+1)$ in which $x$ and $x+1$ respectively replace occurences of $0$ in the original formula.

\subsubsection{Features of The Language}

The following features of the language are methodologically significant:

[to be supplied]

\subsection{Tools}

\subsection{ProofPower}\label{ProofPower}

The tool used for preparation of this document, for checking the syntax and type correctness of the formal specifications, for assisting in the construction of formal proofs, and for checking the resulting proofs in detail is \Product.

This document is a {\it literate script}.
This means that it is a {\it script} intended for processing by machine, which is also intended to be humanly intelligible (i.e. literate).

The source for the document is machine processed in two distinct ways.
The formal content is extracted and processed by the proof tool \Product, which understands two main languages, the first, HOL, a kind of higher order logic suitable for the formal development of mathematics and for applications of formalised logic and/or mathematics.
The second is a functional programming language called SML, in which instructions may be given to \Product on how to process the formal specifications.
This includes instructions on how to construct and check formal proofs of conjectures in HOL.

\Product come with a library of already defined mathematical concepts and of theorems proven in the context of these definitions, which are organised into a hierarchy of theories in which a theory may make use of the definitions made and theorems proven in any of its ancestors.
As \Product processes a document it aguments the theory hierarchy with the new material.
Listings of the theories can be obtained for inclusion at the end of the document.

The other way of processing the source is for the purpose of obtaining a humanly readable document, typically in PDF format, of which this is an example.
While the document is being written, the author enters into an interactive dialogue with the proof tool in which new definitions or modifications to existing definitions are checked for grammatical correctness and type-correctness.
Proofs of conjecture are developed interactively in such a session using a ``goal package'' which permits the user to work backwards from the goal he is attempting to prove.
The end result of such proof development is a script in the metalanguage SML which provides to \Product a prescription for constructing a proof, which is checked for correctness on-the-fly.
This will be rerun when the complete document is later processed in batch.

Document preparation uses the \LaTeX package augmented by facilities provided by \Product, various aspects such as the formatting of formal text, the creation of contents lists, indexes and bibliographies being thereby facilitated.
